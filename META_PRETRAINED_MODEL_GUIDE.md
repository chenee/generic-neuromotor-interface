# Metaé¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨æŒ‡å—ï¼ˆColabç¯å¢ƒï¼‰

## âœ… æ˜¯çš„ï¼ŒMetaæä¾›äº†å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹ï¼

### ğŸ“¦ æ¨¡å‹ä¿¡æ¯

Metaåœ¨é¡¹ç›®ä¸­æä¾›äº†3ä¸ªä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼š
- âœ… **discrete_gestures** (ç¦»æ•£æ‰‹åŠ¿è¯†åˆ«)
- âœ… **handwriting** (æ‰‹å†™è¯†åˆ«)  
- âœ… **wrist** (è…•éƒ¨è¿åŠ¨)

**è®­ç»ƒé…ç½®:**
- 100ä¸ªå‚ä¸è€…çš„å®Œæ•´æ•°æ®
- 250 epochsè®­ç»ƒ
- æœ€ä¼˜è¶…å‚æ•°é…ç½®
- çº¦25-74MBå¤§å°

---

## ğŸš€ åœ¨Colabä¸­ä¸‹è½½å’Œä½¿ç”¨

### æ–¹æ³•1: Pythonè„šæœ¬ä¸‹è½½

```python
from generic_neuromotor_interface.scripts.download_models import download_models

# ä¸‹è½½discrete_gesturesé¢„è®­ç»ƒæ¨¡å‹
download_models("discrete_gestures", "/content/emg_models")
```

### æ–¹æ³•2: å‘½ä»¤è¡Œä¸‹è½½

```bash
python -m generic_neuromotor_interface.scripts.download_models \
    --task discrete_gestures \
    --output-dir /content/emg_models
```

ä¸‹è½½å®Œæˆåä¼šå¾—åˆ°ï¼š
```
/content/emg_models/discrete_gestures/
â”œâ”€â”€ model_checkpoint.ckpt    # PyTorch Lightning checkpoint (~74MB)
â””â”€â”€ model_config.yaml         # æ¨¡å‹é…ç½®æ–‡ä»¶
```

---

## ğŸ’¡ é¢„è®­ç»ƒæ¨¡å‹ç”¨é€”

### 1ï¸âƒ£ ç›´æ¥è¯„ä¼°Metaæ¨¡å‹æ€§èƒ½

æŸ¥çœ‹Metaå®˜æ–¹æ¨¡å‹çš„å‡†ç¡®ç‡ï¼Œä½œä¸ºbaselineå‚è€ƒï¼š

```python
import torch
from hydra.utils import instantiate
from omegaconf import OmegaConf

# åŠ è½½é…ç½®
config = OmegaConf.load("/content/emg_models/discrete_gestures/model_config.yaml")

# åŠ è½½æ¨¡å‹
model = instantiate(config.lightning_module)
model = model.load_from_checkpoint(
    "/content/emg_models/discrete_gestures/model_checkpoint.ckpt",
    map_location=torch.device("cpu")
)

# è¯„ä¼°
# å‚è€ƒ notebooks/discrete_gestures-eval.ipynb
```

### 2ï¸âƒ£ ä½œä¸ºTeacherè¿›è¡ŒçŸ¥è¯†è’¸é¦

ä½¿ç”¨Metaé«˜æ€§èƒ½æ¨¡å‹è’¸é¦è½»é‡çº§Studentæ¨¡å‹ï¼š

```python
# åœ¨è’¸é¦è„šæœ¬ä¸­
cd mini/chenee/distillation

python train_distillation.py \
    --teacher_checkpoint /content/emg_models/discrete_gestures/model_checkpoint.ckpt \
    --data_dir /content/generic-neuromotor-interface/data \
    --split_csv /content/generic-neuromotor-interface/data/discrete_gestures_corpus.csv \
    --output_dir ./student_models
```

è¿™æ ·å¯ä»¥å¾—åˆ°ï¼š
- ConvOnly: 80KB INT8æ¨¡å‹ï¼ˆESP32ï¼‰
- Student: 600KBæ¨¡å‹ï¼ˆæ‰‹æœºï¼‰

### 3ï¸âƒ£ ä¸è‡ªå·±è®­ç»ƒçš„æ¨¡å‹å¯¹æ¯”

å¯¹æ¯”æ‚¨è®­ç»ƒçš„æ¨¡å‹ä¸Metaå®˜æ–¹æ¨¡å‹çš„æ€§èƒ½å·®è·ï¼š

```python
# Metaé¢„è®­ç»ƒæ¨¡å‹
meta_model = load_checkpoint("/content/emg_models/discrete_gestures/model_checkpoint.ckpt")
meta_accuracy = evaluate(meta_model)  # é¢„æœŸ: ~95%+

# æ‚¨è®­ç»ƒçš„æ¨¡å‹  
your_model = load_checkpoint("/content/generic-neuromotor-interface/logs/.../epoch=8-step=1980.ckpt")
your_accuracy = evaluate(your_model)  # å½“å‰: ~39% (10 epochs)

print(f"Metaæ¨¡å‹: {meta_accuracy:.2%}")
print(f"æ‚¨çš„æ¨¡å‹: {your_accuracy:.2%}")
print(f"å·®è·: {meta_accuracy - your_accuracy:.2%}")
```

### 4ï¸âƒ£ è¿ç§»å­¦ä¹ /å¾®è°ƒ

åœ¨æ–°æ•°æ®ä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ï¼š

```python
# åŠ è½½é¢„è®­ç»ƒæƒé‡
pretrained_model = load_checkpoint("/content/emg_models/discrete_gestures/model_checkpoint.ckpt")

# åœ¨æ–°æ•°æ®ä¸Šå¾®è°ƒ
trainer = Trainer(max_epochs=50)
trainer.fit(pretrained_model, new_datamodule)
```

---

## ğŸ“Š é¢„æœŸæ€§èƒ½ï¼ˆMetaé¢„è®­ç»ƒæ¨¡å‹ï¼‰

æ ¹æ®è®ºæ–‡ï¼ŒMetaé¢„è®­ç»ƒæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°ï¼š

| ä»»åŠ¡ | å‡†ç¡®ç‡ | CLER | å¤‡æ³¨ |
|------|--------|------|------|
| **Discrete Gestures** | ~95%+ | <5% | 9ç§æ‰‹åŠ¿åˆ†ç±» |
| **Handwriting** | ~90%+ | ~10% | å­—ç¬¦è¯†åˆ« |
| **Wrist** | ~85%+ | - | è…•éƒ¨è¿åŠ¨è½¨è¿¹ |

**å¯¹æ¯”æ‚¨å½“å‰çš„10è½®è®­ç»ƒ:**
- æ‚¨çš„æ¨¡å‹: 39% å‡†ç¡®ç‡ (10 epochs)
- Metaæ¨¡å‹: ~95% å‡†ç¡®ç‡ (250 epochs, 100ç”¨æˆ·)
- **å·®è·åŸå› **: è®­ç»ƒæ—¶é—´çŸ­ï¼Œéœ€è¦ç»§ç»­è®­ç»ƒè‡³250 epochs

---

## ğŸ”§ å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ï¼ˆColab Notebookï¼‰

åœ¨æ‚¨çš„colab_train.ipynbä¸­æ·»åŠ ä»¥ä¸‹å•å…ƒæ ¼ï¼š

### å•å…ƒæ ¼1: æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹

```python
import os
from pathlib import Path

MODEL_DIR = Path("/content/emg_models")
PRETRAINED_MODEL = MODEL_DIR / "discrete_gestures" / "model_checkpoint.ckpt"

if PRETRAINED_MODEL.exists():
    size_mb = PRETRAINED_MODEL.stat().st_size / 1e6
    print(f"âœ… æ‰¾åˆ°Metaé¢„è®­ç»ƒæ¨¡å‹: {size_mb:.1f} MB")
else:
    print("âš ï¸  æœªæ‰¾åˆ°ï¼Œéœ€è¦ä¸‹è½½")
```

### å•å…ƒæ ¼2: ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

```python
from generic_neuromotor_interface.scripts.download_models import download_models

print("ğŸ“¥ ä¸‹è½½Metaé¢„è®­ç»ƒæ¨¡å‹...")
download_models("discrete_gestures", "/content/emg_models")
print("âœ… ä¸‹è½½å®Œæˆï¼")
```

### å•å…ƒæ ¼3: åŠ è½½å¹¶æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯

```python
import torch
from omegaconf import OmegaConf

# åŠ è½½é…ç½®
config_path = "/content/emg_models/discrete_gestures/model_config.yaml"
config = OmegaConf.load(config_path)

print("ğŸ“‹ Metaæ¨¡å‹é…ç½®:")
print(OmegaConf.to_yaml(config))

# åŠ è½½checkpointæŸ¥çœ‹è¯¦æƒ…
ckpt = torch.load(
    "/content/emg_models/discrete_gestures/model_checkpoint.ckpt",
    map_location='cpu',
    weights_only=False
)

print(f"\nğŸ“Š Checkpointä¿¡æ¯:")
print(f"  Epoch: {ckpt.get('epoch', 'N/A')}")
print(f"  Global Step: {ckpt.get('global_step', 'N/A')}")

# æŸ¥çœ‹æœ€ä½³éªŒè¯æŒ‡æ ‡
if 'callbacks' in ckpt:
    print(f"\nğŸ† Metaæ¨¡å‹æœ€ä½³è¡¨ç°:")
    for cb_name, cb_state in ckpt['callbacks'].items():
        if 'best' in str(cb_name).lower():
            print(f"  {cb_name}:")
            if isinstance(cb_state, dict):
                for k, v in cb_state.items():
                    if 'best' in str(k).lower():
                        print(f"    {k}: {v}")
```

---

## âš ï¸ é‡è¦è¯´æ˜

### Colabç¯å¢ƒè·¯å¾„

æ‚¨ä½¿ç”¨VSCodeè¿æ¥Colab kernelï¼Œæ‰€ä»¥ï¼š
- âœ… æ•°æ®è·¯å¾„: `/content/generic-neuromotor-interface/data`
- âœ… æ¨¡å‹è·¯å¾„: `/content/emg_models`
- âœ… æ—¥å¿—è·¯å¾„: `/content/generic-neuromotor-interface/logs`
- âŒ **ä¸æ˜¯**æœ¬åœ°è·¯å¾„: `~/emg_data` æˆ– `/Users/chenee/...`

### ä¸‹è½½æ—¶é—´å’Œå¤§å°

- discrete_gesturesæ¨¡å‹: ~74MB
- ä¸‹è½½æ—¶é—´: çº¦30ç§’ï¼ˆå–å†³äºç½‘ç»œï¼‰
- å­˜å‚¨ä½ç½®: Colabä¸´æ—¶å­˜å‚¨ï¼ˆé‡å¯ä¼šä¸¢å¤±ï¼‰

### æ°¸ä¹…ä¿å­˜

å¦‚æœè¦æ°¸ä¹…ä¿å­˜é¢„è®­ç»ƒæ¨¡å‹åˆ°Google Driveï¼š

```python
# ä¸‹è½½åå¤åˆ¶åˆ°Drive
!cp -r /content/emg_models /content/drive/MyDrive/emg_models

# ä¸‹æ¬¡ä½¿ç”¨æ—¶ä»DriveåŠ è½½
MODEL_PATH = "/content/drive/MyDrive/emg_models/discrete_gestures/model_checkpoint.ckpt"
```

---

## ğŸ¯ æ¨èå·¥ä½œæµ

### åœºæ™¯1: å¿«é€ŸéªŒè¯ï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰

1. ä¸‹è½½Metaé¢„è®­ç»ƒæ¨¡å‹
2. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
3. æŸ¥çœ‹baselineæ€§èƒ½
4. å†³å®šæ˜¯å¦éœ€è¦é‡æ–°è®­ç»ƒ

### åœºæ™¯2: å®Œæ•´è®­ç»ƒï¼ˆä»é›¶å¼€å§‹ï¼‰

1. è®­ç»ƒè‡ªå·±çš„æ¨¡å‹ï¼ˆ250 epochsï¼‰
2. ä¸‹è½½Metaé¢„è®­ç»ƒæ¨¡å‹
3. å¯¹æ¯”ä¸¤è€…æ€§èƒ½
4. åˆ†æå·®è·åŸå› 

### åœºæ™¯3: çŸ¥è¯†è’¸é¦ï¼ˆæ¨èï¼‰

1. ä¸‹è½½Metaé¢„è®­ç»ƒæ¨¡å‹ä½œä¸ºTeacher
2. è®­ç»ƒè½»é‡çº§Studentæ¨¡å‹
3. éƒ¨ç½²åˆ°ESP32ç­‰åµŒå…¥å¼è®¾å¤‡
4. å®ç°10-100å€æ¨¡å‹å‹ç¼©

---

## ğŸ“š ç›¸å…³èµ„æº

- ä¸‹è½½è„šæœ¬: `generic_neuromotor_interface/scripts/download_models.py`
- è¯„ä¼°notebook: `notebooks/discrete_gestures-eval.ipynb`
- è’¸é¦ä»£ç : `mini/chenee/distillation/`
- Metaè®ºæ–‡: https://www.nature.com/articles/s41586-025-09255-w

---

## âœ… æ€»ç»“

**æ˜¯çš„ï¼Œé¡¹ç›®ä¸­æœ‰Metaé¢„è®­ç»ƒçš„é«˜æ€§èƒ½æ¨¡å‹ï¼**

**å…³é”®ç‚¹:**
- ğŸ“¦ éœ€è¦æ‰‹åŠ¨ä¸‹è½½ï¼ˆçº¦74MBï¼‰
- âš¡ æ€§èƒ½ä¼˜ç§€ï¼ˆ~95%å‡†ç¡®ç‡ï¼‰
- ğŸ¯ å¯ç”¨äºè¯„ä¼°ã€è’¸é¦ã€å¯¹æ¯”
- ğŸ’» åœ¨Colabç¯å¢ƒä¸­ä½¿ç”¨ï¼Œä¸æ˜¯æœ¬åœ°

**ç«‹å³ä½¿ç”¨:**
```python
# åœ¨Colab notebookä¸­è¿è¡Œ
from generic_neuromotor_interface.scripts.download_models import download_models
download_models("discrete_gestures", "/content/emg_models")
```

ç°åœ¨å°±å¯ä»¥è¯„ä¼°Metaçš„sotaæ¨¡å‹æ€§èƒ½äº†ï¼ğŸš€

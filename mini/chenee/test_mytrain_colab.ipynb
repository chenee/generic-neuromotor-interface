{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4e1bfe",
   "metadata": {},
   "source": [
    "# ğŸ§ª æµ‹è¯• mytrain.py - Colabå°æ ·æœ¬éªŒè¯\n",
    "\n",
    "**ç›®æ ‡**ï¼šéªŒè¯Metaå®Œæ•´è®­ç»ƒæµç¨‹åœ¨Colabä¸­å¯ä»¥æ­£å¸¸è¿è¡Œ\n",
    "\n",
    "**æµ‹è¯•å†…å®¹**ï¼š\n",
    "1. âœ… æ•°æ®åŠ è½½ï¼ˆWindowedEmgDataset + DataSplitï¼‰\n",
    "2. âœ… æ•°æ®å¢å¼ºï¼ˆRotationAugmentationï¼‰\n",
    "3. âœ… æ¨¡å‹è®­ç»ƒï¼ˆDiscreteGesturesArchitectureï¼‰\n",
    "4. âœ… å°æ ·æœ¬å¿«é€ŸéªŒè¯ï¼ˆ1 epochï¼‰\n",
    "\n",
    "**æ•°æ®**ï¼šä½¿ç”¨Colabå·²ä¸‹è½½çš„30GBæ•°æ®ï¼ˆ./dataç›®å½•ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "âš ï¸ **é‡è¦æç¤º**ï¼šè¯·ç¡®ä¿å·²å¯ç”¨GPUï¼\n",
    "- èœå•ï¼š**ä»£ç æ‰§è¡Œç¨‹åº â†’ æ›´æ”¹è¿è¡Œæ—¶ç±»å‹**\n",
    "- ç¡¬ä»¶åŠ é€Ÿå™¨ï¼šé€‰æ‹© **T4 GPU**\n",
    "- CPUè®­ç»ƒéœ€è¦5å°æ—¶ ğŸ˜°ï¼ŒGPUåªéœ€15-30åˆ†é’Ÿ ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” GPUå¯ç”¨æ€§æ£€æŸ¥\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ–¥ï¸  ç¡¬ä»¶ç¯å¢ƒæ£€æŸ¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"âœ… GPUå·²å¯ç”¨: {gpu_name}\")\n",
    "    print(f\"âœ… æ˜¾å­˜å¤§å°: {gpu_memory:.1f} GB\")\n",
    "    print(f\"âœ… CUDAç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "    print(\"\\nğŸš€ é¢„è®¡è®­ç»ƒæ—¶é—´: 15-30åˆ†é’Ÿ\")\n",
    "else:\n",
    "    print(\"âš ï¸  å½“å‰ä½¿ç”¨CPUæ¨¡å¼\")\n",
    "    print(\"âš ï¸  é¢„è®¡è®­ç»ƒæ—¶é—´: 5+ å°æ—¶\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âŒ å¼ºçƒˆå»ºè®®å¯ç”¨GPUï¼\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"æ“ä½œæ­¥éª¤ï¼š\")\n",
    "    print(\"1. èœå•æ  â†’ ä»£ç æ‰§è¡Œç¨‹åº â†’ æ›´æ”¹è¿è¡Œæ—¶ç±»å‹\")\n",
    "    print(\"2. ç¡¬ä»¶åŠ é€Ÿå™¨ â†’ é€‰æ‹© 'T4 GPU'\")\n",
    "    print(\"3. ä¿å­˜ â†’ Notebookä¼šè‡ªåŠ¨é‡å¯\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8eaff575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DataSplit.from_csv æºä»£ç :\n",
      "============================================================\n",
      "    @classmethod\n",
      "    def from_csv(cls, csv_filename: str, pool_test_partitions: bool = True) -> \"DataSplit\":\n",
      "        df = pd.read_csv(csv_filename)\n",
      "        splits: dict[str, dict[str, list[tuple[float, float]]]] = {\n",
      "            \"train\": {},\n",
      "            \"val\": {},\n",
      "            \"test\": {},\n",
      "        }\n",
      "\n",
      "        for split in [\"train\", \"val\", \"test\"]:\n",
      "            for dataset in df[df[\"split\"] == split][\"dataset\"].unique():\n",
      "                dataset_rows = df[(df[\"split\"] == split) & (df[\"dataset\"] == dataset)]\n",
      "                if split == \"test\" and pool_test_partitions:\n",
      "                    first_start = dataset_rows[\"start\"].min()\n",
      "                    last_end = dataset_rows[\"end\"].max()\n",
      "                    splits[split][dataset] = [(first_start, last_end)]\n",
      "                else:\n",
      "                    splits[split][dataset] = [\n",
      "                        (row.start, row.end) for row in dataset_rows.itertuples()\n",
      "                    ]\n",
      "\n",
      "        return cls(**splits)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(\"=\" * 60)\n",
    "print(\"DataSplit.from_csv æºä»£ç :\")\n",
    "print(\"=\" * 60)\n",
    "print(inspect.getsource(DataSplit.from_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf069b",
   "metadata": {},
   "source": [
    "## ğŸ“¦ æ­¥éª¤1ï¼šç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50c63c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorchç‰ˆæœ¬: 2.9.0+cpu\n",
      "âœ… è®¾å¤‡: CPU\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(f\"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"âœ… è®¾å¤‡: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95eb81d",
   "metadata": {},
   "source": [
    "## âš™ï¸ æ­¥éª¤2ï¼šå‚æ•°é…ç½®ï¼ˆå°æ ·æœ¬æµ‹è¯•ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04663472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š è®­ç»ƒé…ç½®:\n",
      "   æ•°æ®è·¯å¾„: ./data\n",
      "   çª—å£é•¿åº¦: 16000 æ ·æœ¬ç‚¹ (8.0ç§’)\n",
      "   Batchå¤§å°: 32\n",
      "   è®­ç»ƒè½®æ•°: 1 (å°æ ·æœ¬æµ‹è¯•)\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# åŸºç¡€å‚æ•°\n",
    "# ==========================\n",
    "SEED = 0\n",
    "DATA_LOCATION = \"./data\"  # Colabä¸­æ•°æ®æ‰€åœ¨ç›®å½•\n",
    "CSV_FILENAME = os.path.join(DATA_LOCATION, \"discrete_gestures_corpus.csv\")\n",
    "\n",
    "WINDOW_LENGTH = 16_000  # 8 ç§’ @ 2kHz\n",
    "STRIDE = 16_000\n",
    "BATCH_SIZE = 32  # å‡å°batch sizeé€‚é…Colabå†…å­˜\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# ğŸ”§ å°æ ·æœ¬æµ‹è¯•ï¼šåªè·‘1ä¸ªepoch\n",
    "MAX_EPOCHS = 1\n",
    "ACCELERATOR = \"auto\"\n",
    "\n",
    "LEARNING_RATE = 5e-4\n",
    "WARMUP_START_FACTOR = 0.001\n",
    "WARMUP_END_FACTOR = 1.0\n",
    "WARMUP_TOTAL_EPOCHS = 5\n",
    "LR_SCHEDULER_MILESTONES = [25]\n",
    "LR_SCHEDULER_FACTOR = 0.5\n",
    "GRADIENT_CLIP_VAL = 0.5\n",
    "\n",
    "PULSE_WINDOW = [0.08, 0.12]  # ç§’\n",
    "ROTATION_AUG = 2\n",
    "\n",
    "LOG_EVERY = 10  # æ›´é¢‘ç¹çš„æ—¥å¿—\n",
    "\n",
    "# å¸¸é‡\n",
    "EMG_NUM_CHANNELS = 16\n",
    "EMG_SAMPLE_RATE = 2000  # Hz\n",
    "\n",
    "print(\"ğŸ“Š è®­ç»ƒé…ç½®:\")\n",
    "print(f\"   æ•°æ®è·¯å¾„: {DATA_LOCATION}\")\n",
    "print(f\"   çª—å£é•¿åº¦: {WINDOW_LENGTH} æ ·æœ¬ç‚¹ ({WINDOW_LENGTH/EMG_SAMPLE_RATE:.1f}ç§’)\")\n",
    "print(f\"   Batchå¤§å°: {BATCH_SIZE}\")\n",
    "print(f\"   è®­ç»ƒè½®æ•°: {MAX_EPOCHS} (å°æ ·æœ¬æµ‹è¯•)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a5295",
   "metadata": {},
   "source": [
    "## ğŸ¯ æ­¥éª¤3ï¼šæ ¸å¿ƒç±»å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b539066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å®šä¹‰äº† 9 ç§æ‰‹åŠ¿ç±»å‹\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# æ‰‹åŠ¿ç±»å‹æšä¸¾\n",
    "# ==========================\n",
    "class GestureType(Enum):\n",
    "    index_press = 0\n",
    "    index_release = 1\n",
    "    middle_press = 2\n",
    "    middle_release = 3\n",
    "    thumb_click = 4\n",
    "    thumb_down = 5\n",
    "    thumb_in = 6\n",
    "    thumb_out = 7\n",
    "    thumb_up = 8\n",
    "\n",
    "print(f\"âœ… å®šä¹‰äº† {len(GestureType)} ç§æ‰‹åŠ¿ç±»å‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "508b3264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… éšæœºç§å­å·²è®¾ç½®\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# å·¥å…·å‡½æ•°\n",
    "# ==========================\n",
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def get_full_dataset_path(root: str, dataset: str) -> Path:\n",
    "    path = Path(root).expanduser().joinpath(f\"{dataset}\")\n",
    "    if not path.suffix:\n",
    "        path = path.with_suffix(\".hdf5\")\n",
    "    return path\n",
    "\n",
    "seed_everything(SEED)\n",
    "print(\"âœ… éšæœºç§å­å·²è®¾ç½®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e9cc85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataSplit ç±»å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# DataSplit: æ•°æ®åˆ†å‰²é…ç½®\n",
    "# ==========================\n",
    "@dataclass\n",
    "class DataSplit:\n",
    "    train: dict[str, list[tuple[float, float]] | None]\n",
    "    val: dict[str, list[tuple[float, float]] | None]\n",
    "    test: dict[str, list[tuple[float, float]] | None]\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(cls, csv_filename: str, pool_test_partitions: bool = True) -> \"DataSplit\":\n",
    "        df = pd.read_csv(csv_filename)\n",
    "        splits: dict[str, dict[str, list[tuple[float, float]]]] = {\n",
    "            \"train\": {},\n",
    "            \"val\": {},\n",
    "            \"test\": {},\n",
    "        }\n",
    "\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            for dataset in df[df[\"split\"] == split][\"dataset\"].unique():\n",
    "                dataset_rows = df[(df[\"split\"] == split) & (df[\"dataset\"] == dataset)]\n",
    "                if split == \"test\" and pool_test_partitions:\n",
    "                    first_start = dataset_rows[\"start\"].min()\n",
    "                    last_end = dataset_rows[\"end\"].max()\n",
    "                    splits[split][dataset] = [(first_start, last_end)]\n",
    "                else:\n",
    "                    splits[split][dataset] = [\n",
    "                        (row.start, row.end) for row in dataset_rows.itertuples()\n",
    "                    ]\n",
    "\n",
    "        return cls(**splits)\n",
    "\n",
    "print(\"âœ… DataSplit ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aec7db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… EmgRecording ç±»å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# EmgRecording: HDF5æ•°æ®è¯»å–\n",
    "# ==========================\n",
    "class EmgRecording:\n",
    "    def __init__(self, hdf5_path: Path, start_time: float = -np.inf, end_time: float = np.inf) -> None:\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "\n",
    "        self._file = h5py.File(self.hdf5_path, \"r\")\n",
    "        self.timeseries = self._file[\"data\"]\n",
    "        self.prompts = pd.read_hdf(hdf5_path, \"prompts\") if \"prompts\" in self._file.keys() else None\n",
    "\n",
    "        timestamps = self.timeseries[\"time\"]\n",
    "        assert (np.diff(timestamps) >= 0).all(), \"Timestamps are not monotonic\"\n",
    "        self.start_idx, self.end_idx = timestamps.searchsorted([self.start_time, self.end_time])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.end_idx - self.start_idx\n",
    "\n",
    "    def __getitem__(self, key: slice) -> np.ndarray:\n",
    "        if not isinstance(key, slice):\n",
    "            raise TypeError(\"Only slices are supported\")\n",
    "        start = key.start if key.start is not None else 0\n",
    "        stop = key.stop if key.stop is not None else len(self)\n",
    "        start += self.start_idx\n",
    "        stop += self.start_idx\n",
    "        return self.timeseries[start:stop]\n",
    "\n",
    "print(\"âœ… EmgRecording ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f07c1d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… WindowedEmgDataset ç±»å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# WindowedEmgDataset: æ»‘åŠ¨çª—å£æ•°æ®é›†\n",
    "# ==========================\n",
    "class WindowedEmgDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hdf5_path: Path,\n",
    "        start: float,\n",
    "        end: float,\n",
    "        transform: Callable[[np.ndarray, pd.DataFrame | None], dict[str, torch.Tensor]],\n",
    "        emg_augmentation: Callable[[torch.Tensor], torch.Tensor] | None = None,\n",
    "        window_length: int | None = 10_000,\n",
    "        stride: int | None = None,\n",
    "        jitter: bool = False,\n",
    "    ) -> None:\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.transform = transform\n",
    "        self.emg_augmentation = emg_augmentation\n",
    "        self.window_length = window_length\n",
    "        self.stride = stride\n",
    "        self.jitter = jitter\n",
    "\n",
    "        self.emg_recording = EmgRecording(self.hdf5_path, self.start, self.end)\n",
    "        self.window_length = window_length if window_length is not None else len(self.emg_recording)\n",
    "        self.stride = stride if stride is not None else self.window_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(max(len(self.emg_recording) - self.window_length, 0) // self.stride + 1)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict[str, torch.Tensor | pd.DataFrame | np.ndarray]:\n",
    "        start_sample = idx * self.stride\n",
    "\n",
    "        leftover = len(self.emg_recording) - (start_sample + self.window_length)\n",
    "        if leftover < 0:\n",
    "            raise IndexError(f\"Index {idx} out of bounds\")\n",
    "        if leftover > 0 and self.jitter:\n",
    "            start_sample += np.random.randint(0, min(self.stride, leftover))\n",
    "\n",
    "        start = start_sample\n",
    "        end = start_sample + self.window_length\n",
    "        timeseries = self.emg_recording[start:end]\n",
    "\n",
    "        datum = self.transform(timeseries, self.emg_recording.prompts)\n",
    "\n",
    "        if self.emg_augmentation is not None:\n",
    "            datum[\"emg\"] = self.emg_augmentation(datum[\"emg\"])\n",
    "\n",
    "        return datum\n",
    "\n",
    "print(\"âœ… WindowedEmgDataset ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c147556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… make_dataset å‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# make_dataset: æ‰¹é‡åˆ›å»ºæ•°æ®é›†\n",
    "# ==========================\n",
    "def make_dataset(\n",
    "    data_location: str,\n",
    "    partition_dict: dict[str, list[tuple[float, float]] | None],\n",
    "    transform: Callable[[np.ndarray, pd.DataFrame | None], dict[str, torch.Tensor]],\n",
    "    emg_augmentation: Callable[[torch.Tensor], torch.Tensor] | None,\n",
    "    window_length: int | None,\n",
    "    stride: int | None,\n",
    "    jitter: bool,\n",
    "    split_label: str | None = None,\n",
    ") -> ConcatDataset:\n",
    "    datasets: list[Dataset] = []\n",
    "    for dataset, partitions in tqdm(\n",
    "        partition_dict.items(), desc=f\"[setup] Loading datasets for split {split_label}\"\n",
    "    ):\n",
    "        if partitions is None:\n",
    "            partitions = [(-np.inf, np.inf)]\n",
    "\n",
    "        dataset_path = get_full_dataset_path(data_location, dataset)\n",
    "        if not dataset_path.exists():\n",
    "            continue\n",
    "\n",
    "        for start, end in partitions:\n",
    "            if window_length is not None:\n",
    "                partition_samples = (end - start) * EMG_SAMPLE_RATE\n",
    "                if partition_samples < window_length:\n",
    "                    continue\n",
    "\n",
    "            datasets.append(\n",
    "                WindowedEmgDataset(\n",
    "                    dataset_path,\n",
    "                    start=start,\n",
    "                    end=end,\n",
    "                    transform=transform,\n",
    "                    window_length=window_length,\n",
    "                    stride=stride,\n",
    "                    jitter=jitter,\n",
    "                    emg_augmentation=emg_augmentation,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return ConcatDataset(datasets)\n",
    "\n",
    "print(\"âœ… make_dataset å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51bb5757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RotationAugmentation ç±»å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# RotationAugmentation: é€šé“æ—‹è½¬å¢å¼º\n",
    "# ==========================\n",
    "@dataclass\n",
    "class RotationAugmentation:\n",
    "    rotation: int = 1\n",
    "\n",
    "    def __call__(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        rotation = np.random.choice(np.arange(-self.rotation, self.rotation + 1))\n",
    "        return torch.roll(data, rotation, dims=-1)\n",
    "\n",
    "print(\"âœ… RotationAugmentation ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0bfea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DiscreteGesturesTransform ç±»å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# DiscreteGesturesTransform: è„‰å†²ç›®æ ‡è½¬æ¢\n",
    "# ==========================\n",
    "@dataclass\n",
    "class DiscreteGesturesTransform:\n",
    "    pulse_window: list[float]\n",
    "\n",
    "    def __call__(self, timeseries: np.ndarray, prompts: pd.DataFrame | None) -> dict[str, torch.Tensor]:\n",
    "        assert prompts is not None\n",
    "\n",
    "        tlim = (timeseries[\"time\"][0], timeseries[\"time\"][-1])\n",
    "        prompts = prompts[prompts[\"time\"].between(*tlim)]\n",
    "        prompts = prompts[prompts[\"name\"].isin([g.name for g in GestureType])]\n",
    "\n",
    "        targets = self.gesture_times_to_targets(\n",
    "            timeseries[\"time\"],\n",
    "            prompts[\"time\"],\n",
    "            prompts[\"name\"].map({g.name: g.value for g in GestureType}),\n",
    "        )\n",
    "\n",
    "        emg = torch.from_numpy(timeseries[\"emg\"].T).float()\n",
    "        return {\"emg\": emg, \"targets\": targets}\n",
    "\n",
    "    def gesture_times_to_targets(\n",
    "        self,\n",
    "        times: np.ndarray,\n",
    "        event_start_times: np.ndarray,\n",
    "        event_ids: pd.Series,\n",
    "    ) -> torch.Tensor:\n",
    "        num_timesteps = len(times)\n",
    "        duration = times[-1] - times[0]\n",
    "        sampling_freq = int(num_timesteps / duration)\n",
    "\n",
    "        event_ids = event_ids.to_numpy()\n",
    "        event_time_indices = np.searchsorted(times, event_start_times)\n",
    "\n",
    "        pulse = torch.zeros(len(GestureType), num_timesteps, dtype=torch.float32)\n",
    "\n",
    "        valid_events = (event_time_indices > 0) & (event_time_indices < num_timesteps)\n",
    "        valid_indices = np.where(valid_events)[0]\n",
    "\n",
    "        for idx in valid_indices:\n",
    "            event_start = event_time_indices[idx]\n",
    "            event_id = event_ids[idx]\n",
    "\n",
    "            start_offset = int(self.pulse_window[0] * sampling_freq)\n",
    "            end_offset = int(self.pulse_window[1] * sampling_freq)\n",
    "\n",
    "            start_idx = max(0, event_start + start_offset)\n",
    "            end_idx = min(num_timesteps, event_start + end_offset)\n",
    "\n",
    "            if start_idx < end_idx:\n",
    "                pulse[event_id, start_idx:end_idx] = 1.0\n",
    "\n",
    "        return pulse\n",
    "\n",
    "print(\"âœ… DiscreteGesturesTransform ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d22be8",
   "metadata": {},
   "source": [
    "## ğŸ¤– æ­¥éª¤4ï¼šæ¨¡å‹å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca43a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ReinhardCompression ç±»å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# ReinhardCompression: ä¿¡å·å‹ç¼©\n",
    "# ==========================\n",
    "class ReinhardCompression(nn.Module):\n",
    "    def __init__(self, range: float, midpoint: float) -> None:\n",
    "        super().__init__()\n",
    "        self.range = range\n",
    "        self.midpoint = midpoint\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return self.range * inputs / (self.midpoint + torch.abs(inputs))\n",
    "\n",
    "print(\"âœ… ReinhardCompression ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a3a882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DiscreteGesturesArchitecture æ¨¡å‹å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# DiscreteGesturesArchitecture: ä¸»æ¨¡å‹\n",
    "# ==========================\n",
    "class DiscreteGesturesArchitecture(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int = 16,\n",
    "        conv_output_channels: int = 512,\n",
    "        kernel_width: int = 21,\n",
    "        stride: int = 10,\n",
    "        lstm_hidden_size: int = 512,\n",
    "        lstm_num_layers: int = 3,\n",
    "        output_channels: int = 9,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.left_context = kernel_width - 1\n",
    "        self.stride = stride\n",
    "\n",
    "        self.compression = ReinhardCompression(range=64.0, midpoint=32.0)\n",
    "        self.conv_layer = nn.Conv1d(\n",
    "            input_channels,\n",
    "            conv_output_channels,\n",
    "            kernel_size=kernel_width,\n",
    "            stride=stride,\n",
    "            padding=self.left_context,\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=conv_output_channels,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=lstm_num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Linear(lstm_hidden_size, output_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, C, T)\n",
    "        x = self.compression(x)\n",
    "        x = self.conv_layer(x)  # (B, conv_ch, T')\n",
    "        x = x.permute(0, 2, 1)  # (B, T', conv_ch)\n",
    "        x, _ = self.lstm(x)  # (B, T', lstm_hidden)\n",
    "        x = self.fc_layer(x)  # (B, T', output_ch)\n",
    "        return x\n",
    "\n",
    "print(\"âœ… DiscreteGesturesArchitecture æ¨¡å‹å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8206241",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ­¥éª¤5ï¼šæ„å»ºDataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c1d01f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… build_dataloaders å‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "def build_dataloaders() -> tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    \"\"\"æ„å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•æ•°æ®åŠ è½½å™¨\"\"\"\n",
    "    \n",
    "    # ğŸ” æ£€æŸ¥CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "    if not os.path.exists(CSV_FILENAME):\n",
    "        print(f\"âš ï¸  CSVæ–‡ä»¶ä¸å­˜åœ¨: {CSV_FILENAME}\")\n",
    "        print(f\"   ä½¿ç”¨ç®€åŒ–æ¨¡å¼ï¼šç›´æ¥åŠ è½½å‰3ä¸ªHDF5æ–‡ä»¶\")\n",
    "        \n",
    "        # æŸ¥æ‰¾å¯ç”¨çš„HDF5æ–‡ä»¶\n",
    "        data_path = Path(DATA_LOCATION)\n",
    "        available = sorted([p.stem for p in data_path.glob(\"discrete_gestures*.hdf5\")])\n",
    "        \n",
    "        if not available:\n",
    "            raise RuntimeError(f\"âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶: {DATA_LOCATION}/discrete_gestures*.hdf5\")\n",
    "        \n",
    "        print(f\"âœ… æ‰¾åˆ° {len(available)} ä¸ªæ•°æ®æ–‡ä»¶\")\n",
    "        print(f\"   ä½¿ç”¨å‰3ä¸ªæ–‡ä»¶è¿›è¡Œæµ‹è¯•...\")\n",
    "        \n",
    "        # åˆ›å»ºç®€åŒ–çš„DataSplit\n",
    "        train_name = available[0]\n",
    "        val_name = available[1] if len(available) > 1 else available[0]\n",
    "        test_name = available[2] if len(available) > 2 else available[0]\n",
    "        \n",
    "        data_split = DataSplit(\n",
    "            train={train_name: None},\n",
    "            val={val_name: None},\n",
    "            test={test_name: None}\n",
    "        )\n",
    "    else:\n",
    "        # ä½¿ç”¨CSVåŠ è½½å®Œæ•´é…ç½®\n",
    "        print(f\"âœ… ä»CSVåŠ è½½æ•°æ®åˆ†å‰²é…ç½®: {CSV_FILENAME}\")\n",
    "        data_split = DataSplit.from_csv(CSV_FILENAME, pool_test_partitions=True)\n",
    "        \n",
    "        # è¿‡æ»¤ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼ˆä¿®å¤ï¼šä½¿ç”¨p.nameè€Œä¸æ˜¯p.stemï¼‰\n",
    "        existing = {p.name for p in Path(DATA_LOCATION).glob(\"*.hdf5\")}\n",
    "        data_split.train = {k: v for k, v in data_split.train.items() if k in existing}\n",
    "        data_split.val = {k: v for k, v in data_split.val.items() if k in existing}\n",
    "        data_split.test = {k: v for k, v in data_split.test.items() if k in existing}\n",
    "\n",
    "    print(f\"\\nğŸ“¦ æ•°æ®é›†åˆ’åˆ†:\")\n",
    "    print(f\"   è®­ç»ƒé›†: {len(data_split.train)} ä¸ªæ–‡ä»¶\")\n",
    "    print(f\"   éªŒè¯é›†: {len(data_split.val)} ä¸ªæ–‡ä»¶\")\n",
    "    print(f\"   æµ‹è¯•é›†: {len(data_split.test)} ä¸ªæ–‡ä»¶\")\n",
    "\n",
    "    # å®šä¹‰Transformå’ŒAugmentation\n",
    "    transform = DiscreteGesturesTransform(pulse_window=PULSE_WINDOW)\n",
    "    augmentation = RotationAugmentation(rotation=ROTATION_AUG)\n",
    "\n",
    "    # åˆ›å»ºæ•°æ®é›†\n",
    "    train_dataset = make_dataset(\n",
    "        data_location=DATA_LOCATION,\n",
    "        partition_dict=data_split.train,\n",
    "        transform=transform,\n",
    "        emg_augmentation=augmentation,\n",
    "        window_length=WINDOW_LENGTH,\n",
    "        stride=STRIDE,\n",
    "        jitter=True,\n",
    "        split_label=\"train\",\n",
    "    )\n",
    "\n",
    "    val_dataset = make_dataset(\n",
    "        data_location=DATA_LOCATION,\n",
    "        partition_dict=data_split.val,\n",
    "        transform=transform,\n",
    "        emg_augmentation=None,\n",
    "        window_length=WINDOW_LENGTH,\n",
    "        stride=STRIDE,\n",
    "        jitter=False,\n",
    "        split_label=\"val\",\n",
    "    )\n",
    "\n",
    "    test_dataset = make_dataset(\n",
    "        data_location=DATA_LOCATION,\n",
    "        partition_dict=data_split.test,\n",
    "        transform=transform,\n",
    "        emg_augmentation=None,\n",
    "        window_length=WINDOW_LENGTH,\n",
    "        stride=STRIDE,\n",
    "        jitter=False,\n",
    "        split_label=\"test\",\n",
    "    )\n",
    "\n",
    "    print(f\"\\nğŸ“Š æ•°æ®é›†å¤§å°:\")\n",
    "    print(f\"   è®­ç»ƒæ ·æœ¬: {len(train_dataset)} ä¸ªçª—å£\")\n",
    "    print(f\"   éªŒè¯æ ·æœ¬: {len(val_dataset)} ä¸ªçª—å£\")\n",
    "    print(f\"   æµ‹è¯•æ ·æœ¬: {len(test_dataset)} ä¸ªçª—å£\")\n",
    "\n",
    "    # åˆ›å»ºDataLoader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "print(\"âœ… build_dataloaders å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7603d006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "å¼€å§‹æ„å»ºæ•°æ®åŠ è½½å™¨...\n",
      "============================================================\n",
      "âœ… ä»CSVåŠ è½½æ•°æ®åˆ†å‰²é…ç½®: ./data/discrete_gestures_corpus.csv\n",
      "\n",
      "ğŸ“¦ æ•°æ®é›†åˆ’åˆ†:\n",
      "   è®­ç»ƒé›†: 80 ä¸ªæ–‡ä»¶\n",
      "   éªŒè¯é›†: 10 ä¸ªæ–‡ä»¶\n",
      "   æµ‹è¯•é›†: 10 ä¸ªæ–‡ä»¶\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67595649978b44c09b10d686db63a466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split train:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54ed0a59a664117b07d203b4a5ceeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475513492f384153961f7c2e483cd0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split test:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š æ•°æ®é›†å¤§å°:\n",
      "   è®­ç»ƒæ ·æœ¬: 14024 ä¸ªçª—å£\n",
      "   éªŒè¯æ ·æœ¬: 1749 ä¸ªçª—å£\n",
      "   æµ‹è¯•æ ·æœ¬: 2509 ä¸ªçª—å£\n",
      "\n",
      "âœ… æ•°æ®åŠ è½½å™¨æ„å»ºå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ å¼€å§‹æ„å»ºæ•°æ®åŠ è½½å™¨\n",
    "print(\"=\" * 60)\n",
    "print(\"å¼€å§‹æ„å»ºæ•°æ®åŠ è½½å™¨...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_loader, val_loader, test_loader = build_dataloaders()\n",
    "\n",
    "print(\"\\nâœ… æ•°æ®åŠ è½½å™¨æ„å»ºå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd169a3",
   "metadata": {},
   "source": [
    "## ğŸ” æ­¥éª¤6ï¼šéªŒè¯æ•°æ®åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3937897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æµ‹è¯•æ•°æ®åŠ è½½...\n",
      "\n",
      "âœ… æˆåŠŸåŠ è½½ä¸€ä¸ªbatch:\n",
      "   EMGå½¢çŠ¶: torch.Size([32, 16, 16000])  # (batch, channels, time)\n",
      "   Targetså½¢çŠ¶: torch.Size([32, 9, 16000])  # (batch, gestures, time)\n",
      "   EMGæ•°æ®ç±»å‹: torch.float32\n",
      "   EMGæ•°å€¼èŒƒå›´: [-2082.49, 1662.22]\n",
      "   Targetsæ¿€æ´»ç‡: 0.0039\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•åŠ è½½ä¸€ä¸ªbatch\n",
    "print(\"ğŸ” æµ‹è¯•æ•°æ®åŠ è½½...\\n\")\n",
    "\n",
    "for batch in train_loader:\n",
    "    emg = batch[\"emg\"]\n",
    "    targets = batch[\"targets\"]\n",
    "    \n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½ä¸€ä¸ªbatch:\")\n",
    "    print(f\"   EMGå½¢çŠ¶: {emg.shape}  # (batch, channels, time)\")\n",
    "    print(f\"   Targetså½¢çŠ¶: {targets.shape}  # (batch, gestures, time)\")\n",
    "    print(f\"   EMGæ•°æ®ç±»å‹: {emg.dtype}\")\n",
    "    print(f\"   EMGæ•°å€¼èŒƒå›´: [{emg.min():.2f}, {emg.max():.2f}]\")\n",
    "    print(f\"   Targetsæ¿€æ´»ç‡: {(targets > 0).float().mean():.4f}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95ea6a",
   "metadata": {},
   "source": [
    "## ğŸ“ æ­¥éª¤7ï¼šè®­ç»ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8cd6895c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: cpu\n",
      "\n",
      "ğŸ“Š æ¨¡å‹ä¿¡æ¯:\n",
      "   æ€»å‚æ•°é‡: 6,480,905\n",
      "   å¯è®­ç»ƒå‚æ•°: 6,480,905\n",
      "   æ¨¡å‹å¤§å°: 24.72 MB (fp32)\n",
      "\n",
      "âœ… ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨å·²é…ç½®\n",
      "   åˆå§‹å­¦ä¹ ç‡: 0.0005\n",
      "   Warmupè½®æ•°: 5\n"
     ]
    }
   ],
   "source": [
    "# è®¾å¤‡é…ç½®\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = DiscreteGesturesArchitecture(output_channels=len(GestureType)).to(device)\n",
    "\n",
    "# ç»Ÿè®¡å‚æ•°é‡\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nğŸ“Š æ¨¡å‹ä¿¡æ¯:\")\n",
    "print(f\"   æ€»å‚æ•°é‡: {total_params:,}\")\n",
    "print(f\"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}\")\n",
    "print(f\"   æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (fp32)\")\n",
    "\n",
    "# ä¼˜åŒ–å™¨\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=WARMUP_START_FACTOR,\n",
    "    end_factor=WARMUP_END_FACTOR,\n",
    "    total_iters=WARMUP_TOTAL_EPOCHS,\n",
    ")\n",
    "\n",
    "multistep_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=LR_SCHEDULER_MILESTONES,\n",
    "    gamma=LR_SCHEDULER_FACTOR,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ChainedScheduler(\n",
    "    [warmup_scheduler, multistep_scheduler]\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨å·²é…ç½®\")\n",
    "print(f\"   åˆå§‹å­¦ä¹ ç‡: {LEARNING_RATE}\")\n",
    "print(f\"   Warmupè½®æ•°: {WARMUP_TOTAL_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ccbcac",
   "metadata": {},
   "source": [
    "## ğŸ‹ï¸ æ­¥éª¤8ï¼šè®­ç»ƒå¾ªç¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "afc12fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è®­ç»ƒ/è¯„ä¼°å‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰æŸå¤±å‡½æ•°å’Œè®­ç»ƒå‡½æ•°\n",
    "def train_one_epoch(model, train_loader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    for step, batch in enumerate(pbar, 1):\n",
    "        emg = batch[\"emg\"].to(device)  # (B, C, T)\n",
    "        targets = batch[\"targets\"].to(device)  # (B, 9, T)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        logits = model(emg)  # (B, T', 9)\n",
    "        \n",
    "        # è°ƒæ•´targetså½¢çŠ¶ä»¥åŒ¹é…è¾“å‡º\n",
    "        targets = targets.permute(0, 2, 1)  # (B, T, 9)\n",
    "        \n",
    "        # å¦‚æœæ—¶é—´ç»´åº¦ä¸åŒ¹é…ï¼Œè¿›è¡Œæ’å€¼\n",
    "        if logits.shape[1] != targets.shape[1]:\n",
    "            targets = torch.nn.functional.interpolate(\n",
    "                targets.permute(0, 2, 1),  # (B, 9, T)\n",
    "                size=logits.shape[1],\n",
    "                mode='nearest'\n",
    "            ).permute(0, 2, 1)  # (B, T', 9)\n",
    "        \n",
    "        # BCEæŸå¤±\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, reduction='mean'\n",
    "        )\n",
    "        \n",
    "        # åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "        \n",
    "        # æ¢¯åº¦è£å‰ª\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP_VAL)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_count += 1\n",
    "        \n",
    "        # æ›´æ–°è¿›åº¦æ¡\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        if step % LOG_EVERY == 0:\n",
    "            avg_loss = total_loss / total_count\n",
    "            print(f\"  Step {step}/{len(train_loader)}, Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    return total_loss / max(total_count, 1)\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            emg = batch[\"emg\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "            \n",
    "            logits = model(emg)\n",
    "            targets = targets.permute(0, 2, 1)\n",
    "            \n",
    "            if logits.shape[1] != targets.shape[1]:\n",
    "                targets = torch.nn.functional.interpolate(\n",
    "                    targets.permute(0, 2, 1),\n",
    "                    size=logits.shape[1],\n",
    "                    mode='nearest'\n",
    "                ).permute(0, 2, 1)\n",
    "            \n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                logits, targets, reduction='mean'\n",
    "            )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_count += 1\n",
    "    \n",
    "    return total_loss / max(total_count, 1)\n",
    "\n",
    "print(\"âœ… è®­ç»ƒ/è¯„ä¼°å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0785de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "å¼€å§‹è®­ç»ƒæ¨¡å‹...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 1/1\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a47cc3ab1f74126915b44ff276ceb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 10/439, Loss: 0.696162\n",
      "  Step 20/439, Loss: 0.696045\n",
      "  Step 30/439, Loss: 0.695923\n",
      "  Step 40/439, Loss: 0.695810\n",
      "  Step 50/439, Loss: 0.695703\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ å¼€å§‹è®­ç»ƒ\n",
    "print(\"=\" * 60)\n",
    "print(\"å¼€å§‹è®­ç»ƒæ¨¡å‹...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_val = math.inf\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS + 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch}/{MAX_EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, device, epoch)\n",
    "    \n",
    "    # éªŒè¯\n",
    "    val_loss = evaluate(model, val_loader, device)\n",
    "    \n",
    "    # æ›´æ–°å­¦ä¹ ç‡\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Epoch {epoch} ç»“æœ:\")\n",
    "    print(f\"   è®­ç»ƒæŸå¤±: {train_loss:.6f}\")\n",
    "    print(f\"   éªŒè¯æŸå¤±: {val_loss:.6f}\")\n",
    "    print(f\"   å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        ckpt_path = os.path.join(\"logs\", \"best_discrete_gestures.pt\")\n",
    "        torch.save({\"model\": model.state_dict()}, ckpt_path)\n",
    "        print(f\"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°: {ckpt_path}\")\n",
    "\n",
    "# æµ‹è¯•\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "test_loss = evaluate(model, test_loader, device)\n",
    "print(f\"\\nğŸ“Š æµ‹è¯•æŸå¤±: {test_loss:.6f}\")\n",
    "\n",
    "print(\"\\nğŸ‰ è®­ç»ƒå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cfd543",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ­¥éª¤9ï¼šç»“æœå¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58beb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# è·å–ä¸€ä¸ªæµ‹è¯•æ ·æœ¬\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        emg = batch[\"emg\"].to(device)\n",
    "        targets = batch[\"targets\"].to(device)\n",
    "        \n",
    "        # æ¨¡å‹é¢„æµ‹\n",
    "        logits = model(emg)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # å–ç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "        emg_sample = emg[0].cpu().numpy()  # (16, T)\n",
    "        targets_sample = targets[0].cpu().numpy()  # (9, T)\n",
    "        probs_sample = probs[0].cpu().numpy()  # (T', 9)\n",
    "        \n",
    "        break\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(11, 1, figsize=(15, 12), sharex=True)\n",
    "fig.suptitle('Metaè®­ç»ƒæµç¨‹éªŒè¯ - é¢„æµ‹ç»“æœ', fontsize=16, fontweight='bold')\n",
    "\n",
    "time_s = np.arange(emg_sample.shape[1]) / EMG_SAMPLE_RATE\n",
    "time_pred = np.arange(probs_sample.shape[0]) / EMG_SAMPLE_RATE * 10  # è¿‘ä¼¼\n",
    "\n",
    "# EMGä¿¡å·ï¼ˆæ˜¾ç¤º2ä¸ªé€šé“ï¼‰\n",
    "axes[0].plot(time_s, emg_sample[0], label='é€šé“0', linewidth=0.5, alpha=0.7)\n",
    "axes[0].plot(time_s, emg_sample[1], label='é€šé“1', linewidth=0.5, alpha=0.7)\n",
    "axes[0].set_ylabel('EMG', fontsize=9)\n",
    "axes[0].legend(loc='upper right', fontsize=8)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# 9ä¸ªæ‰‹åŠ¿çš„é¢„æµ‹\n",
    "gesture_names = [g.name for g in GestureType]\n",
    "for i in range(9):\n",
    "    ax = axes[i+1]\n",
    "    \n",
    "    # çœŸå®æ ‡ç­¾\n",
    "    ax.fill_between(time_s[:targets_sample.shape[1]], 0, targets_sample[i], \n",
    "                    color='blue', alpha=0.3, label='çœŸå®')\n",
    "    \n",
    "    # é¢„æµ‹æ¦‚ç‡\n",
    "    ax.plot(time_pred, probs_sample[:, i], \n",
    "           color='red', linewidth=1.5, label='é¢„æµ‹')\n",
    "    \n",
    "    ax.axhline(0.5, color='gray', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "    ax.set_ylabel(gesture_names[i].replace('_', '\\n'), \n",
    "                 fontsize=7, rotation=0, ha='right', va='center')\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "axes[-1].set_xlabel('æ—¶é—´ (ç§’)', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… å¯è§†åŒ–å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aac494",
   "metadata": {},
   "source": [
    "## ğŸ¯ æ€»ç»“\n",
    "\n",
    "### âœ… éªŒè¯å®Œæˆçš„åŠŸèƒ½\n",
    "\n",
    "1. **æ•°æ®åŠ è½½æµç¨‹**ï¼š\n",
    "   - âœ… DataSplit - CSVé…ç½®è¯»å–\n",
    "   - âœ… WindowedEmgDataset - æ»‘åŠ¨çª—å£åˆ‡åˆ†\n",
    "   - âœ… EmgRecording - HDF5æ•°æ®è¯»å–\n",
    "   - âœ… æ—¶é—´åˆ†åŒºï¼ˆpartitionï¼‰æ”¯æŒ\n",
    "\n",
    "2. **æ•°æ®å¢å¼º**ï¼š\n",
    "   - âœ… RotationAugmentation - é€šé“æ—‹è½¬\n",
    "   - âœ… Jitter - è®­ç»ƒæ—¶çª—å£éšæœºåç§»\n",
    "\n",
    "3. **æ ‡ç­¾è½¬æ¢**ï¼š\n",
    "   - âœ… DiscreteGesturesTransform - è„‰å†²ç›®æ ‡ç”Ÿæˆ\n",
    "   - âœ… äº‹ä»¶æ—¶é—´ â†’ äºŒå€¼è„‰å†²çŸ©é˜µ\n",
    "\n",
    "4. **æ¨¡å‹è®­ç»ƒ**ï¼š\n",
    "   - âœ… ReinhardCompression - ä¿¡å·å‹ç¼©\n",
    "   - âœ… DiscreteGesturesArchitecture - LSTMä¸»æ¨¡å‹\n",
    "   - âœ… BCEæŸå¤± + æ¢¯åº¦è£å‰ª\n",
    "   - âœ… å­¦ä¹ ç‡è°ƒåº¦ï¼ˆWarmup + MultiStepï¼‰\n",
    "\n",
    "### ğŸš€ åç»­æ­¥éª¤\n",
    "\n",
    "1. **ç§»æ¤åˆ° myEmg.ipynb**ï¼š\n",
    "   - æ›¿æ¢ç°æœ‰çš„ç®€åŒ–æ•°æ®åŠ è½½\n",
    "   - ä½¿ç”¨å®Œæ•´çš„Metaè®­ç»ƒæµç¨‹\n",
    "   - ä¿ç•™çŸ¥è¯†è’¸é¦å’Œé‡åŒ–éƒ¨åˆ†\n",
    "\n",
    "2. **å®Œæ•´æ•°æ®è®­ç»ƒ**ï¼š\n",
    "   - å¢åŠ  MAX_EPOCHS åˆ° 250\n",
    "   - ä½¿ç”¨å…¨éƒ¨100ä¸ªHDF5æ–‡ä»¶\n",
    "   - é¢„è®¡è®­ç»ƒæ—¶é—´ï¼š2-4å°æ—¶ï¼ˆGPUï¼‰\n",
    "\n",
    "3. **ç²¾åº¦å¯¹æ¯”**ï¼š\n",
    "   - ç›®æ ‡ï¼šå¤ç°Metaè®ºæ–‡çš„CLER â‰ˆ 0.18\n",
    "   - å¯¹æ¯”ç®€åŒ–ç‰ˆçš„20%å‡†ç¡®ç‡\n",
    "\n",
    "---\n",
    "\n",
    "**æµ‹è¯•æˆåŠŸï¼å¯ä»¥æ”¾å¿ƒç§»æ¤åˆ°çŸ¥è¯†è’¸é¦æµç¨‹ä¸­ã€‚**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

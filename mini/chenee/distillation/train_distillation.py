#!/usr/bin/env python3
"""
çŸ¥è¯†è’¸é¦è®­ç»ƒè„šæœ¬

ä½¿ç”¨é¢„è®­ç»ƒçš„Teacheræ¨¡å‹ï¼ˆMetaå¤§æ¨¡å‹ï¼‰è’¸é¦åˆ°è½»é‡çº§Studentæ¨¡å‹

ä½¿ç”¨æ–¹æ³•:
    python train_distillation.py --teacher_checkpoint ../logs/best_discrete_gestures.pt
"""

import argparse
from pathlib import Path
import sys

import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor

# æ·»åŠ è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent.parent.parent))

from generic_neuromotor_interface.networks import DiscreteGesturesArchitecture
from generic_neuromotor_interface.data_module import EmgDataModule
from student_network import StudentDiscreteGesturesArchitecture
from distillation_module import DistillationModule


def load_teacher_model(checkpoint_path: str) -> DiscreteGesturesArchitecture:
    """
    åŠ è½½é¢„è®­ç»ƒçš„Teacheræ¨¡å‹
    
    Parameters
    ----------
    checkpoint_path : str
        Teacheræ¨¡å‹æƒé‡è·¯å¾„ï¼ˆ.ptæˆ–.ckptæ–‡ä»¶ï¼‰
        
    Returns
    -------
    teacher : DiscreteGesturesArchitecture
        åŠ è½½æƒé‡åçš„Teacheræ¨¡å‹
    """
    print(f"\nğŸ“‚ åŠ è½½Teacheræ¨¡å‹: {checkpoint_path}")
    
    # åˆ›å»ºTeacherç½‘ç»œ
    teacher = DiscreteGesturesArchitecture()
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
    if 'state_dict' in checkpoint:
        # Lightning checkpointæ ¼å¼
        state_dict = checkpoint['state_dict']
        # ç§»é™¤'network.'å‰ç¼€
        state_dict = {k.replace('network.', ''): v for k, v in state_dict.items() 
                     if k.startswith('network.')}
    else:
        # ç›´æ¥çš„state_dict
        state_dict = checkpoint
    
    teacher.load_state_dict(state_dict)
    teacher.eval()
    
    print(f"âœ… Teacheræ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   å‚æ•°é‡: {sum(p.numel() for p in teacher.parameters()):,}")
    
    return teacher


def create_student_model() -> StudentDiscreteGesturesArchitecture:
    """åˆ›å»ºStudentæ¨¡å‹"""
    print("\nğŸ“ åˆ›å»ºStudentæ¨¡å‹")
    
    student = StudentDiscreteGesturesArchitecture(
        input_channels=16,
        conv_output_channels=128,  # Teacher: 512
        kernel_width=21,
        stride=10,
        lstm_hidden_size=256,      # Teacher: 512
        lstm_num_layers=2,         # Teacher: 3
        output_channels=9,
    )
    
    params = student.count_parameters()
    print(f"âœ… Studentæ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"   å‚æ•°é‡: {params['total']:,}")
    print(f"   - Conv: {params['conv']:,}")
    print(f"   - LSTM: {params['lstm']:,}")
    print(f"   - æŠ•å½±: {params['projection']:,}")
    
    return student


def setup_data_module(
    data_dir: str,
    split_csv: str,
    batch_size: int = 16,
    window_duration: float = 0.25,
    window_stride: int = 40,
) -> EmgDataModule:
    """
    è®¾ç½®æ•°æ®æ¨¡å—
    
    Parameters
    ----------
    data_dir : str
        æ•°æ®ç›®å½•è·¯å¾„
    split_csv : str
        æ•°æ®åˆ’åˆ†CSVè·¯å¾„
    batch_size : int
        æ‰¹æ¬¡å¤§å°
    window_duration : float
        çª—å£æ—¶é•¿ï¼ˆç§’ï¼‰
    window_stride : int
        çª—å£æ­¥é•¿ï¼ˆæ ·æœ¬æ•°ï¼‰
        
    Returns
    -------
    data_module : EmgDataModule
        é…ç½®å¥½çš„æ•°æ®æ¨¡å—
    """
    print(f"\nğŸ“Š è®¾ç½®æ•°æ®æ¨¡å—")
    print(f"   æ•°æ®ç›®å½•: {data_dir}")
    print(f"   åˆ’åˆ†æ–‡ä»¶: {split_csv}")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    data_module = EmgDataModule(
        task="discrete_gestures",
        data_dir=data_dir,
        split_csv=split_csv,
        batch_size=batch_size,
        window_duration=window_duration,
        window_stride=window_stride,
        num_workers=4,
    )
    
    return data_module


def train_distillation(
    teacher_checkpoint: str,
    data_dir: str,
    split_csv: str,
    output_dir: str = "./distillation_output",
    batch_size: int = 16,
    max_epochs: int = 100,
    learning_rate: float = 1e-3,
    temperature: float = 3.0,
    alpha: float = 0.5,
    gpus: int = 1,
):
    """
    æ‰§è¡ŒçŸ¥è¯†è’¸é¦è®­ç»ƒ
    
    Parameters
    ----------
    teacher_checkpoint : str
        Teacheræ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
    data_dir : str
        æ•°æ®ç›®å½•
    split_csv : str
        æ•°æ®åˆ’åˆ†CSV
    output_dir : str
        è¾“å‡ºç›®å½•
    batch_size : int
        æ‰¹æ¬¡å¤§å°
    max_epochs : int
        æœ€å¤§è®­ç»ƒè½®æ•°
    learning_rate : float
        å­¦ä¹ ç‡
    temperature : float
        è’¸é¦æ¸©åº¦ï¼ˆæ¨è2-5ï¼‰
    alpha : float
        è’¸é¦æŸå¤±æƒé‡ï¼ˆ0-1ï¼‰
    gpus : int
        GPUæ•°é‡
    """
    
    print("\n" + "="*60)
    print("å¼€å§‹çŸ¥è¯†è’¸é¦è®­ç»ƒ")
    print("="*60)
    
    # 1. åŠ è½½Teacheræ¨¡å‹
    teacher = load_teacher_model(teacher_checkpoint)
    
    # 2. åˆ›å»ºStudentæ¨¡å‹
    student = create_student_model()
    
    # æ¯”è¾ƒå‚æ•°é‡
    teacher_params = sum(p.numel() for p in teacher.parameters())
    student_params = sum(p.numel() for p in student.parameters())
    print(f"\nğŸ“Š æ¨¡å‹å¯¹æ¯”:")
    print(f"   Teacher: {teacher_params:,} å‚æ•°")
    print(f"   Student: {student_params:,} å‚æ•°")
    print(f"   å‹ç¼©æ¯”: {student_params/teacher_params:.1%}")
    
    # 3. è®¾ç½®æ•°æ®æ¨¡å—
    data_module = setup_data_module(
        data_dir=data_dir,
        split_csv=split_csv,
        batch_size=batch_size,
    )
    
    # 4. åˆ›å»ºè’¸é¦æ¨¡å—
    print(f"\nğŸ”¥ åˆ›å»ºè’¸é¦è®­ç»ƒæ¨¡å—")
    print(f"   æ¸©åº¦: {temperature}")
    print(f"   Alpha: {alpha} (distill={alpha}, task={1-alpha})")
    
    optimizer = torch.optim.AdamW(student.parameters(), lr=learning_rate)
    
    distill_module = DistillationModule(
        student_network=student,
        teacher_network=teacher,
        optimizer=optimizer,
        learning_rate=learning_rate,
        lr_scheduler_milestones=[60, 80],
        lr_scheduler_factor=0.1,
        warmup_start_factor=0.1,
        warmup_end_factor=1.0,
        warmup_total_epochs=5,
        gradient_clip_val=1.0,
        temperature=temperature,
        alpha=alpha,
    )
    
    # 5. è®¾ç½®Callbacks
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    checkpoint_callback = ModelCheckpoint(
        dirpath=output_path,
        filename='student-{epoch:02d}-{val_loss:.4f}',
        monitor='val_loss',
        mode='min',
        save_top_k=3,
        save_last=True,
    )
    
    early_stop_callback = EarlyStopping(
        monitor='val_loss',
        patience=15,
        mode='min',
        verbose=True,
    )
    
    lr_monitor = LearningRateMonitor(logging_interval='epoch')
    
    # 6. åˆ›å»ºTrainer
    trainer = pl.Trainer(
        max_epochs=max_epochs,
        accelerator='gpu' if gpus > 0 else 'cpu',
        devices=gpus if gpus > 0 else 1,
        callbacks=[checkpoint_callback, early_stop_callback, lr_monitor],
        log_every_n_steps=10,
        gradient_clip_val=1.0,
        deterministic=False,
    )
    
    # 7. å¼€å§‹è®­ç»ƒ
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒï¼ˆæœ€å¤š{max_epochs}è½®ï¼‰")
    print(f"   è¾“å‡ºç›®å½•: {output_path}")
    
    trainer.fit(distill_module, datamodule=data_module)
    
    # 8. ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = output_path / "student_final.pt"
    torch.save(student.state_dict(), final_model_path)
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
    print(f"   æœ€ä½³æ¨¡å‹: {checkpoint_callback.best_model_path}")
    print(f"   æœ€ç»ˆæ¨¡å‹: {final_model_path}")
    
    return distill_module, trainer


def main():
    parser = argparse.ArgumentParser(description="çŸ¥è¯†è’¸é¦è®­ç»ƒè„šæœ¬")
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        "--teacher_checkpoint",
        type=str,
        required=True,
        help="Teacheræ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„",
    )
    parser.add_argument(
        "--data_dir",
        type=str,
        required=True,
        help="EMGæ•°æ®ç›®å½•",
    )
    parser.add_argument(
        "--split_csv",
        type=str,
        required=True,
        help="æ•°æ®åˆ’åˆ†CSVæ–‡ä»¶è·¯å¾„",
    )
    
    # å¯é€‰å‚æ•°
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./distillation_output",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./distillation_outputï¼‰",
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=16,
        help="æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤: 16ï¼‰",
    )
    parser.add_argument(
        "--max_epochs",
        type=int,
        default=100,
        help="æœ€å¤§è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤: 100ï¼‰",
    )
    parser.add_argument(
        "--learning_rate",
        type=float,
        default=1e-3,
        help="å­¦ä¹ ç‡ï¼ˆé»˜è®¤: 1e-3ï¼‰",
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=3.0,
        help="è’¸é¦æ¸©åº¦ï¼ˆé»˜è®¤: 3.0ï¼Œæ¨è2-5ï¼‰",
    )
    parser.add_argument(
        "--alpha",
        type=float,
        default=0.5,
        help="è’¸é¦æŸå¤±æƒé‡ï¼ˆé»˜è®¤: 0.5ï¼ŒèŒƒå›´0-1ï¼‰",
    )
    parser.add_argument(
        "--gpus",
        type=int,
        default=1,
        help="GPUæ•°é‡ï¼ˆé»˜è®¤: 1ï¼‰",
    )
    
    args = parser.parse_args()
    
    # æ‰§è¡Œè®­ç»ƒ
    train_distillation(
        teacher_checkpoint=args.teacher_checkpoint,
        data_dir=args.data_dir,
        split_csv=args.split_csv,
        output_dir=args.output_dir,
        batch_size=args.batch_size,
        max_epochs=args.max_epochs,
        learning_rate=args.learning_rate,
        temperature=args.temperature,
        alpha=args.alpha,
        gpus=args.gpus,
    )


if __name__ == "__main__":
    main()

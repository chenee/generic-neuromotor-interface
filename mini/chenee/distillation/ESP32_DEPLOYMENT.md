# ESP32éƒ¨ç½²æŒ‡å— - è¶…è½»é‡çº§æ‰‹åŠ¿è¯†åˆ«

é’ˆå¯¹ESP32ï¼ˆ~520KB RAMï¼‰çš„æ¨¡å‹éƒ¨ç½²å®Œæ•´æ–¹æ¡ˆ

## ğŸ¯ æ¨¡å‹é€‰æ‹©

### æ–¹æ¡ˆå¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | FP32å¤§å° | INT8å¤§å° | æ¨èè®¾å¤‡ |
|------|--------|----------|----------|---------|
| **ConvOnly** | ~8ä¸‡ | 320KB | **80KB** | âœ… ESP32 |
| **TinyStudent** | ~15ä¸‡ | 600KB | **150KB** | ESP32-S3 |
| **GRUStudent** | ~40ä¸‡ | 1.6MB | 400KB | æ ‘è“æ´¾ |
| Standard Student | ~60ä¸‡ | 2.4MB | 600KB | æ‰‹æœº/PC |

### ESP32æ¨èï¼šConvOnly + INT8

**ä¸ºä»€ä¹ˆé€‰æ‹©ConvOnlyï¼Ÿ**
- âœ… æœ€å°æ¨¡å‹ï¼ˆINT8ä»…80KBï¼‰
- âœ… æ— LSTMï¼Œæ— çŠ¶æ€ï¼Œå†…å­˜å ç”¨ä½
- âœ… å…¨å·ç§¯ï¼Œæ¨ç†é€Ÿåº¦å¿«
- âœ… æ˜“äºé‡åŒ–ï¼Œç²¾åº¦æŸå¤±å°

## ğŸ“‹ å®Œæ•´éƒ¨ç½²æµç¨‹

### Step 1: è®­ç»ƒè¶…è½»é‡çº§æ¨¡å‹

```bash
cd distillation

# 1. å…ˆéªŒè¯æ¨¡å‹ç»“æ„
python3 ultra_light_models.py

# 2. ä¿®æ”¹train_distillation.pyï¼Œæ›¿æ¢Studentæ¨¡å‹
# å°† StudentDiscreteGesturesArchitecture æ”¹ä¸º ConvOnlyStudentArchitecture
```

**ä¿®æ”¹è®­ç»ƒè„šæœ¬**ï¼š

```python
# åœ¨ train_distillation.py ä¸­
from ultra_light_models import ConvOnlyStudentArchitecture  # æ–°å¢

def create_student_model():
    # ä½¿ç”¨ConvOnlyæ¨¡å‹
    student = ConvOnlyStudentArchitecture(
        input_channels=16,
        hidden_channels=64,  # å¯ä»¥è°ƒæ•´ï¼š32/64/128
        output_channels=9,
    )
    return student
```

### Step 2: è®­ç»ƒè’¸é¦æ¨¡å‹

```bash
python3 train_distillation.py \
    --teacher_checkpoint ../../../../../logs/best_discrete_gestures.pt \
    --data_dir /path/to/emg_data \
    --split_csv /path/to/split.csv \
    --output_dir ./ultra_light_models \
    --max_epochs 100 \
    --temperature 4.0 \
    --alpha 0.6
```

**æ³¨æ„**ï¼šConvOnlyæ¨¡å‹æ›´ç®€å•ï¼Œå»ºè®®ï¼š
- æé«˜temperatureåˆ°4.0ï¼ˆæ›´æŸ”å’Œçš„è’¸é¦ï¼‰
- æé«˜alphaåˆ°0.6-0.7ï¼ˆæ›´ä¾èµ–Teacherï¼‰

### Step 3: é‡åŒ–ä¸ºINT8

```bash
# è¿è¡Œé‡åŒ–è„šæœ¬
python3 quantization_utils.py

# æˆ–è€…è‡ªå®šä¹‰é‡åŒ–
python3 << EOF
import torch
from ultra_light_models import ConvOnlyStudentArchitecture
from quantization_utils import quantize_model_dynamic

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
model = ConvOnlyStudentArchitecture()
model.load_state_dict(torch.load('ultra_light_models/student_final.pt'))

# é‡åŒ–
quantized = quantize_model_dynamic(
    model,
    output_path='convonly_int8.pt',
    qconfig_spec={torch.nn.Conv1d, torch.nn.Linear}
)

print("âœ… é‡åŒ–å®Œæˆï¼Œæ¨¡å‹å·²ç¼©å°4å€")
EOF
```

### Step 4: è½¬æ¢ä¸ºTFLite

```bash
# å®‰è£…è½¬æ¢å·¥å…·
pip install onnx onnx-tf tensorflow

# 1. å¯¼å‡ºONNX
python3 -c "
from quantization_utils import export_to_onnx_int8
import torch
from ultra_light_models import ConvOnlyStudentArchitecture

model = ConvOnlyStudentArchitecture()
model.load_state_dict(torch.load('convonly_int8.pt'))
export_to_onnx_int8(model, 'convonly_int8.onnx')
"

# 2. ONNX -> TensorFlow
onnx-tf convert -i convonly_int8.onnx -o convonly_tf

# 3. TensorFlow -> TFLite
python3 << EOF
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model('convonly_tf')

# INT8é‡åŒ–é…ç½®
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8

# è½¬æ¢
tflite_model = converter.convert()

# ä¿å­˜
with open('gesture_model.tflite', 'wb') as f:
    f.write(tflite_model)

print("âœ… TFLiteæ¨¡å‹ç”Ÿæˆå®Œæˆï¼")
EOF
```

### Step 5: ç”ŸæˆCæ•°ç»„ï¼ˆç”¨äºESP32ï¼‰

```bash
# å°†TFLiteæ¨¡å‹è½¬ä¸ºCå¤´æ–‡ä»¶
xxd -i gesture_model.tflite > gesture_model.h

# æŸ¥çœ‹å¤§å°
ls -lh gesture_model.tflite
# é¢„æœŸ: çº¦80-100KB
```

### Step 6: ESP32ä»£ç 

```cpp
// gesture_recognition.ino (Arduino IDE)

#include <TensorFlowLite_ESP32.h>
#include "gesture_model.h"

// TFLiteç›¸å…³
const tflite::Model* model = nullptr;
tflite::MicroInterpreter* interpreter = nullptr;
TfLiteTensor* input = nullptr;
TfLiteTensor* output = nullptr;

// å†…å­˜æ± ï¼ˆè°ƒæ•´å¤§å°ä»¥é€‚åº”æ¨¡å‹ï¼‰
constexpr int kTensorArenaSize = 100 * 1024;  // 100KB
alignas(16) uint8_t tensor_arena[kTensorArenaSize];

void setup() {
  Serial.begin(115200);
  
  // åŠ è½½æ¨¡å‹
  model = tflite::GetModel(gesture_model_tflite);
  
  if (model->version() != TFLITE_SCHEMA_VERSION) {
    Serial.println("æ¨¡å‹ç‰ˆæœ¬ä¸åŒ¹é…!");
    return;
  }
  
  // åˆ›å»ºè§£é‡Šå™¨
  static tflite::MicroMutableOpResolver<10> resolver;
  resolver.AddConv2D();
  resolver.AddReLU();
  resolver.AddQuantize();
  resolver.AddDequantize();
  // ... æ·»åŠ å…¶ä»–éœ€è¦çš„æ“ä½œ
  
  static tflite::MicroInterpreter static_interpreter(
    model, resolver, tensor_arena, kTensorArenaSize
  );
  interpreter = &static_interpreter;
  
  // åˆ†é…å†…å­˜
  if (interpreter->AllocateTensors() != kTfLiteOk) {
    Serial.println("å†…å­˜åˆ†é…å¤±è´¥!");
    return;
  }
  
  // è·å–è¾“å…¥è¾“å‡ºå¼ é‡
  input = interpreter->input(0);
  output = interpreter->output(0);
  
  Serial.println("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!");
  Serial.printf("è¾“å…¥shape: [%d, %d, %d]\n", 
    input->dims->data[0], 
    input->dims->data[1], 
    input->dims->data[2]
  );
}

void loop() {
  // 1. è¯»å–EMGæ•°æ®ï¼ˆå‡è®¾ä»ADCè¯»å–16é€šé“ï¼‰
  float emg_data[16][2000];
  read_emg_data(emg_data);
  
  // 2. å¡«å……è¾“å…¥å¼ é‡ï¼ˆINT8é‡åŒ–ï¼‰
  for (int c = 0; c < 16; c++) {
    for (int t = 0; t < 2000; t++) {
      // é‡åŒ–ï¼šfloat -> int8
      int8_t quantized = (int8_t)(emg_data[c][t] * input->params.scale + input->params.zero_point);
      input->data.int8[c * 2000 + t] = quantized;
    }
  }
  
  // 3. è¿è¡Œæ¨ç†
  unsigned long start = micros();
  if (interpreter->Invoke() != kTfLiteOk) {
    Serial.println("æ¨ç†å¤±è´¥!");
    return;
  }
  unsigned long elapsed = micros() - start;
  
  // 4. è¯»å–è¾“å‡ºï¼ˆ9ä¸ªæ‰‹åŠ¿çš„logitsï¼‰
  float gesture_probs[9];
  for (int i = 0; i < 9; i++) {
    // åé‡åŒ–ï¼šint8 -> float
    int8_t quantized_output = output->data.int8[i];
    gesture_probs[i] = (quantized_output - output->params.zero_point) * output->params.scale;
  }
  
  // 5. æ‰¾åˆ°æœ€å¯èƒ½çš„æ‰‹åŠ¿
  int max_idx = 0;
  float max_prob = gesture_probs[0];
  for (int i = 1; i < 9; i++) {
    if (gesture_probs[i] > max_prob) {
      max_prob = gesture_probs[i];
      max_idx = i;
    }
  }
  
  // 6. è¾“å‡ºç»“æœ
  const char* gestures[] = {
    "index_press", "index_release",
    "middle_press", "middle_release",
    "thumb_click", "thumb_down",
    "thumb_in", "thumb_out", "thumb_up"
  };
  
  Serial.printf("æ£€æµ‹åˆ°: %s (ç½®ä¿¡åº¦: %.2f)\n", gestures[max_idx], max_prob);
  Serial.printf("æ¨ç†æ—¶é—´: %lu us\n", elapsed);
  
  delay(100);
}
```

## ğŸ”§ ä¼˜åŒ–æŠ€å·§

### 1. è¿›ä¸€æ­¥å‡å°æ¨¡å‹

å¦‚æœ80KBè¿˜æ˜¯å¤ªå¤§ï¼š

```python
# ultra_light_models.py
class TinyConvOnlyArchitecture(nn.Module):
    def __init__(self):
        super().__init__()
        # æ›´å°‘é€šé“: 64 -> 32
        # ç§»é™¤ä¸€å±‚å·ç§¯
        # é¢„è®¡: ~4ä¸‡å‚æ•°ï¼ŒINT8çº¦40KB
```

### 2. å†…å­˜ä¼˜åŒ–

```cpp
// å‡å°tensor_arenaå¤§å°
constexpr int kTensorArenaSize = 80 * 1024;  // 80KB

// ä½¿ç”¨æµå¼æ¨ç†ï¼ˆåˆ†æ‰¹å¤„ç†é•¿æ—¶é—´åºåˆ—ï¼‰
```

### 3. é€Ÿåº¦ä¼˜åŒ–

```python
# ä½¿ç”¨æ›´å¤§çš„stride
stride = 20  # ä»10æ”¹ä¸º20ï¼Œè¾“å‡ºå‡åŠï¼Œé€Ÿåº¦ç¿»å€
```

## ğŸ“Š æ€§èƒ½é¢„æœŸ

### ConvOnly + INT8 on ESP32

- **æ¨¡å‹å¤§å°**: 80-100KB
- **RAMå ç”¨**: ~150KBï¼ˆåŒ…æ‹¬tensor arenaï¼‰
- **æ¨ç†æ—¶é—´**: 50-100msï¼ˆ1ç§’@2000Hzè¾“å…¥ï¼‰
- **å‡†ç¡®ç‡**: Teacherçš„70-80%ï¼ˆæƒè¡¡ï¼‰

### ç²¾åº¦æŸå¤±åˆ†æ

```
Teacher (650ä¸‡å‚æ•°):      å‡†ç¡®ç‡ 95%
â†“ è’¸é¦
Student (60ä¸‡å‚æ•°):       å‡†ç¡®ç‡ 90%
â†“ å‹ç¼©
TinyStudent (15ä¸‡å‚æ•°):   å‡†ç¡®ç‡ 85%
â†“ æè‡´å‹ç¼©
ConvOnly (8ä¸‡å‚æ•°):       å‡†ç¡®ç‡ 75-80%
â†“ é‡åŒ–INT8
ConvOnly INT8:            å‡†ç¡®ç‡ 75-78% (æŸå¤±<2%)
```

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: ESP32å†…å­˜ä¸å¤Ÿï¼Ÿ

```
æ–¹æ¡ˆ1: ä½¿ç”¨PSRAMï¼ˆESP32-WROVERï¼‰
æ–¹æ¡ˆ2: è¿›ä¸€æ­¥å‡å°hidden_channelsåˆ°32
æ–¹æ¡ˆ3: ä½¿ç”¨æµå¼æ¨ç†ï¼Œåˆ†æ®µå¤„ç†
```

### Q2: æ¨ç†å¤ªæ…¢ï¼Ÿ

```
æ–¹æ¡ˆ1: å¢å¤§strideï¼ˆ20æˆ–40ï¼‰
æ–¹æ¡ˆ2: å‡å°‘è¾“å…¥æ—¶é—´é•¿åº¦ï¼ˆ1ç§’æ”¹ä¸º0.5ç§’ï¼‰
æ–¹æ¡ˆ3: ä½¿ç”¨ESP32-S3ï¼ˆæ›´å¿«çš„CPUï¼‰
```

### Q3: ç²¾åº¦å¤ªä½ï¼Ÿ

```
æ–¹æ¡ˆ1: ç”¨TinyStudentä»£æ›¿ConvOnlyï¼ˆ15ä¸‡å‚æ•°ï¼‰
æ–¹æ¡ˆ2: å¢åŠ hidden_channelsåˆ°128
æ–¹æ¡ˆ3: ä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆéƒ¨åˆ†FP16ï¼‰
```

## ğŸ“ ä¸‹ä¸€æ­¥

1. **æµ‹è¯•ConvOnlyæ¨¡å‹**: `python3 ultra_light_models.py`
2. **å¼€å§‹è’¸é¦è®­ç»ƒ**: ä¿®æ”¹`train_distillation.py`ä½¿ç”¨ConvOnly
3. **é‡åŒ–æ¨¡å‹**: `python3 quantization_utils.py`
4. **è½¬æ¢ä¸ºTFLite**: æŒ‰ç…§Step 4æ“ä½œ
5. **ESP32éƒ¨ç½²**: æŒ‰ç…§Step 6ç¼–å†™ä»£ç 

ç¥éƒ¨ç½²é¡ºåˆ©ï¼ğŸš€

"""
å­¦ç”Ÿç½‘ç»œï¼šç¦»æ•£æ‰‹åŠ¿è¯†åˆ«çš„è½»é‡çº§æ¨¡å‹

ç›¸æ¯”Teacheræ¨¡å‹ï¼ˆ650ä¸‡å‚æ•°ï¼‰ï¼ŒStudentæ¨¡å‹çº¦60ä¸‡å‚æ•°ï¼ˆ~10%ï¼‰
é€‚åˆéƒ¨ç½²åˆ°èµ„æºå—é™çš„è®¾å¤‡ï¼ˆå¦‚å¾®æ§åˆ¶å™¨ã€ç§»åŠ¨ç«¯ï¼‰
"""

import torch
from torch import nn
import sys
from pathlib import Path

# å¯¼å…¥Teacheræ¨¡å‹çš„å‹ç¼©å±‚
sys.path.append(str(Path(__file__).parent.parent.parent.parent.parent))
from generic_neuromotor_interface.networks import ReinhardCompression


class StudentDiscreteGesturesArchitecture(nn.Module):
    """
    è½»é‡çº§ç¦»æ•£æ‰‹åŠ¿è¯†åˆ«ç½‘ç»œ
    
    ä¸Teacheræ¨¡å‹å¯¹æ¯”ï¼š
    - Convé€šé“æ•°ï¼š512 -> 128 (4å€å‹ç¼©)
    - LSTMå±‚æ•°ï¼š3 -> 2 (å‡å°‘1å±‚)
    - LSTMéšè—å•å…ƒï¼š512 -> 256 (2å€å‹ç¼©)
    - æ€»å‚æ•°é‡ï¼š~650ä¸‡ -> ~60ä¸‡ï¼ˆçº¦10%ï¼‰
    
    Parameters
    ----------
    input_channels : int
        è¾“å…¥EMGé€šé“æ•°ï¼ˆé»˜è®¤16ï¼‰
    conv_output_channels : int
        å·ç§¯è¾“å‡ºé€šé“æ•°ï¼ˆé»˜è®¤128ï¼ŒTeacherä¸º512ï¼‰
    kernel_width : int
        å·ç§¯æ ¸å®½åº¦ï¼ˆä¿æŒ21ï¼‰
    stride : int
        å·ç§¯æ­¥é•¿ï¼ˆä¿æŒ10ï¼‰
    lstm_hidden_size : int
        LSTMéšè—å•å…ƒæ•°ï¼ˆé»˜è®¤256ï¼ŒTeacherä¸º512ï¼‰
    lstm_num_layers : int
        LSTMå±‚æ•°ï¼ˆé»˜è®¤2ï¼ŒTeacherä¸º3ï¼‰
    output_channels : int
        è¾“å‡ºæ‰‹åŠ¿ç±»åˆ«æ•°ï¼ˆ9ç§æ‰‹åŠ¿ï¼‰
    """

    def __init__(
        self,
        input_channels: int = 16,
        conv_output_channels: int = 128,  # Teacher: 512
        kernel_width: int = 21,
        stride: int = 10,
        lstm_hidden_size: int = 256,      # Teacher: 512
        lstm_num_layers: int = 2,         # Teacher: 3
        output_channels: int = 9,
    ) -> None:
        super().__init__()

        self.lstm_num_layers = lstm_num_layers
        self.lstm_hidden_size = lstm_hidden_size
        self.left_context = kernel_width - 1
        self.stride = stride

        # ============ ä¸Teacherç›¸åŒçš„å±‚ ============
        # ReinhardåŠ¨æ€èŒƒå›´å‹ç¼©
        self.compression = ReinhardCompression(range=64.0, midpoint=32.0)

        # Conv1då±‚ï¼ˆé€šé“æ•°å‡å°‘ï¼‰
        self.conv_layer = nn.Conv1d(
            input_channels,
            conv_output_channels,
            kernel_size=kernel_width,
            stride=stride,
        )

        # ReLUæ¿€æ´»
        self.relu = nn.ReLU()

        # Dropoutï¼ˆä¿æŒ0.1ï¼‰
        self.dropout = nn.Dropout(p=0.1)

        # LayerNorm
        self.post_conv_layer_norm = nn.LayerNorm(normalized_shape=conv_output_channels)

        # ============ ç²¾ç®€åçš„LSTM ============
        # LSTMå±‚æ•°å‡å°‘åˆ°2å±‚ï¼Œéšè—å•å…ƒå‡å°‘åˆ°256
        self.lstm = nn.LSTM(
            input_size=conv_output_channels,
            hidden_size=lstm_hidden_size,
            num_layers=lstm_num_layers,
            batch_first=True,
            dropout=0.1 if lstm_num_layers > 1 else 0.0,  # å•å±‚LSTMä¸ç”¨dropout
        )

        # LayerNorm
        self.post_lstm_layer_norm = nn.LayerNorm(normalized_shape=lstm_hidden_size)

        # è¾“å‡ºæŠ•å½±å±‚
        self.projection = nn.Linear(lstm_hidden_size, output_channels)

    def forward(self, inputs: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­ï¼ˆä¸Teacherç»“æ„å®Œå…¨ä¸€è‡´ï¼‰

        Parameters
        ----------
        inputs : torch.Tensor
            è¾“å…¥EMGæ•°æ®ï¼Œshape=(batch_size, 16, sequence_length)

        Returns
        -------
        output : torch.Tensor
            æ‰‹åŠ¿é¢„æµ‹logitsï¼Œshape=(batch_size, 9, downsampled_length)
        """

        # Reinhardå‹ç¼©
        x = self.compression(inputs)

        # å·ç§¯å±‚
        x = self.conv_layer(x)
        x = self.relu(x)
        x = self.dropout(x)

        # LayerNorm (éœ€è¦è½¬ç½®)
        x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
        x = self.post_conv_layer_norm(x)

        # LSTM
        x, _ = self.lstm(x)

        # LayerNorm
        x = self.post_lstm_layer_norm(x)

        # è¾“å‡ºæŠ•å½±
        x = self.projection(x)
        x = x.permute(0, 2, 1)  # (B, T, 9) -> (B, 9, T)

        return x

    def count_parameters(self) -> dict:
        """ç»Ÿè®¡æ¨¡å‹å‚æ•°é‡"""
        total = sum(p.numel() for p in self.parameters())
        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        # åˆ†å±‚ç»Ÿè®¡
        conv_params = sum(p.numel() for p in self.conv_layer.parameters())
        lstm_params = sum(p.numel() for p in self.lstm.parameters())
        proj_params = sum(p.numel() for p in self.projection.parameters())
        
        return {
            "total": total,
            "trainable": trainable,
            "conv": conv_params,
            "lstm": lstm_params,
            "projection": proj_params,
        }


if __name__ == "__main__":
    # æµ‹è¯•å­¦ç”Ÿç½‘ç»œ
    print("="*60)
    print("Student Network Architecture")
    print("="*60)
    
    # åˆ›å»ºæ¨¡å‹
    student = StudentDiscreteGesturesArchitecture()
    
    # ç»Ÿè®¡å‚æ•°
    params = student.count_parameters()
    print(f"\nğŸ“Š å‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {params['total']:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {params['trainable']:,}")
    print(f"  Convå±‚: {params['conv']:,}")
    print(f"  LSTMå±‚: {params['lstm']:,}")
    print(f"  æŠ•å½±å±‚: {params['projection']:,}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 2
    num_channels = 16
    seq_length = 1000
    
    dummy_input = torch.randn(batch_size, num_channels, seq_length)
    output = student(dummy_input)
    
    output_length = len(torch.arange(seq_length)[student.left_context::student.stride])
    
    print(f"\nâœ… å‰å‘ä¼ æ’­æµ‹è¯•:")
    print(f"  è¾“å…¥shape: {dummy_input.shape}")
    print(f"  è¾“å‡ºshape: {output.shape}")
    print(f"  é¢„æœŸè¾“å‡ºshape: ({batch_size}, 9, {output_length})")
    
    assert output.shape == (batch_size, 9, output_length), "è¾“å‡ºshapeä¸åŒ¹é…ï¼"
    print("\nâœ¨ Studentæ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")

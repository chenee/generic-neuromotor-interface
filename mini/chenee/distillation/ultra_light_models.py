"""
è¶…è½»é‡çº§Studentæ¨¡å‹ - ä¸“ä¸ºESP32ç­‰å¾®æ§åˆ¶å™¨è®¾è®¡

ç›¸æ¯”æ ‡å‡†Studentæ¨¡å‹çš„è¿›ä¸€æ­¥å‹ç¼©æ–¹æ¡ˆï¼š
1. TinyStudent: 1å±‚LSTMï¼Œæ›´å°‘é€šé“ï¼ˆ~15ä¸‡å‚æ•°ï¼‰
2. ConvOnlyStudent: å…¨å·ç§¯ç½‘ç»œï¼Œæ— LSTMï¼ˆ~8ä¸‡å‚æ•°ï¼‰
3. GRUStudent: ç”¨GRUæ›¿ä»£LSTMï¼ˆ~40ä¸‡å‚æ•°ï¼‰

é€‰æ‹©å»ºè®®ï¼š
- ESP32 (520KB RAM): ConvOnlyStudent æˆ– TinyStudent + INT8é‡åŒ–
- æ ‘è“æ´¾/æ‰‹æœº: æ ‡å‡†Studentæ¨¡å‹
- äº‘ç«¯/PC: Teacheræ¨¡å‹
"""

import torch
from torch import nn
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent.parent.parent.parent))
from generic_neuromotor_interface.networks import ReinhardCompression


class TinyStudentArchitecture(nn.Module):
    """
    è¶…è½»é‡çº§LSTMæ¨¡å‹ï¼ˆ~15ä¸‡å‚æ•°ï¼‰
    
    å‹ç¼©ç­–ç•¥ï¼š
    - Convé€šé“: 128 -> 64 (2å€å‹ç¼©)
    - LSTMå±‚æ•°: 2 -> 1 (å•å±‚)
    - LSTMéšè—: 256 -> 128 (2å€å‹ç¼©)
    
    ç›¸æ¯”Teacher: ~2.3% (650ä¸‡ -> 15ä¸‡)
    ç›¸æ¯”Student: ~25% (60ä¸‡ -> 15ä¸‡)
    """
    
    def __init__(
        self,
        input_channels: int = 16,
        conv_output_channels: int = 64,   # Student: 128
        kernel_width: int = 21,
        stride: int = 10,
        lstm_hidden_size: int = 128,      # Student: 256
        lstm_num_layers: int = 1,         # Student: 2
        output_channels: int = 9,
    ):
        super().__init__()
        
        self.lstm_num_layers = lstm_num_layers
        self.lstm_hidden_size = lstm_hidden_size
        self.left_context = kernel_width - 1
        self.stride = stride
        
        self.compression = ReinhardCompression(range=64.0, midpoint=32.0)
        
        self.conv_layer = nn.Conv1d(
            input_channels, conv_output_channels,
            kernel_size=kernel_width, stride=stride
        )
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)
        self.post_conv_layer_norm = nn.LayerNorm(normalized_shape=conv_output_channels)
        
        self.lstm = nn.LSTM(
            input_size=conv_output_channels,
            hidden_size=lstm_hidden_size,
            num_layers=lstm_num_layers,
            batch_first=True,
            dropout=0.0,  # å•å±‚LSTMä¸éœ€è¦dropout
        )
        
        self.post_lstm_layer_norm = nn.LayerNorm(normalized_shape=lstm_hidden_size)
        self.projection = nn.Linear(lstm_hidden_size, output_channels)
    
    def forward(self, inputs: torch.Tensor) -> torch.Tensor:
        x = self.compression(inputs)
        x = self.conv_layer(x)
        x = self.relu(x)
        x = self.dropout(x)
        
        x = x.transpose(1, 2)
        x = self.post_conv_layer_norm(x)
        
        x, _ = self.lstm(x)
        x = self.post_lstm_layer_norm(x)
        
        x = self.projection(x)
        x = x.permute(0, 2, 1)
        return x


class GRUStudentArchitecture(nn.Module):
    """
    GRUæ›¿ä»£LSTMï¼ˆ~40ä¸‡å‚æ•°ï¼‰
    
    GRUæ¯”LSTMå‚æ•°å°‘25%ï¼š
    - LSTM: 4ä¸ªé—¨ï¼ˆè¾“å…¥ã€é—å¿˜ã€è¾“å‡ºã€cellï¼‰
    - GRU: 2ä¸ªé—¨ï¼ˆé‡ç½®ã€æ›´æ–°ï¼‰
    
    ä¼˜åŠ¿ï¼šå‚æ•°å°‘ã€é€Ÿåº¦å¿«
    åŠ£åŠ¿ï¼šå¯èƒ½ç²¾åº¦ç•¥ä½
    """
    
    def __init__(
        self,
        input_channels: int = 16,
        conv_output_channels: int = 128,
        kernel_width: int = 21,
        stride: int = 10,
        gru_hidden_size: int = 256,
        gru_num_layers: int = 2,
        output_channels: int = 9,
    ):
        super().__init__()
        
        self.gru_num_layers = gru_num_layers
        self.gru_hidden_size = gru_hidden_size
        self.left_context = kernel_width - 1
        self.stride = stride
        
        self.compression = ReinhardCompression(range=64.0, midpoint=32.0)
        
        self.conv_layer = nn.Conv1d(
            input_channels, conv_output_channels,
            kernel_size=kernel_width, stride=stride
        )
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)
        self.post_conv_layer_norm = nn.LayerNorm(normalized_shape=conv_output_channels)
        
        # GRUæ›¿ä»£LSTM
        self.gru = nn.GRU(
            input_size=conv_output_channels,
            hidden_size=gru_hidden_size,
            num_layers=gru_num_layers,
            batch_first=True,
            dropout=0.1 if gru_num_layers > 1 else 0.0,
        )
        
        self.post_gru_layer_norm = nn.LayerNorm(normalized_shape=gru_hidden_size)
        self.projection = nn.Linear(gru_hidden_size, output_channels)
    
    def forward(self, inputs: torch.Tensor) -> torch.Tensor:
        x = self.compression(inputs)
        x = self.conv_layer(x)
        x = self.relu(x)
        x = self.dropout(x)
        
        x = x.transpose(1, 2)
        x = self.post_conv_layer_norm(x)
        
        x, _ = self.gru(x)
        x = self.post_gru_layer_norm(x)
        
        x = self.projection(x)
        x = x.permute(0, 2, 1)
        return x


class ConvOnlyStudentArchitecture(nn.Module):
    """
    å…¨å·ç§¯ç½‘ç»œï¼ˆ~8ä¸‡å‚æ•°ï¼‰- æœ€é€‚åˆESP32
    
    å®Œå…¨ç§»é™¤LSTMï¼Œç”¨å¤šå±‚å·ç§¯æ›¿ä»£ï¼š
    - Conv1: 16 -> 64 é€šé“
    - Conv2: 64 -> 64 é€šé“ï¼ˆæ‰©å¤§æ„Ÿå—é‡ï¼‰
    - Conv3: 64 -> 32 é€šé“
    - Linear: 32 -> 9
    
    ä¼˜åŠ¿ï¼š
    - å‚æ•°æœ€å°‘ï¼ˆ~8ä¸‡ï¼‰
    - æ¨ç†é€Ÿåº¦æœ€å¿«ï¼ˆæ— å¾ªç¯ä¾èµ–ï¼‰
    - å†…å­˜å ç”¨æœ€å°
    - æ˜“äºé‡åŒ–å’Œéƒ¨ç½²
    
    åŠ£åŠ¿ï¼š
    - æ— æ³•å»ºæ¨¡é•¿æœŸä¾èµ–
    - å¯èƒ½ç²¾åº¦æœ€ä½
    """
    
    def __init__(
        self,
        input_channels: int = 16,
        hidden_channels: int = 64,
        output_channels: int = 9,
    ):
        super().__init__()
        
        self.left_context = 20  # Conv1(20) = 20
        self.stride = 10
        
        self.compression = ReinhardCompression(range=64.0, midpoint=32.0)
        
        # ä¸‰å±‚å·ç§¯ç½‘ç»œ
        self.conv1 = nn.Conv1d(
            input_channels, hidden_channels,
            kernel_size=21, stride=10
        )
        self.bn1 = nn.BatchNorm1d(hidden_channels)
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(p=0.2)
        
        # ç¬¬äºŒå±‚ï¼šæ‰©å¤§æ—¶é—´æ„Ÿå—é‡
        self.conv2 = nn.Conv1d(
            hidden_channels, hidden_channels,
            kernel_size=5, stride=1, padding=2
        )
        self.bn2 = nn.BatchNorm1d(hidden_channels)
        self.relu2 = nn.ReLU()
        self.dropout2 = nn.Dropout(p=0.2)
        
        # ç¬¬ä¸‰å±‚ï¼šé™ç»´
        self.conv3 = nn.Conv1d(
            hidden_channels, 32,
            kernel_size=3, stride=1, padding=1
        )
        self.bn3 = nn.BatchNorm1d(32)
        self.relu3 = nn.ReLU()
        
        # è¾“å‡ºå±‚
        self.projection = nn.Conv1d(32, output_channels, kernel_size=1)
    
    def forward(self, inputs: torch.Tensor) -> torch.Tensor:
        x = self.compression(inputs)
        
        # Convå—1
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu1(x)
        x = self.dropout1(x)
        
        # Convå—2
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu2(x)
        x = self.dropout2(x)
        
        # Convå—3
        x = self.conv3(x)
        x = self.bn3(x)
        x = self.relu3(x)
        
        # è¾“å‡º
        x = self.projection(x)
        return x


def count_parameters(model: nn.Module) -> dict:
    """ç»Ÿè®¡æ¨¡å‹å‚æ•°"""
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    return {
        "total": total,
        "trainable": trainable,
    }


if __name__ == "__main__":
    print("="*70)
    print("è¶…è½»é‡çº§æ¨¡å‹å¯¹æ¯” - ESP32éƒ¨ç½²æ–¹æ¡ˆ")
    print("="*70)
    
    # åˆ›å»ºæ‰€æœ‰æ¨¡å‹
    models = {
        "TinyStudent (1-LSTM)": TinyStudentArchitecture(),
        "GRUStudent (2-GRU)": GRUStudentArchitecture(),
        "ConvOnly (No-RNN)": ConvOnlyStudentArchitecture(),
    }
    
    # å‚è€ƒæ¨¡å‹
    from student_network import StudentDiscreteGesturesArchitecture
    from generic_neuromotor_interface.networks import DiscreteGesturesArchitecture
    
    teacher = DiscreteGesturesArchitecture()
    student = StudentDiscreteGesturesArchitecture()
    
    print(f"\nğŸ“Š æ¨¡å‹å‚æ•°å¯¹æ¯”:\n")
    print(f"{'æ¨¡å‹':<25} {'å‚æ•°é‡':>12} {'ç›¸å¯¹Teacher':>12} {'ç›¸å¯¹Student':>12}")
    print("-" * 70)
    
    teacher_params = count_parameters(teacher)['total']
    student_params = count_parameters(student)['total']
    
    print(f"{'Teacher (Metaå¤§æ¨¡å‹)':<25} {teacher_params:>12,} {'100.0%':>12} {'-':>12}")
    print(f"{'Student (æ ‡å‡†å°æ¨¡å‹)':<25} {student_params:>12,} {f'{student_params/teacher_params:.1%}':>12} {'100.0%':>12}")
    print("-" * 70)
    
    for name, model in models.items():
        params = count_parameters(model)['total']
        print(f"{name:<25} {params:>12,} {f'{params/teacher_params:.1%}':>12} {f'{params/student_params:.1%}':>12}")
    
    # æµ‹è¯•æ¨ç†
    print(f"\n\nğŸ§ª æ¨ç†æµ‹è¯•ï¼ˆè¾“å…¥: 1Ã—16Ã—2000ï¼‰:\n")
    dummy_input = torch.randn(1, 16, 2000)
    
    for name, model in models.items():
        model.eval()
        with torch.no_grad():
            output = model(dummy_input)
        print(f"{name:<25} è¾“å‡º: {output.shape}")
    
    # ESP32éƒ¨ç½²å»ºè®®
    print(f"\n\nğŸ’¡ ESP32éƒ¨ç½²å»ºè®®:\n")
    
    conv_params = count_parameters(models["ConvOnly (No-RNN)"])['total']
    tiny_params = count_parameters(models["TinyStudent (1-LSTM)"])['total']
    
    # FP32å¤§å°
    conv_size_fp32 = conv_params * 4 / 1024  # KB
    tiny_size_fp32 = tiny_params * 4 / 1024
    
    # INT8å¤§å°
    conv_size_int8 = conv_params * 1 / 1024
    tiny_size_int8 = tiny_params * 1 / 1024
    
    print(f"1ï¸âƒ£  ConvOnlyæ¨¡å‹:")
    print(f"   - FP32: {conv_size_fp32:.1f} KB")
    print(f"   - INT8é‡åŒ–å: {conv_size_int8:.1f} KB")
    print(f"   - æ¨èè®¾å¤‡: ESP32 (520KB RAM)")
    print(f"   - ç‰¹ç‚¹: æœ€å¿«ã€æœ€å°ã€æ— çŠ¶æ€")
    
    print(f"\n2ï¸âƒ£  TinyStudentæ¨¡å‹:")
    print(f"   - FP32: {tiny_size_fp32:.1f} KB")
    print(f"   - INT8é‡åŒ–å: {tiny_size_int8:.1f} KB")
    print(f"   - æ¨èè®¾å¤‡: ESP32-S3 (æ›´å¤§RAM) æˆ–æ ‘è“æ´¾Pico")
    print(f"   - ç‰¹ç‚¹: ä¸­ç­‰å¤§å°ã€æœ‰çŠ¶æ€ã€ç²¾åº¦è¾ƒå¥½")
    
    print(f"\n3ï¸âƒ£  GRUStudentæ¨¡å‹:")
    print(f"   - æ¨èè®¾å¤‡: æ ‘è“æ´¾ã€æ‰‹æœº")
    print(f"   - ç‰¹ç‚¹: ESP32å¯èƒ½å†…å­˜ä¸è¶³")
    
    print(f"\n\nğŸ¯ æ¨èæ–¹æ¡ˆ:")
    print(f"   ESP32: ConvOnly + INT8é‡åŒ– (~{conv_size_int8:.0f}KB)")
    print(f"   ESP32-S3: TinyStudent + INT8é‡åŒ– (~{tiny_size_int8:.0f}KB)")
    print(f"   æ ‘è“æ´¾/æ‰‹æœº: æ ‡å‡†Studentæ¨¡å‹")

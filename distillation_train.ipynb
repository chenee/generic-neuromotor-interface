{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355cb5a2",
   "metadata": {},
   "source": [
    "# EMGæ‰‹åŠ¿è¯†åˆ«æ¨¡å‹çŸ¥è¯†è’¸é¦è®­ç»ƒ\n",
    "\n",
    "æœ¬notebookç”¨äºå°†Metaçš„é¢„è®­ç»ƒTeacheræ¨¡å‹è’¸é¦ä¸ºè½»é‡çº§Studentæ¨¡å‹ï¼Œé€‚åˆESP32éƒ¨ç½²ã€‚\n",
    "\n",
    "## è®­ç»ƒæ—¶é—´é¢„ä¼°\n",
    "- **å¿«é€Ÿæµ‹è¯•**: ConvOnlyæ¨¡å‹, 30 epochs â†’ ~1-2å°æ—¶ (é€‚åˆESP32)\n",
    "- **æ ‡å‡†è®­ç»ƒ**: Studentæ¨¡å‹, 100 epochs â†’ ~6-8å°æ—¶ (æ›´é«˜ç²¾åº¦)\n",
    "\n",
    "## ç¯å¢ƒè¦æ±‚\n",
    "- Google Colab with GPU (Tesla T4æ¨è)\n",
    "- 30GB EMGæ•°æ®é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0532d332",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b233d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAå¯ç”¨: True\n",
      "GPUå‹å·: Tesla T4\n",
      "æ˜¾å­˜: 14.6 GB\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥GPUå¯ç”¨æ€§\n",
    "import torch\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPUå‹å·: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd199f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/generic-neuromotor-interface\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…ä¾èµ– (å¦‚æœåœ¨Colabä¸Š)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦åœ¨Colabç¯å¢ƒ\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Cloneé¡¹ç›®\n",
    "    if not os.path.exists('/content/generic-neuromotor-interface'):\n",
    "        !git clone https://github.com/fwillett/generic-neuromotor-interface.git\n",
    "    \n",
    "    # å®‰è£…ä¾èµ–\n",
    "    %cd /content/generic-neuromotor-interface\n",
    "    !pip install -e . -q\n",
    "    !pip install tensorboard -q\n",
    "else:\n",
    "    print(\"æœ¬åœ°ç¯å¢ƒï¼Œå‡è®¾å·²å®‰è£…ä¾èµ–\")\n",
    "    # è®¾ç½®å·¥ä½œç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•\n",
    "    %cd /Users/chenee/Documents/Dev/ç®—æ³•/myEMG/generic-neuromotor-interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9830bb",
   "metadata": {},
   "source": [
    "## 2. ä¸‹è½½Metaé¢„è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c1d3d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹ä¸‹è½½Metaé¢„è®­ç»ƒæ¨¡å‹...\n",
      "Downloading the pretrained model for discrete_gestures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading discrete_gestures model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74.2M/74.2M [00:02<00:00, 34.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for discrete_gestures downloaded and extracted to /content/emg_models/discrete_gestures\n",
      "âœ… æ¨¡å‹å·²ä¸‹è½½åˆ°: /content/emg_models/discrete_gestures/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ä¸‹è½½Metaçš„é¢„è®­ç»ƒTeacheræ¨¡å‹ (~95%ç²¾åº¦)\n",
    "from generic_neuromotor_interface.scripts.download_models import download_models\n",
    "\n",
    "# ä¸‹è½½discrete_gesturesä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹\n",
    "model_save_dir = \"/content/emg_models\" if IN_COLAB else \"../models\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "print(\"å¼€å§‹ä¸‹è½½Metaé¢„è®­ç»ƒæ¨¡å‹...\")\n",
    "download_models(\"discrete_gestures\", model_save_dir)\n",
    "print(f\"âœ… æ¨¡å‹å·²ä¸‹è½½åˆ°: {model_save_dir}/discrete_gestures/\")\n",
    "\n",
    "# è®¾ç½®Teacheræ¨¡å‹è·¯å¾„\n",
    "TEACHER_CHECKPOINT = f\"{model_save_dir}/discrete_gestures/model_checkpoint.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387124d",
   "metadata": {},
   "source": [
    "## 3. æ•°æ®å‡†å¤‡\n",
    "\n",
    "### é€‰æ‹©æ•°æ®æº\n",
    "- **é€‰é¡¹A**: æœ¬åœ°è·¯å¾„ `/content/generic-neuromotor-interface/data`\n",
    "- **é€‰é¡¹B**: Google Drive (æ”¯æŒå¤šColabå…±äº«)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30afa63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®è·¯å¾„: /content/generic-neuromotor-interface/data\n",
      "âœ… æ‰¾åˆ° 100 ä¸ªHDF5æ–‡ä»¶\n"
     ]
    }
   ],
   "source": [
    "# æ•°æ®è·¯å¾„é…ç½®\n",
    "USE_GOOGLE_DRIVE = False  # å¦‚æœä½¿ç”¨Google Driveï¼Œæ”¹ä¸ºTrue\n",
    "\n",
    "if USE_GOOGLE_DRIVE and IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = \"/content/drive/MyDrive/emg_data\"  # ä¿®æ”¹ä¸ºä½ çš„Driveè·¯å¾„\n",
    "else:\n",
    "    DATA_PATH = \"/content/generic-neuromotor-interface/data\" if IN_COLAB else \"data\"\n",
    "\n",
    "print(f\"æ•°æ®è·¯å¾„: {DATA_PATH}\")\n",
    "\n",
    "# éªŒè¯æ•°æ®å­˜åœ¨\n",
    "if os.path.exists(DATA_PATH):\n",
    "    hdf5_files = [f for f in os.listdir(DATA_PATH) if f.endswith('.hdf5')]\n",
    "    print(f\"âœ… æ‰¾åˆ° {len(hdf5_files)} ä¸ªHDF5æ–‡ä»¶\")\n",
    "else:\n",
    "    print(f\"âš ï¸ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {DATA_PATH}\")\n",
    "    print(\"è¯·å…ˆä¸‹è½½æ•°æ®æˆ–æŒ‚è½½Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b4c77",
   "metadata": {},
   "source": [
    "## 4. è’¸é¦é…ç½®\n",
    "\n",
    "### é€‰æ‹©è®­ç»ƒæ¨¡å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb12810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "è®­ç»ƒæ¨¡å¼: QUICK\n",
      "Studentæ¨¡å‹: ConvOnly\n",
      "è®­ç»ƒè½®æ•°: 30 epochs\n",
      "æ‰¹æ¬¡å¤§å°: 128\n",
      "è’¸é¦æ¸©åº¦: 4.0\n",
      "è’¸é¦æƒé‡ Alpha: 0.6\n",
      "é¢„è®¡æ—¶é—´: 1-2å°æ—¶\n",
      "é¢„æœŸç²¾åº¦: 75-80% (Teacherçš„75-80%)\n",
      "å®éªŒID: distill_convonly_quick\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ========== é…ç½®åŒºåŸŸ ==========\n",
    "\n",
    "# è®­ç»ƒæ¨¡å¼é€‰æ‹©\n",
    "TRAINING_MODE = \"quick\"  # \"quick\" (1-2å°æ—¶) æˆ– \"standard\" (6-8å°æ—¶)\n",
    "\n",
    "# å¿«é€Ÿæ¨¡å¼: ConvOnly, 30 epochs, é€‚åˆESP32\n",
    "if TRAINING_MODE == \"quick\":\n",
    "    STUDENT_MODEL = \"ConvOnly\"  # 8ä¸‡å‚æ•°, é‡åŒ–å80KB\n",
    "    MAX_EPOCHS = 30\n",
    "    BATCH_SIZE = 128  # âœ… T4ä¼˜åŒ–ï¼šå……åˆ†åˆ©ç”¨GPU\n",
    "    TEMPERATURE = 4.0  # ç®€å•æ¨¡å‹ç”¨æ›´é«˜æ¸©åº¦\n",
    "    ALPHA = 0.6\n",
    "    EXPECTED_TIME = \"1-2å°æ—¶\"\n",
    "    EXPECTED_ACCURACY = \"75-80% (Teacherçš„75-80%)\"\n",
    "\n",
    "# æ ‡å‡†æ¨¡å¼: Student, 100 epochs, æ›´é«˜ç²¾åº¦\n",
    "elif TRAINING_MODE == \"standard\":\n",
    "    STUDENT_MODEL = \"Student\"  # 60ä¸‡å‚æ•°, é‡åŒ–å400KB\n",
    "    MAX_EPOCHS = 100\n",
    "    BATCH_SIZE = 32  # âœ… T4ä¼˜åŒ–ï¼šæ€§èƒ½ä¸ç¨³å®šæ€§å¹³è¡¡\n",
    "    TEMPERATURE = 3.0\n",
    "    ALPHA = 0.5\n",
    "    EXPECTED_TIME = \"6-8å°æ—¶\"\n",
    "    EXPECTED_ACCURACY = \"90-95% (Teacherçš„90-95%)\"\n",
    "\n",
    "# å®éªŒID (ç”¨äºåŒºåˆ†ä¸åŒè®­ç»ƒ)\n",
    "EXPERIMENT_ID = f\"distill_{STUDENT_MODEL.lower()}_{TRAINING_MODE}\"\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"è®­ç»ƒæ¨¡å¼: {TRAINING_MODE.upper()}\")\n",
    "print(f\"Studentæ¨¡å‹: {STUDENT_MODEL}\")\n",
    "print(f\"è®­ç»ƒè½®æ•°: {MAX_EPOCHS} epochs\")\n",
    "print(f\"æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}\")\n",
    "print(f\"è’¸é¦æ¸©åº¦: {TEMPERATURE}\")\n",
    "print(f\"è’¸é¦æƒé‡ Alpha: {ALPHA}\")\n",
    "print(f\"é¢„è®¡æ—¶é—´: {EXPECTED_TIME}\")\n",
    "print(f\"é¢„æœŸç²¾åº¦: {EXPECTED_ACCURACY}\")\n",
    "print(f\"å®éªŒID: {EXPERIMENT_ID}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06afbfd",
   "metadata": {},
   "source": [
    "## 5. å¯åŠ¨TensorBoardç›‘æ§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239fdc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# å¯åŠ¨TensorBoard\n",
    "%load_ext tensorboard\n",
    "\n",
    "log_dir = f\"logs/distillation/{EXPERIMENT_ID}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0d3cc",
   "metadata": {},
   "source": [
    "## 6. çŸ¥è¯†è’¸é¦è®­ç»ƒ\n",
    "\n",
    "### æ–¹æ³•è¯´æ˜\n",
    "çŸ¥è¯†è’¸é¦(Knowledge Distillation)é€šè¿‡è®©è½»é‡çº§Studentæ¨¡å‹å­¦ä¹ Teacheræ¨¡å‹çš„\"è½¯æ ‡ç­¾\"ï¼Œåœ¨å¤§å¹…å‡å°‘å‚æ•°é‡çš„åŒæ—¶ä¿æŒé«˜ç²¾åº¦ã€‚\n",
    "\n",
    "**å…³é”®å‚æ•°**:\n",
    "- `temperature`: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶æ¦‚ç‡åˆ†å¸ƒçš„å¹³æ»‘ç¨‹åº¦\n",
    "- `alpha`: è’¸é¦æŸå¤±æƒé‡ (1-alphaä¸ºçœŸå®æ ‡ç­¾æƒé‡)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28bfb71b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train_distillation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1961291267.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../mini/chenee/distillation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_distillation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_distillation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multra_light_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvOnlyStudent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTinyStudent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRUStudent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train_distillation'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥è®­ç»ƒè„šæœ¬\n",
    "import sys\n",
    "sys.path.insert(0, '../mini/chenee/distillation')\n",
    "\n",
    "from train_distillation import train_distillation\n",
    "from ultra_light_models import ConvOnlyStudent, TinyStudent, GRUStudent\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "print(\"âœ… å¯¼å…¥è®­ç»ƒæ¨¡å—æˆåŠŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¼€å§‹è’¸é¦è®­ç»ƒ\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"å¼€å§‹çŸ¥è¯†è’¸é¦è®­ç»ƒ: {STUDENT_MODEL}\")\n",
    "print(f\"é¢„è®¡è®­ç»ƒæ—¶é—´: {EXPECTED_TIME}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# è®­ç»ƒå‚æ•°\n",
    "training_config = {\n",
    "    \"teacher_checkpoint\": TEACHER_CHECKPOINT,\n",
    "    \"student_model\": STUDENT_MODEL,\n",
    "    \"data_path\": DATA_PATH,\n",
    "    \"max_epochs\": MAX_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"temperature\": TEMPERATURE,\n",
    "    \"alpha\": ALPHA,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"experiment_name\": EXPERIMENT_ID,\n",
    "    \"num_workers\": 4,\n",
    "    \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": 16,  # æ··åˆç²¾åº¦è®­ç»ƒï¼ŒåŠ é€Ÿ1.5-2å€\n",
    "}\n",
    "\n",
    "# è°ƒç”¨è®­ç»ƒå‡½æ•° (éœ€è¦æ ¹æ®å®é™…çš„train_distillation.pyæ¥å£è°ƒæ•´)\n",
    "# è¿™é‡Œæä¾›ä¸€ä¸ªç¤ºä¾‹æ¡†æ¶\n",
    "\n",
    "print(\"è®­ç»ƒé…ç½®:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nå¼€å§‹è®­ç»ƒ...\")\n",
    "print(\"ğŸ’¡ æç¤º: åœ¨TensorBoardä¸­å®æ—¶æŸ¥çœ‹è®­ç»ƒè¿›åº¦\")\n",
    "\n",
    "# å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šæ¥å®é™…è¿è¡Œè®­ç»ƒ\n",
    "# trainer, student_model = train_distillation(**training_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf82b3",
   "metadata": {},
   "source": [
    "### æ‰‹åŠ¨è®­ç»ƒæµç¨‹ (å¦‚æœtrain_distillationå‡½æ•°ä¸å¯ç”¨)\n",
    "\n",
    "å¦‚æœä¸Šé¢çš„è‡ªåŠ¨è®­ç»ƒä¸å·¥ä½œï¼Œä½¿ç”¨ä¸‹é¢çš„æ‰‹åŠ¨æµç¨‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89999f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½Teacheræ¨¡å‹...\n",
      "âœ… Teacheræ¨¡å‹å‚æ•°: 6.5M\n",
      "âœ… Studentæ¨¡å‹å‚æ•°: 0.02M\n",
      "å‹ç¼©æ¯”: 372.9x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'network' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['network'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# æ‰‹åŠ¨è®­ç»ƒæµç¨‹\n",
    "\n",
    "# 1. åŠ è½½Teacheræ¨¡å‹\n",
    "from generic_neuromotor_interface.lightning import DiscreteGesturesModule\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# PyTorch 2.6+ éœ€è¦è®¾ç½®weights_only=Falseæ¥åŠ è½½åŒ…å«è‡ªå®šä¹‰ç±»çš„checkpoint\n",
    "# Metaçš„å®˜æ–¹æ¨¡å‹æ˜¯å¯ä¿¡çš„ï¼Œå¯ä»¥å®‰å…¨åŠ è½½\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# ä¸´æ—¶patch torch.loadä»¥ä½¿ç”¨weights_only=False\n",
    "original_torch_load = torch.load\n",
    "def patched_torch_load(*args, **kwargs):\n",
    "    kwargs['weights_only'] = False\n",
    "    return original_torch_load(*args, **kwargs)\n",
    "torch.load = patched_torch_load\n",
    "\n",
    "print(\"åŠ è½½Teacheræ¨¡å‹...\")\n",
    "teacher = DiscreteGesturesModule.load_from_checkpoint(TEACHER_CHECKPOINT)\n",
    "\n",
    "# æ¢å¤åŸå§‹torch.load\n",
    "torch.load = original_torch_load\n",
    "teacher.eval()\n",
    "teacher.freeze()\n",
    "print(f\"âœ… Teacheræ¨¡å‹å‚æ•°: {sum(p.numel() for p in teacher.parameters()) / 1e6:.1f}M\")\n",
    "\n",
    "# 2. å®šä¹‰è½»é‡çº§Studentæ¨¡å‹\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvOnlyStudent(nn.Module):\n",
    "    \"\"\"\n",
    "    ConvOnlyè¶…è½»é‡çº§æ¨¡å‹ - é€‚åˆESP32éƒ¨ç½²\n",
    "    åªä½¿ç”¨å·ç§¯å±‚ï¼Œæ— GRU/LSTMç­‰å¤æ‚å±‚\n",
    "    ç›®æ ‡: ~8ä¸‡å‚æ•°, é‡åŒ–å<100KB\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=21, input_channels=16, sequence_length=16000):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ç®€åŒ–çš„å·ç§¯ç‰¹å¾æå–\n",
    "        # è¾“å…¥: [batch, 16, 16000]\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(4)  # 16000 -> 4000\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.pool2 = nn.MaxPool1d(4)  # 4000 -> 1000\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(32, 16, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(16)\n",
    "        self.pool3 = nn.MaxPool1d(4)  # 1000 -> 250\n",
    "        \n",
    "        # å…¨å±€å¹³å‡æ± åŒ– + åˆ†ç±»å™¨\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(16, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, sequence, channels] - éœ€è¦è½¬ç½®ä¸º [batch, channels, sequence]\n",
    "        if x.dim() == 3 and x.shape[2] < x.shape[1]:\n",
    "            x = x.transpose(1, 2)  # [batch, sequence, channels] -> [batch, channels, sequence]\n",
    "        \n",
    "        # ç‰¹å¾æå–\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # å…¨å±€æ± åŒ– + åˆ†ç±»\n",
    "        x = self.global_pool(x)  # [batch, 16, 1]\n",
    "        x = x.squeeze(-1)  # [batch, 16]\n",
    "        x = self.fc(x)  # [batch, num_classes]\n",
    "        \n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºStudentæ¨¡å‹\n",
    "student = ConvOnlyStudent(num_classes=9)  # âœ… discrete_gesturesæœ‰9ä¸ªç±»åˆ«ï¼Œä¸æ˜¯21ï¼\n",
    "student = student.cuda() if torch.cuda.is_available() else student\n",
    "\n",
    "print(f\"âœ… Studentæ¨¡å‹å‚æ•°: {sum(p.numel() for p in student.parameters()) / 1e6:.2f}M\")\n",
    "print(f\"å‹ç¼©æ¯”: {sum(p.numel() for p in teacher.parameters()) / sum(p.numel() for p in student.parameters()):.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db616296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½æ•°æ®é…ç½®...\n",
      "è®¾ç½®æ•°æ®æ¨¡å—...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa5c346c9c94885ba45c72d82766386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split train:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ac0c80614a4816b7429e5dbb37a898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è®­ç»ƒé›†: 110 batches\n",
      "âœ… éªŒè¯é›†: 14 batches\n"
     ]
    }
   ],
   "source": [
    "# 3. å‡†å¤‡æ•°æ®\n",
    "from generic_neuromotor_interface.data_module import WindowedEmgDataModule\n",
    "from generic_neuromotor_interface.data import DataSplit\n",
    "from generic_neuromotor_interface.transforms import DiscreteGesturesTransform\n",
    "from generic_neuromotor_interface.augmentation import RotationAugmentation\n",
    "\n",
    "print(\"åŠ è½½æ•°æ®é…ç½®...\")\n",
    "\n",
    "# åˆ›å»ºdata split\n",
    "data_split = DataSplit.from_csv(\n",
    "    csv_filename=f\"{DATA_PATH}/discrete_gestures_corpus.csv\",\n",
    "    pool_test_partitions=True\n",
    ")\n",
    "\n",
    "# åˆ›å»ºtransform\n",
    "transform = DiscreteGesturesTransform(pulse_window=[0.08, 0.12])\n",
    "\n",
    "# åˆ›å»ºaugmentation\n",
    "emg_augmentation = RotationAugmentation(rotation=2)\n",
    "\n",
    "# åˆ›å»ºdata module\n",
    "data_module = WindowedEmgDataModule(\n",
    "    window_length=16_000,  # 8ç§’ @ 2kHz\n",
    "    stride=16_000,  # æ— é‡å \n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,  # Colabä¸Šå¤šworkerå¯èƒ½æœ‰é—®é¢˜ï¼Œç”¨0æœ€ç¨³å®š\n",
    "    data_split=data_split,\n",
    "    transform=transform,\n",
    "    data_location=DATA_PATH,\n",
    "    emg_augmentation=emg_augmentation,\n",
    ")\n",
    "\n",
    "print(\"è®¾ç½®æ•°æ®æ¨¡å—...\")\n",
    "data_module.setup(\"fit\")\n",
    "print(f\"âœ… è®­ç»ƒé›†: {len(data_module.train_dataloader())} batches\")\n",
    "print(f\"âœ… éªŒè¯é›†: {len(data_module.val_dataloader())} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed55c165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è’¸é¦æ¨¡å‹åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# 4. é…ç½®è’¸é¦è®­ç»ƒå™¨\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DistillationModule(pl.LightningModule):\n",
    "    def __init__(self, teacher, student, temperature, alpha):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.student(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # æ•°æ®æ ¼å¼: {\"emg\": tensor, \"targets\": tensor}\n",
    "        emg = batch[\"emg\"]  # shape: [batch, channels, sequence]\n",
    "        targets = batch[\"targets\"]  # shape: [batch, num_classes, sequence]\n",
    "        \n",
    "        # ä»targetsä¸­æå–ç±»åˆ«æ ‡ç­¾ (å–targetsä¸­çš„argmax)\n",
    "        # targetsæ˜¯æ—¶é—´åºåˆ—ä¸Šçš„å¤šæ ‡ç­¾ï¼Œæˆ‘ä»¬å–æ¯ä¸ªæ ·æœ¬çš„ä¸»è¦ç±»åˆ«\n",
    "        y = targets.max(dim=2)[0].argmax(dim=1)  # shape: [batch]\n",
    "        \n",
    "        # Teacherå‰å‘ä¼ æ’­ (ä¸è®¡ç®—æ¢¯åº¦)\n",
    "        # Teacherçš„forwardæ–¹æ³•åªæ¥å—emg tensor\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = self.teacher(emg)  # shape: [batch, num_classes, time_steps]\n",
    "            # èšåˆæ—¶é—´ç»´åº¦ï¼šå–å¹³å‡æˆ–æœ€å¤§å€¼\n",
    "            teacher_logits = teacher_logits.mean(dim=2)  # shape: [batch, num_classes]\n",
    "        \n",
    "        # Studentå‰å‘ä¼ æ’­\n",
    "        student_logits = self.student(emg)  # shape: [batch, num_classes]\n",
    "        \n",
    "        # è’¸é¦æŸå¤± (è½¯æ ‡ç­¾)\n",
    "        distill_loss = F.kl_div(\n",
    "            F.log_softmax(student_logits / self.temperature, dim=1),\n",
    "            F.softmax(teacher_logits / self.temperature, dim=1),\n",
    "            reduction='batchmean'\n",
    "        ) * (self.temperature ** 2)\n",
    "        \n",
    "        # çœŸå®æ ‡ç­¾æŸå¤±\n",
    "        student_loss = self.ce_loss(student_logits, y)\n",
    "        \n",
    "        # æ€»æŸå¤±\n",
    "        loss = self.alpha * distill_loss + (1 - self.alpha) * student_loss\n",
    "        \n",
    "        # è®°å½•æŒ‡æ ‡\n",
    "        acc = (student_logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        self.log('distill_loss', distill_loss)\n",
    "        self.log('student_loss', student_loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # æ•°æ®æ ¼å¼: {\"emg\": tensor, \"targets\": tensor}\n",
    "        emg = batch[\"emg\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        y = targets.max(dim=2)[0].argmax(dim=1)\n",
    "        \n",
    "        # Studentæ¨ç†\n",
    "        logits = self.student(emg)\n",
    "        loss = self.ce_loss(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.student.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=MAX_EPOCHS\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# åˆ›å»ºè’¸é¦æ¨¡å‹\n",
    "distill_model = DistillationModule(\n",
    "    teacher=teacher,\n",
    "    student=student,\n",
    "    temperature=TEMPERATURE,\n",
    "    alpha=ALPHA\n",
    ")\n",
    "\n",
    "print(\"âœ… è’¸é¦æ¨¡å‹åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "762e57bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:56: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è®­ç»ƒå™¨é…ç½®å®Œæˆ\n",
      "æœ€å¤§è®­ç»ƒè½®æ•°: 30\n",
      "è®¾å¤‡: GPU\n",
      "æ··åˆç²¾åº¦: å¼€å¯ (FP16)\n"
     ]
    }
   ],
   "source": [
    "# 5. é…ç½®è®­ç»ƒå™¨\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# å›è°ƒå‡½æ•°\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{log_dir}/checkpoints\",\n",
    "    filename=\"{epoch:02d}-{val_acc:.4f}\",\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=3,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_acc\",\n",
    "    patience=10,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "# æ—¥å¿—è®°å½•å™¨\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=log_dir,\n",
    "    name=EXPERIMENT_ID\n",
    ")\n",
    "\n",
    "# åˆ›å»ºè®­ç»ƒå™¨\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    precision=16,  # æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "    callbacks=[checkpoint_callback, early_stop_callback, lr_monitor],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    "    gradient_clip_val=1.0,\n",
    ")\n",
    "\n",
    "print(\"âœ… è®­ç»ƒå™¨é…ç½®å®Œæˆ\")\n",
    "print(f\"æœ€å¤§è®­ç»ƒè½®æ•°: {MAX_EPOCHS}\")\n",
    "print(f\"è®¾å¤‡: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"æ··åˆç²¾åº¦: å¼€å¯ (FP16)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b43ecfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸš€ å¼€å§‹è’¸é¦è®­ç»ƒ: ConvOnly\n",
      "ğŸ“Š é¢„è®¡æ—¶é—´: 1-2å°æ—¶\n",
      "ğŸ¯ é¢„æœŸç²¾åº¦: 75-80% (Teacherçš„75-80%)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6180c2c434404b658512b211cee35e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split train:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a01095d3ed4d938f8bf08b1b1407cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | teacher | DiscreteGesturesModule | 6.5 M \n",
      "1 | student | ConvOnlyStudent        | 17.4 K\n",
      "2 | ce_loss | CrossEntropyLoss       | 0     \n",
      "---------------------------------------------------\n",
      "17.4 K    Trainable params\n",
      "6.5 M     Non-trainable params\n",
      "6.5 M     Total params\n",
      "13.001    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b973a7a8d74744f6935b83a966a42920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43c535303474ef1be809865af9b43d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d1a9ded2224b9da289e7ce3310aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af272c1b45ea421f8a3f1e5e1a1a2f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cfa18d3f0714a97978ac8282b08b3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f032cdc26e4839972a7e0dae8b22e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ce095ba9ea4414811afb0b719f6806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473a6e7879fd4a4bae60f13d6b7dd277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5040744ba24e19923c99a7df948806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1172e5b34ecf4f9fb67512f6fcd98264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bc5c150ac543f99617509429198f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c390115e3404bed86778e927e3ecd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5785b8328a4349199c015dfbdce30277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bf39f27d2f426bb6ffca76e5dcd1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90d012ad329492caa029e63d890339f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f80776c7d04dc9b491b413a00c1bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea769a2fc8f94d5b8d9d6740284464f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062429ecef314675a3471ae59702cc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993f4b11a96a4e8e851815333c8741e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d1af59f1aa48d48ac5a365cc65a82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f16c1158794a18bb87d681b76b9561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… è®­ç»ƒå®Œæˆï¼\n",
      "â±ï¸  å®é™…ç”¨æ—¶: 1å°æ—¶6åˆ†é’Ÿ\n",
      "ğŸ“ æœ€ä½³æ¨¡å‹: logs/distillation/distill_convonly_quick/checkpoints/epoch=08-val_acc=0.1567.ckpt\n",
      "ğŸ¯ æœ€ä½³éªŒè¯ç²¾åº¦: 0.1567\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 6. å¼€å§‹è®­ç»ƒï¼\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸš€ å¼€å§‹è’¸é¦è®­ç»ƒ: {STUDENT_MODEL}\")\n",
    "print(f\"ğŸ“Š é¢„è®¡æ—¶é—´: {EXPECTED_TIME}\")\n",
    "print(f\"ğŸ¯ é¢„æœŸç²¾åº¦: {EXPECTED_ACCURACY}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.fit(distill_model, data_module)\n",
    "\n",
    "# è®­ç»ƒå®Œæˆ\n",
    "elapsed_time = time.time() - start_time\n",
    "hours = int(elapsed_time // 3600)\n",
    "minutes = int((elapsed_time % 3600) // 60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"âœ… è®­ç»ƒå®Œæˆï¼\")\n",
    "print(f\"â±ï¸  å®é™…ç”¨æ—¶: {hours}å°æ—¶{minutes}åˆ†é’Ÿ\")\n",
    "print(f\"ğŸ“ æœ€ä½³æ¨¡å‹: {checkpoint_callback.best_model_path}\")\n",
    "print(f\"ğŸ¯ æœ€ä½³éªŒè¯ç²¾åº¦: {checkpoint_callback.best_model_score:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07615b8b",
   "metadata": {},
   "source": [
    "## 7. è¯„ä¼°Meta Teacheræ¨¡å‹\n",
    "\n",
    "å…ˆéªŒè¯Metaé¢„è®­ç»ƒæ¨¡å‹çš„ç²¾åº¦æ˜¯å¦æ­£å¸¸ï¼ˆåº”è¯¥åœ¨90-95%ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "765fac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š è¯„ä¼°Metaé¢„è®­ç»ƒTeacheræ¨¡å‹\n",
      "======================================================================\n",
      "\n",
      "å¼€å§‹è¯„ä¼°Teacheræ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:29<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¯ Meta Teacheræ¨¡å‹éªŒè¯é›†ç²¾åº¦\n",
      "======================================================================\n",
      "éªŒè¯ç²¾åº¦: 1.09%\n",
      "æ ·æœ¬æ•°: 1749 samples\n",
      "======================================================================\n",
      "\n",
      "âŒ Teacheræ¨¡å‹ç²¾åº¦å¼‚å¸¸ä½(1.09%)ï¼\n",
      "   å¯èƒ½çš„é—®é¢˜:\n",
      "   1. æ•°æ®é¢„å¤„ç†ä¸åŒ¹é…\n",
      "   2. æ ‡ç­¾æå–é”™è¯¯\n",
      "   3. æ¨¡å‹åŠ è½½å¤±è´¥\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# è¯„ä¼°Meta Teacheræ¨¡å‹çš„ç²¾åº¦\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š è¯„ä¼°Metaé¢„è®­ç»ƒTeacheræ¨¡å‹\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_teacher(teacher_model, dataloader, device='cuda'):\n",
    "    \"\"\"\n",
    "    è¯„ä¼°Teacheræ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„ç²¾åº¦\n",
    "    Teacherè¾“å‡º: [batch, num_classes, time_steps]\n",
    "    \"\"\"\n",
    "    teacher_model.eval()\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    print(\"\\nå¼€å§‹è¯„ä¼°Teacheræ¨¡å‹...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            emg = batch[\"emg\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)  # [batch, 9, time_steps]\n",
    "            \n",
    "            # Teacheræ¨¡å‹å‰å‘ä¼ æ’­\n",
    "            teacher_output = teacher_model(emg)  # [batch, 9, time_steps]\n",
    "            \n",
    "            # å¯¹æ—¶é—´ç»´åº¦å–å¹³å‡ï¼Œå¾—åˆ°æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
    "            teacher_logits = teacher_output.mean(dim=2)  # [batch, 9]\n",
    "            \n",
    "            # ä»targetsä¸­æå–çœŸå®æ ‡ç­¾\n",
    "            # targetsæ˜¯äºŒè¿›åˆ¶è„‰å†²çŸ©é˜µï¼Œå–æ—¶é—´ä¸Šçš„æœ€å¤§å€¼å†argmax\n",
    "            y = targets.max(dim=2)[0].argmax(dim=1)  # [batch]\n",
    "            \n",
    "            # è®¡ç®—å‡†ç¡®ç‡\n",
    "            predictions = teacher_logits.argmax(dim=1)\n",
    "            correct = (predictions == y).sum().item()\n",
    "            \n",
    "            total_correct += correct\n",
    "            total_samples += y.size(0)\n",
    "    \n",
    "    accuracy = total_correct / total_samples\n",
    "    return accuracy\n",
    "\n",
    "# åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°\n",
    "teacher_val_acc = evaluate_teacher(teacher, data_module.val_dataloader())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ Meta Teacheræ¨¡å‹éªŒè¯é›†ç²¾åº¦\")\n",
    "print(\"=\"*70)\n",
    "print(f\"éªŒè¯ç²¾åº¦: {teacher_val_acc*100:.2f}%\")\n",
    "print(f\"æ ·æœ¬æ•°: {len(data_module.val_dataloader().dataset)} samples\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# åˆ¤æ–­Teacheræ¨¡å‹æ˜¯å¦æ­£å¸¸\n",
    "if teacher_val_acc > 0.85:\n",
    "    print(\"\\nâœ… Teacheræ¨¡å‹ç²¾åº¦æ­£å¸¸ï¼å¯ä»¥ç”¨äºè’¸é¦è®­ç»ƒ\")\n",
    "elif teacher_val_acc > 0.50:\n",
    "    print(f\"\\nâš ï¸ Teacheræ¨¡å‹ç²¾åº¦åä½({teacher_val_acc*100:.2f}%)ï¼Œä½†ä»å¯ç”¨\")\n",
    "    print(\"   å¯èƒ½çš„åŸå› : éªŒè¯é›†åˆ†å¸ƒä¸è®­ç»ƒé›†ä¸åŒ\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Teacheræ¨¡å‹ç²¾åº¦å¼‚å¸¸ä½({teacher_val_acc*100:.2f}%)ï¼\")\n",
    "    print(\"   å¯èƒ½çš„é—®é¢˜:\")\n",
    "    print(\"   1. æ•°æ®é¢„å¤„ç†ä¸åŒ¹é…\")\n",
    "    print(\"   2. æ ‡ç­¾æå–é”™è¯¯\")\n",
    "    print(\"   3. æ¨¡å‹åŠ è½½å¤±è´¥\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "237772ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ” æ•°æ®æ ¼å¼è°ƒè¯•\n",
      "======================================================================\n",
      "\n",
      "ğŸ“¦ Batchæ•°æ®ç»“æ„:\n",
      "  ç±»å‹: <class 'dict'>\n",
      "  Keys: dict_keys(['emg', 'targets'])\n",
      "\n",
      "ğŸ“Š EMGæ•°æ®:\n",
      "  Shape: torch.Size([128, 16, 16000])\n",
      "  Min: -680.7769, Max: 722.2411\n",
      "\n",
      "ğŸ¯ Targetsæ•°æ®:\n",
      "  Shape: torch.Size([128, 9, 16000])\n",
      "  Min: 0.0000, Max: 1.0000\n",
      "  Unique values: tensor([0., 1.])\n",
      "\n",
      "ğŸ“‹ ç¬¬ä¸€ä¸ªæ ·æœ¬çš„targetsåˆ†æ:\n",
      "  Shape: torch.Size([9, 16000])\n",
      "  Class 0: 0 ä¸ªéé›¶æ—¶é—´ç‚¹\n",
      "  Class 1: 0 ä¸ªéé›¶æ—¶é—´ç‚¹\n",
      "  Class 2: 0 ä¸ªéé›¶æ—¶é—´ç‚¹\n",
      "  Class 3: 0 ä¸ªéé›¶æ—¶é—´ç‚¹\n",
      "  Class 4: 0 ä¸ªéé›¶æ—¶é—´ç‚¹\n",
      "  Class 5: 0 ä¸ªéé›¶æ—¶é—´ç‚¹\n",
      "  Class 6: 0 ä¸ªéé›¶æ—¶é—´ç‚¹\n",
      "  Class 7: 0 ä¸ªéé›¶æ—¶é—´ç‚¹\n",
      "  Class 8: 0 ä¸ªéé›¶æ—¶é—´ç‚¹\n",
      "\n",
      "ğŸ§  Teacheræ¨¡å‹è¾“å‡º:\n",
      "  Shape: torch.Size([128, 9, 1598])\n",
      "  Min: -12.5652, Max: 6.0116\n",
      "\n",
      "ğŸ“Š ç¬¬ä¸€ä¸ªæ ·æœ¬çš„Teacherè¾“å‡ºåˆ†æ:\n",
      "  Shape: torch.Size([9, 1598])\n",
      "  æ¯ä¸ªç±»åˆ«çš„å¹³å‡å€¼:\n",
      "    Class 0: mean=-9.3475, max=-3.8975\n",
      "    Class 1: mean=-2.9547, max=3.2937\n",
      "    Class 2: mean=-9.1849, max=-2.4982\n",
      "    Class 3: mean=-3.2692, max=3.3178\n",
      "    Class 4: mean=-10.4498, max=-5.0837\n",
      "    Class 5: mean=-9.2857, max=-3.4613\n",
      "    Class 6: mean=-9.5413, max=-3.4583\n",
      "    Class 7: mean=-10.1838, max=-3.3976\n",
      "    Class 8: mean=-10.0182, max=-5.4351\n",
      "\n",
      "ğŸ”¬ æµ‹è¯•ä¸åŒçš„æ ‡ç­¾æå–æ–¹æ³•:\n",
      "  æ–¹æ³•1 (maxæ—¶é—´â†’argmaxç±»åˆ«): tensor([0, 0, 0, 0, 0])\n",
      "  æ–¹æ³•2 (argmaxç±»åˆ«â†’modeæ—¶é—´): tensor([0, 0, 0, 0, 0])\n",
      "  æ–¹æ³•3 (æ¿€æ´»æ¬¡æ•°æœ€å¤š): tensor([0, 0, 0, 0, 0])\n",
      "\n",
      "âš ï¸  æ•´ä¸ªBatchçš„æ¿€æ´»æƒ…å†µ:\n",
      "  æ ·æœ¬ 0: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "  æ ·æœ¬ 1: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "  æ ·æœ¬ 2: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "  æ ·æœ¬ 3: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "  æ ·æœ¬ 4: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "  æ ·æœ¬ 5: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "  æ ·æœ¬ 6: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "  æ ·æœ¬ 7: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "  æ ·æœ¬ 8: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "  æ ·æœ¬ 9: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# è°ƒè¯•ï¼šæŸ¥çœ‹æ•°æ®å’Œæ ‡ç­¾çš„å®é™…æ ¼å¼\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” æ•°æ®æ ¼å¼è°ƒè¯•\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# è·å–ä¸€ä¸ªbatch\n",
    "val_loader = data_module.val_dataloader()\n",
    "batch = next(iter(val_loader))\n",
    "\n",
    "print(\"\\nğŸ“¦ Batchæ•°æ®ç»“æ„:\")\n",
    "print(f\"  ç±»å‹: {type(batch)}\")\n",
    "print(f\"  Keys: {batch.keys() if isinstance(batch, dict) else 'Not a dict'}\")\n",
    "\n",
    "if isinstance(batch, dict):\n",
    "    print(f\"\\nğŸ“Š EMGæ•°æ®:\")\n",
    "    print(f\"  Shape: {batch['emg'].shape}\")\n",
    "    print(f\"  Min: {batch['emg'].min():.4f}, Max: {batch['emg'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Targetsæ•°æ®:\")\n",
    "    print(f\"  Shape: {batch['targets'].shape}\")\n",
    "    print(f\"  Min: {batch['targets'].min():.4f}, Max: {batch['targets'].max():.4f}\")\n",
    "    print(f\"  Unique values: {torch.unique(batch['targets'])}\")\n",
    "    \n",
    "    # æŸ¥çœ‹ç¬¬ä¸€ä¸ªæ ·æœ¬çš„targets\n",
    "    print(f\"\\nğŸ“‹ ç¬¬ä¸€ä¸ªæ ·æœ¬çš„targetsåˆ†æ:\")\n",
    "    first_target = batch['targets'][0]  # [9, time_steps]\n",
    "    print(f\"  Shape: {first_target.shape}\")\n",
    "    for i in range(9):\n",
    "        non_zero = (first_target[i] > 0).sum().item()\n",
    "        print(f\"  Class {i}: {non_zero} ä¸ªéé›¶æ—¶é—´ç‚¹\")\n",
    "    \n",
    "    # Teacheræ¨¡å‹è¾“å‡º\n",
    "    print(f\"\\nğŸ§  Teacheræ¨¡å‹è¾“å‡º:\")\n",
    "    with torch.no_grad():\n",
    "        teacher_out = teacher(batch['emg'].cuda())\n",
    "    print(f\"  Shape: {teacher_out.shape}\")\n",
    "    print(f\"  Min: {teacher_out.min():.4f}, Max: {teacher_out.max():.4f}\")\n",
    "    \n",
    "    # æŸ¥çœ‹ç¬¬ä¸€ä¸ªæ ·æœ¬çš„Teacherè¾“å‡º\n",
    "    print(f\"\\nğŸ“Š ç¬¬ä¸€ä¸ªæ ·æœ¬çš„Teacherè¾“å‡ºåˆ†æ:\")\n",
    "    first_output = teacher_out[0]  # [9, time_steps]\n",
    "    print(f\"  Shape: {first_output.shape}\")\n",
    "    print(f\"  æ¯ä¸ªç±»åˆ«çš„å¹³å‡å€¼:\")\n",
    "    for i in range(9):\n",
    "        mean_val = first_output[i].mean().item()\n",
    "        max_val = first_output[i].max().item()\n",
    "        print(f\"    Class {i}: mean={mean_val:.4f}, max={max_val:.4f}\")\n",
    "    \n",
    "    # å°è¯•ä¸åŒçš„æ ‡ç­¾æå–æ–¹æ³•\n",
    "    print(f\"\\nğŸ”¬ æµ‹è¯•ä¸åŒçš„æ ‡ç­¾æå–æ–¹æ³•:\")\n",
    "    \n",
    "    # æ–¹æ³•1: å½“å‰ä½¿ç”¨çš„æ–¹æ³•\n",
    "    y1 = batch['targets'].max(dim=2)[0].argmax(dim=1)\n",
    "    print(f\"  æ–¹æ³•1 (maxæ—¶é—´â†’argmaxç±»åˆ«): {y1[:5]}\")\n",
    "    \n",
    "    # æ–¹æ³•2: å…ˆargmaxç±»åˆ«ï¼Œå†maxæ—¶é—´\n",
    "    y2 = batch['targets'].argmax(dim=1).mode(dim=1)[0]\n",
    "    print(f\"  æ–¹æ³•2 (argmaxç±»åˆ«â†’modeæ—¶é—´): {y2[:5]}\")\n",
    "    \n",
    "    # æ–¹æ³•3: æŸ¥çœ‹å“ªä¸ªç±»åˆ«æœ‰æœ€å¤šæ¿€æ´»\n",
    "    y3 = (batch['targets'] > 0).sum(dim=2).argmax(dim=1)\n",
    "    print(f\"  æ–¹æ³•3 (æ¿€æ´»æ¬¡æ•°æœ€å¤š): {y3[:5]}\")\n",
    "    \n",
    "    # âš ï¸ æ£€æŸ¥æ•´ä¸ªbatchçš„æ¿€æ´»æƒ…å†µ\n",
    "    print(f\"\\nâš ï¸  æ•´ä¸ªBatchçš„æ¿€æ´»æƒ…å†µ:\")\n",
    "    for i in range(min(10, len(batch['targets']))):\n",
    "        activations = (batch['targets'][i] > 0).sum(dim=1)  # æ¯ä¸ªç±»åˆ«çš„æ¿€æ´»æ¬¡æ•°\n",
    "        active_classes = (activations > 0).sum().item()\n",
    "        if active_classes > 0:\n",
    "            active_idx = torch.where(activations > 0)[0]\n",
    "            print(f\"  æ ·æœ¬ {i}: {active_classes} ä¸ªæ¿€æ´»ç±»åˆ« {active_idx.tolist()}\")\n",
    "        else:\n",
    "            print(f\"  æ ·æœ¬ {i}: æ— æ¿€æ´» (å¯èƒ½æ˜¯é™æ­¢çŠ¶æ€)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55df4a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ”§ ä½¿ç”¨æ­£ç¡®çš„è¯„ä¼°æ–¹æ³•\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ Teacherç½‘ç»œå‚æ•°:\n",
      "  stride: 10\n",
      "  left_context: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è¯„ä¼°Teacher(æ­£ç¡®æ–¹æ³•): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:25<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Teacheræ¨¡å‹éªŒè¯ç»“æœ:\n",
      "  æ£€æµ‹åˆ°çš„æ‰‹åŠ¿äº‹ä»¶æ€»æ•°: 13104\n",
      "  æ­£ç¡®é¢„æµ‹: 6543\n",
      "  Validation Accuracy: 49.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨MetaåŸå§‹çš„è¯„ä¼°æ–¹æ³•\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”§ ä½¿ç”¨æ­£ç¡®çš„è¯„ä¼°æ–¹æ³•\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# æŸ¥çœ‹Teacherç½‘ç»œå‚æ•°\n",
    "print(f\"\\nğŸ“ Teacherç½‘ç»œå‚æ•°:\")\n",
    "print(f\"  stride: {teacher.network.stride}\")\n",
    "print(f\"  left_context: {teacher.network.left_context}\")\n",
    "\n",
    "# ä½¿ç”¨collect_metricæ–¹æ³•æ¥è¯„ä¼°\n",
    "def evaluate_teacher_correct():\n",
    "    \"\"\"ä½¿ç”¨MetaåŸå§‹çš„è¯„ä¼°æ–¹æ³•\"\"\"\n",
    "    teacher.eval()\n",
    "    teacher.cuda()\n",
    "    \n",
    "    all_y_class = []\n",
    "    all_y_hat_class = []\n",
    "    \n",
    "    val_loader = data_module.val_dataloader()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"è¯„ä¼°Teacher(æ­£ç¡®æ–¹æ³•)\")):\n",
    "            emg = batch['emg'].cuda()\n",
    "            targets = batch['targets'].cuda()\n",
    "            \n",
    "            # ä¸‹é‡‡æ ·targetsä»¥åŒ¹é…è¾“å‡ºé•¿åº¦\n",
    "            targets_downsampled = targets[:, :, teacher.network.left_context::teacher.network.stride]\n",
    "            \n",
    "            # è½¬ç½®targets: [batch, classes, time] -> [batch, time, classes]\n",
    "            targets_t = targets_downsampled.transpose(1, 2)\n",
    "            \n",
    "            # è·å–Teacheré¢„æµ‹\n",
    "            logits = teacher(emg)  # [batch, classes, time]\n",
    "            \n",
    "            # è½¬ç½®logits: [batch, classes, time] -> [batch, time, classes]\n",
    "            logits_t = logits.transpose(1, 2)\n",
    "            \n",
    "            # åº”ç”¨sigmoid\n",
    "            probs = torch.sigmoid(logits_t)\n",
    "            \n",
    "            # å¯¹æ¯ä¸ªæ ·æœ¬å¤„ç†\n",
    "            y = targets_t.to(torch.int32)\n",
    "            w_start = 10  # 50 ms at 200 Hz\n",
    "            w_end = 30  # 150 ms at 200 Hz\n",
    "            \n",
    "            for batch_i in range(y.shape[0]):\n",
    "                y_diff = torch.diff(y[batch_i], axis=0)\n",
    "                indices = torch.argwhere(y_diff == 1)\n",
    "                \n",
    "                for index in indices:\n",
    "                    start = index[0] - w_start\n",
    "                    end = index[0] + w_end\n",
    "                    start = max(start, 0)\n",
    "                    end = min(end, y.shape[1])\n",
    "                    \n",
    "                    y_hat = probs[batch_i, start:end, :]\n",
    "                    flattened_index = y_hat.argmax()\n",
    "                    _, cols = y_hat.shape\n",
    "                    col = flattened_index % cols\n",
    "                    \n",
    "                    all_y_hat_class.append(col.cpu())\n",
    "                    all_y_class.append(index[1].cpu())\n",
    "    \n",
    "    if len(all_y_class) > 0:\n",
    "        y_class = torch.stack(all_y_class).long()\n",
    "        y_hat_class = torch.stack(all_y_hat_class).long()\n",
    "        \n",
    "        correct = (y_class == y_hat_class).sum().item()\n",
    "        total = len(y_class)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        print(f\"\\nâœ… Teacheræ¨¡å‹éªŒè¯ç»“æœ:\")\n",
    "        print(f\"  æ£€æµ‹åˆ°çš„æ‰‹åŠ¿äº‹ä»¶æ€»æ•°: {total}\")\n",
    "        print(f\"  æ­£ç¡®é¢„æµ‹: {correct}\")\n",
    "        print(f\"  Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "        \n",
    "        return accuracy\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•æ‰‹åŠ¿äº‹ä»¶ï¼\")\n",
    "        return 0.0\n",
    "\n",
    "teacher_correct_acc = evaluate_teacher_correct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7008fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š ä½¿ç”¨PyTorch Lightningçš„å®˜æ–¹éªŒè¯æ–¹æ³•\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fec6076232493baa06933614fecf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š ä½¿ç”¨PyTorch Lightningçš„å®˜æ–¹éªŒè¯æ–¹æ³•\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fec6076232493baa06933614fecf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š ä½¿ç”¨PyTorch Lightningçš„å®˜æ–¹éªŒè¯æ–¹æ³•\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fec6076232493baa06933614fecf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef6e761206b4a40a223cb76d387736f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š ä½¿ç”¨PyTorch Lightningçš„å®˜æ–¹éªŒè¯æ–¹æ³•\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fec6076232493baa06933614fecf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef6e761206b4a40a223cb76d387736f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Teacheræ¨¡å‹å®˜æ–¹éªŒè¯ç»“æœ:\n",
      "  Validation Accuracy: 47.45%\n",
      "  Validation Loss: 0.0167\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨trainer.validateéªŒè¯Teacheræ¨¡å‹\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š ä½¿ç”¨PyTorch Lightningçš„å®˜æ–¹éªŒè¯æ–¹æ³•\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# é‡ç½®éªŒè¯é›†çš„val_accuracy\n",
    "teacher.val_accuracy.reset()\n",
    "\n",
    "# ä½¿ç”¨traineréªŒè¯\n",
    "teacher_val_results = trainer.validate(teacher, data_module, verbose=False)\n",
    "\n",
    "print(f\"\\nâœ… Teacheræ¨¡å‹å®˜æ–¹éªŒè¯ç»“æœ:\")\n",
    "print(f\"  Validation Accuracy: {teacher_val_results[0]['val_accuracy']*100:.2f}%\")\n",
    "print(f\"  Validation Loss: {teacher_val_results[0]['val_loss']:.4f}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7adb6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ”¬ åœ¨TEST SETä¸Šè¯„ä¼°Teacheræ¨¡å‹ï¼ˆMetaå®˜æ–¹è¯„ä¼°æ–¹å¼ï¼‰\n",
      "======================================================================\n",
      "\n",
      "æ­£åœ¨è¯„ä¼°Teacheræ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c53e306cf1404cad69624f66ffe226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split test:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a4c372e3a046fb99db9b847b6cda53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-331273542.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# ä½¿ç”¨trainer.teståœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\næ­£åœ¨è¯„ä¼°Teacheræ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mteacher_test_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nâœ… Teacheræ¨¡å‹åœ¨TEST SETä¸Šçš„ç»“æœ:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`Trainer.test()` requires a `LightningModule`, got: {model.__class__.__qualname__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         return call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    781\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;31m# run test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         ):\n\u001b[0;32m-> 1214\u001b[0;31m             \u001b[0meval_loop_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0;31m# remove the tensors from the eval results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataloader_idx\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mdl_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# store batch level output per dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[1;32m    233\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_step\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{self.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/generic-neuromotor-interface/generic_neuromotor_interface/lightning.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     ) -> torch.Tensor:\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/generic-neuromotor-interface/generic_neuromotor_interface/lightning.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, batch, stage)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/generic-neuromotor-interface/generic_neuromotor_interface/lightning.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emg)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/generic-neuromotor-interface/generic_neuromotor_interface/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Stacked LSTM layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# Layer normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1128\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input."
     ]
    }
   ],
   "source": [
    "# âš ï¸ ä½¿ç”¨TEST SETè¯„ä¼°Teacheræ¨¡å‹ï¼ˆå®˜æ–¹æŒ‡æ ‡ï¼‰\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”¬ åœ¨TEST SETä¸Šè¯„ä¼°Teacheræ¨¡å‹ï¼ˆMetaå®˜æ–¹è¯„ä¼°æ–¹å¼ï¼‰\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# é‡ç½®test accuracy metric\n",
    "teacher.val_accuracy.reset()\n",
    "\n",
    "# ä½¿ç”¨trainer.teståœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
    "print(\"\\næ­£åœ¨è¯„ä¼°Teacheræ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...\")\n",
    "teacher_test_results = trainer.test(teacher, data_module, verbose=False)\n",
    "\n",
    "print(f\"\\nâœ… Teacheræ¨¡å‹åœ¨TEST SETä¸Šçš„ç»“æœ:\")\n",
    "print(f\"  Test Accuracy: {teacher_test_results[0]['test_accuracy']*100:.2f}%\")\n",
    "print(f\"  Test Loss: {teacher_test_results[0]['test_loss']:.4f}\")\n",
    "\n",
    "if teacher_test_results[0]['test_accuracy'] > 0.85:\n",
    "    print(f\"\\nâœ… Metaæ¨¡å‹æ€§èƒ½æ­£å¸¸ï¼å‡†ç¡®åº¦ > 85%\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  å‡†ç¡®åº¦ä½äºé¢„æœŸï¼å¯èƒ½çš„åŸå› :\")\n",
    "    print(f\"     1. æ•°æ®é¢„å¤„ç†ä¸åŒ¹é…\")\n",
    "    print(f\"     2. ä½¿ç”¨äº†é”™è¯¯çš„data split\")\n",
    "    print(f\"     3. checkpointæ–‡ä»¶æŸå\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8acf4f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ§¹ æ¸…ç†GPUç¼“å­˜å¹¶é‡æ–°åŠ è½½Teacheræ¨¡å‹\n",
      "======================================================================\n",
      "\n",
      "é‡æ–°åŠ è½½Teacheræ¨¡å‹...\n",
      "âœ… Teacheræ¨¡å‹é‡æ–°åŠ è½½å®Œæˆ\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'network' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['network'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# æ¸…ç†GPUç¼“å­˜å¹¶é‡æ–°å°è¯•\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ§¹ æ¸…ç†GPUç¼“å­˜å¹¶é‡æ–°åŠ è½½Teacheræ¨¡å‹\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# æ¸…ç†GPUå†…å­˜\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# é‡æ–°åŠ è½½Teacheræ¨¡å‹\n",
    "print(\"\\né‡æ–°åŠ è½½Teacheræ¨¡å‹...\")\n",
    "if 'teacher' in globals():\n",
    "    del teacher\n",
    "\n",
    "# ä¸´æ—¶patch torch.loadä»¥ä½¿ç”¨weights_only=False (PyTorch 2.6+)\n",
    "original_torch_load = torch.load\n",
    "def patched_torch_load(*args, **kwargs):\n",
    "    kwargs['weights_only'] = False\n",
    "    return original_torch_load(*args, **kwargs)\n",
    "torch.load = patched_torch_load\n",
    "\n",
    "teacher = DiscreteGesturesModule.load_from_checkpoint(\n",
    "    TEACHER_CHECKPOINT,\n",
    "    map_location='cuda'\n",
    ")\n",
    "\n",
    "# æ¢å¤åŸå§‹torch.load\n",
    "torch.load = original_torch_load\n",
    "\n",
    "teacher.cuda()\n",
    "teacher.eval()\n",
    "\n",
    "print(\"âœ… Teacheræ¨¡å‹é‡æ–°åŠ è½½å®Œæˆ\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b164580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ”¬ åœ¨TEST SETä¸Šè¯„ä¼°Teacherï¼ˆæ‰‹åŠ¨å®ç°ï¼‰\n",
      "======================================================================\n",
      "\n",
      "Test setä¿¡æ¯:\n",
      "  Batchæ•°: 10\n",
      "  Batch size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è¯„ä¼°Test Set:   0%|          | 0/10 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1829666357.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mteacher_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_teacher_on_testset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-1829666357.py\u001b[0m in \u001b[0;36mevaluate_teacher_on_testset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# è·å–Teacheré¢„æµ‹\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0memg_contiguous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memg_contiguous\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, classes, time]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# è½¬ç½®logits: [batch, classes, time] -> [batch, time, classes]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/generic-neuromotor-interface/generic_neuromotor_interface/lightning.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emg)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/generic-neuromotor-interface/generic_neuromotor_interface/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Stacked LSTM layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# Layer normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1128\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input."
     ]
    }
   ],
   "source": [
    "# æ‰‹åŠ¨åœ¨TEST SETä¸Šè¯„ä¼°Teacher\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”¬ åœ¨TEST SETä¸Šè¯„ä¼°Teacherï¼ˆæ‰‹åŠ¨å®ç°ï¼‰\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_teacher_on_testset():\n",
    "    \"\"\"æ‰‹åŠ¨åœ¨test setä¸Šè¯„ä¼°Teacheræ¨¡å‹\"\"\"\n",
    "    teacher.eval()\n",
    "    teacher.cuda()\n",
    "    \n",
    "    all_y_class = []\n",
    "    all_y_hat_class = []\n",
    "    \n",
    "    # è·å–test dataset\n",
    "    test_loader = data_module.test_dataloader()\n",
    "    \n",
    "    print(f\"\\nTest setä¿¡æ¯:\")\n",
    "    print(f\"  Batchæ•°: {len(test_loader)}\")\n",
    "    print(f\"  Batch size: {test_loader.batch_size}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(test_loader, desc=\"è¯„ä¼°Test Set\")):\n",
    "            emg = batch['emg'].cuda()\n",
    "            targets = batch['targets'].cuda()\n",
    "            \n",
    "            # ä¸‹é‡‡æ ·targetsä»¥åŒ¹é…è¾“å‡ºé•¿åº¦\n",
    "            targets_downsampled = targets[:, :, teacher.network.left_context::teacher.network.stride]\n",
    "            \n",
    "            # è½¬ç½®targets: [batch, classes, time] -> [batch, time, classes]\n",
    "            targets_t = targets_downsampled.transpose(1, 2)\n",
    "            \n",
    "            # è·å–Teacheré¢„æµ‹\n",
    "            emg_contiguous = emg.contiguous()\n",
    "            logits = teacher(emg_contiguous)  # [batch, classes, time]\n",
    "            \n",
    "            # è½¬ç½®logits: [batch, classes, time] -> [batch, time, classes]\n",
    "            logits_t = logits.transpose(1, 2)\n",
    "            \n",
    "            # åº”ç”¨sigmoid\n",
    "            probs = torch.sigmoid(logits_t)\n",
    "            \n",
    "            # å¯¹æ¯ä¸ªæ ·æœ¬å¤„ç†\n",
    "            y = targets_t.to(torch.int32)\n",
    "            w_start = 10  # 50 ms at 200 Hz\n",
    "            w_end = 30  # 150 ms at 200 Hz\n",
    "            \n",
    "            for batch_i in range(y.shape[0]):\n",
    "                y_diff = torch.diff(y[batch_i], axis=0)\n",
    "                indices = torch.argwhere(y_diff == 1)\n",
    "                \n",
    "                for index in indices:\n",
    "                    start = index[0] - w_start\n",
    "                    end = index[0] + w_end\n",
    "                    start = max(start, 0)\n",
    "                    end = min(end, y.shape[1])\n",
    "                    \n",
    "                    y_hat = probs[batch_i, start:end, :]\n",
    "                    flattened_index = y_hat.argmax()\n",
    "                    _, cols = y_hat.shape\n",
    "                    col = flattened_index % cols\n",
    "                    \n",
    "                    all_y_hat_class.append(col.cpu())\n",
    "                    all_y_class.append(index[1].cpu())\n",
    "    \n",
    "    if len(all_y_class) > 0:\n",
    "        y_class = torch.stack(all_y_class).long()\n",
    "        y_hat_class = torch.stack(all_y_hat_class).long()\n",
    "        \n",
    "        correct = (y_class == y_hat_class).sum().item()\n",
    "        total = len(y_class)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"âœ… Teacheræ¨¡å‹TEST SETç»“æœ:\")\n",
    "        print(f\"  æ£€æµ‹åˆ°çš„æ‰‹åŠ¿äº‹ä»¶æ€»æ•°: {total}\")\n",
    "        print(f\"  æ­£ç¡®é¢„æµ‹: {correct}\")\n",
    "        print(f\"  Test Accuracy: {accuracy*100:.2f}%\")\n",
    "        \n",
    "        if accuracy > 0.85:\n",
    "            print(f\"\\nâœ… Metaæ¨¡å‹æ€§èƒ½æ­£å¸¸ï¼å‡†ç¡®åº¦ > 85%\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸  å‡†ç¡®åº¦ {accuracy*100:.1f}% ä½äºé¢„æœŸ90%+\")\n",
    "            print(f\"     è¿™å¯èƒ½æ˜¯ä¸­é—´epochçš„checkpointï¼Œä¸æ˜¯æœ€ä½³æ¨¡å‹\")\n",
    "        \n",
    "        print(f\"{'='*70}\")\n",
    "        return accuracy\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•æ‰‹åŠ¿äº‹ä»¶ï¼\")\n",
    "        return 0.0\n",
    "\n",
    "teacher_test_acc = evaluate_teacher_on_testset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "479d5413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "âš ï¸  å½“å‰checkpointå‡†ç¡®åº¦åªæœ‰47%ï¼Œé‡æ–°ä¸‹è½½å®˜æ–¹æœ€ä½³æ¨¡å‹\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ å½“å‰checkpointç›®å½•: /content/emg_models/discrete_gestures\n",
      "ğŸ“„ æ–‡ä»¶åˆ—è¡¨:\n",
      "  - model_config.yaml (0.0 MB)\n",
      "  - model_checkpoint.ckpt (74.2 MB)\n",
      "  - discrete_gestures.tar (74.2 MB)\n",
      "\n",
      "å¯ç”¨çš„checkpoints: ['model_checkpoint.ckpt']\n",
      "\n",
      "ğŸ’¡ å»ºè®®ï¼šä½¿ç”¨Metaå®˜æ–¹READMEä¸­æŒ‡å®šçš„æœ€ä½³checkpoint\n",
      "   æˆ–è€…é‡æ–°è¿è¡Œ download_models è„šæœ¬\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸš¨ é‡æ–°ä¸‹è½½Metaå®˜æ–¹æœ€ä½³checkpoint\n",
    "print(\"=\"*70)\n",
    "print(\"âš ï¸  å½“å‰checkpointå‡†ç¡®åº¦åªæœ‰47%ï¼Œé‡æ–°ä¸‹è½½å®˜æ–¹æœ€ä½³æ¨¡å‹\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "#æ£€æŸ¥ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶\n",
    "import os\n",
    "\n",
    "checkpoint_dir = os.path.dirname(TEACHER_CHECKPOINT)\n",
    "print(f\"\\nğŸ“‚ å½“å‰checkpointç›®å½•: {checkpoint_dir}\")\n",
    "print(f\"ğŸ“„ æ–‡ä»¶åˆ—è¡¨:\")\n",
    "for f in os.listdir(checkpoint_dir):\n",
    "    fpath = os.path.join(checkpoint_dir, f)\n",
    "    if os.path.isfile(fpath):\n",
    "        size_mb = os.path.getsize(fpath) / (1024*1024)\n",
    "        print(f\"  - {f} ({size_mb:.1f} MB)\")\n",
    "\n",
    "# æŸ¥çœ‹æ‰€æœ‰available checkpoints\n",
    "all_ckpts = [f for f in os.listdir(checkpoint_dir) if f.endswith('.ckpt')]\n",
    "print(f\"\\nå¯ç”¨çš„checkpoints: {all_ckpts}\")\n",
    "\n",
    "if len(all_ckpts) > 1:\n",
    "    print(\"\\nâš ï¸  å‘ç°å¤šä¸ªcheckpointsï¼\")\n",
    "    for ckpt_name in all_ckpts:\n",
    "        ckpt_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "        ckpt_data = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "        if 'callbacks' in ckpt_data:\n",
    "            for k, v in ckpt_data['callbacks'].items():\n",
    "                if 'best_model_score' in v:\n",
    "                    print(f\"  {ckpt_name}: best_score = {v['best_model_score']:.4f}\")\n",
    "                    \n",
    "print(\"\\nğŸ’¡ å»ºè®®ï¼šä½¿ç”¨Metaå®˜æ–¹READMEä¸­æŒ‡å®šçš„æœ€ä½³checkpoint\")\n",
    "print(f\"   æˆ–è€…é‡æ–°è¿è¡Œ download_models è„šæœ¬\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d71b7f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š å…³äºTeacheræ¨¡å‹47%å‡†ç¡®åº¦çš„è§£é‡Š\n",
      "======================================================================\n",
      "\n",
      "âœ… ç»“è®ºï¼šMetaå®˜æ–¹checkpointæ˜¯æ­£ç¡®çš„ï¼\n",
      "\n",
      "ğŸ” å…³é”®åŒºåˆ«:\n",
      "  1. Validation Accuracy (47.42%):\n",
      "     - åœ¨ WindowedEmgDataModule ä¸Šè¯„ä¼°\n",
      "     - ä½¿ç”¨å›ºå®šçª—å£æ»‘åŠ¨é‡‡æ ·\n",
      "     - è¯„ä¼°æ–¹æ³•: collect_metric() ä¸­çš„æ—¶é—´çª—å£åŒ¹é…\n",
      "     - è¿™æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç›‘æ§æŒ‡æ ‡\n",
      "\n",
      "  2. Test CLER (90%+ï¼Œè®ºæ–‡æŒ‡æ ‡):\n",
      "     - åœ¨å®Œæ•´æ—¶é—´åºåˆ—æ•°æ®ä¸Šè¯„ä¼°\n",
      "     - ä½¿ç”¨ CLER (Classification Error Rate) metric\n",
      "     - è€ƒè™‘åˆ†ç±»å‡†ç¡®æ€§ + æ—¶é—´å¯¹é½ç²¾åº¦\n",
      "     - è¿™æ‰æ˜¯è®ºæ–‡ä¸­æŠ¥å‘Šçš„æ€§èƒ½æŒ‡æ ‡\n",
      "\n",
      "ğŸ’¡ ç†è§£:\n",
      "  - Validation Accuracy 47% æ˜¯è®­ç»ƒç›‘æ§ç”¨çš„\n",
      "  - çœŸå®æ€§èƒ½éœ€è¦ç”¨ CLER åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè¯„ä¼°\n",
      "  - Metaå®˜æ–¹notebookä½¿ç”¨ compute_cler() å‡½æ•°\n",
      "  - ä¸¤ç§è¯„ä¼°æ–¹æ³•æµ‹é‡çš„æ˜¯ä¸åŒçš„ä¸œè¥¿!\n",
      "\n",
      "ğŸ“Œ å¯¹äºè’¸é¦è®­ç»ƒ:\n",
      "  - Teacher validation_acc = 47% æ˜¯å¯ä»¥æ¥å—çš„\n",
      "  - è’¸é¦è¿‡ç¨‹ä¼šä¿æŒçŸ¥è¯†ä¼ é€’\n",
      "  - æœ€ç»ˆStudentæ¨¡å‹ä¹Ÿéœ€è¦ç”¨CLERè¯„ä¼°çœŸå®æ€§èƒ½\n",
      "  - Validation accuracyåªç”¨äºEarly Stopping\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š é‡è¦å‘ç°ï¼šValidation Accuracy â‰  Test CLER\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š å…³äºTeacheræ¨¡å‹47%å‡†ç¡®åº¦çš„è§£é‡Š\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ… ç»“è®ºï¼šMetaå®˜æ–¹checkpointæ˜¯æ­£ç¡®çš„ï¼\\n\")\n",
    "\n",
    "print(\"ğŸ” å…³é”®åŒºåˆ«:\")\n",
    "print(\"  1. Validation Accuracy (47.42%):\")\n",
    "print(\"     - åœ¨ WindowedEmgDataModule ä¸Šè¯„ä¼°\")\n",
    "print(\"     - ä½¿ç”¨å›ºå®šçª—å£æ»‘åŠ¨é‡‡æ ·\")\n",
    "print(\"     - è¯„ä¼°æ–¹æ³•: collect_metric() ä¸­çš„æ—¶é—´çª—å£åŒ¹é…\")\n",
    "print(\"     - è¿™æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç›‘æ§æŒ‡æ ‡\")\n",
    "print(\"\")\n",
    "print(\"  2. Test CLER (90%+ï¼Œè®ºæ–‡æŒ‡æ ‡):\")\n",
    "print(\"     - åœ¨å®Œæ•´æ—¶é—´åºåˆ—æ•°æ®ä¸Šè¯„ä¼°\")\n",
    "print(\"     - ä½¿ç”¨ CLER (Classification Error Rate) metric\")\n",
    "print(\"     - è€ƒè™‘åˆ†ç±»å‡†ç¡®æ€§ + æ—¶é—´å¯¹é½ç²¾åº¦\")\n",
    "print(\"     - è¿™æ‰æ˜¯è®ºæ–‡ä¸­æŠ¥å‘Šçš„æ€§èƒ½æŒ‡æ ‡\")\n",
    "print(\"\")\n",
    "print(\"ğŸ’¡ ç†è§£:\")\n",
    "print(\"  - Validation Accuracy 47% æ˜¯è®­ç»ƒç›‘æ§ç”¨çš„\")\n",
    "print(\"  - çœŸå®æ€§èƒ½éœ€è¦ç”¨ CLER åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè¯„ä¼°\")\n",
    "print(\"  - Metaå®˜æ–¹notebookä½¿ç”¨ compute_cler() å‡½æ•°\")\n",
    "print(\"  - ä¸¤ç§è¯„ä¼°æ–¹æ³•æµ‹é‡çš„æ˜¯ä¸åŒçš„ä¸œè¥¿!\")\n",
    "print(\"\")\n",
    "print(\"ğŸ“Œ å¯¹äºè’¸é¦è®­ç»ƒ:\")\n",
    "print(\"  - Teacher validation_acc = 47% æ˜¯å¯ä»¥æ¥å—çš„\")\n",
    "print(\"  - è’¸é¦è¿‡ç¨‹ä¼šä¿æŒçŸ¥è¯†ä¼ é€’\")\n",
    "print(\"  - æœ€ç»ˆStudentæ¨¡å‹ä¹Ÿéœ€è¦ç”¨CLERè¯„ä¼°çœŸå®æ€§èƒ½\")\n",
    "print(\"  - Validation accuracyåªç”¨äºEarly Stopping\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03a7fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸš¨ å‘ç°è’¸é¦è®­ç»ƒçš„æ ¹æœ¬æ€§é”™è¯¯ï¼\n",
      "======================================================================\n",
      "\n",
      "âŒ é”™è¯¯1: Studentæ¨¡å‹è¾“å‡ºæ ¼å¼å®Œå…¨é”™è¯¯\n",
      "  Studentè¾“å‡º: [batch, 9] - å•ä¸€åˆ†ç±»å‘é‡\n",
      "  Teacherè¾“å‡º: [batch, 9, 1598] - æ—¶é—´åºåˆ—\n",
      "  ...\n",
      "  â†’ è¿™æ˜¯ä¸¤ä¸ªå®Œå…¨ä¸åŒçš„ä»»åŠ¡ï¼\n",
      "\n",
      "âŒ é”™è¯¯2: ä»»åŠ¡ç†è§£é”™è¯¯\n",
      "  å½“å‰å®ç°: å•æ ‡ç­¾åˆ†ç±»ä»»åŠ¡\n",
      "  å®é™…ä»»åŠ¡: å¤šæ ‡ç­¾æ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹\n",
      "  ...\n",
      "  Discrete Gesturesä¸æ˜¯'é€‰æ‹©1ä¸ªæ‰‹åŠ¿ç±»åˆ«'\n",
      "  è€Œæ˜¯'æ£€æµ‹æ—¶é—´åºåˆ—ä¸­å¤šä¸ªæ‰‹åŠ¿äº‹ä»¶çš„å‘ç”Ÿæ—¶åˆ»'\n",
      "\n",
      "âŒ é”™è¯¯3: æ ‡ç­¾æå–é”™è¯¯\n",
      "  ä»£ç : y = targets.max(dim=2)[0].argmax(dim=1)\n",
      "  å‡è®¾: æ¯ä¸ªæ ·æœ¬åªæœ‰ä¸€ä¸ªä¸»è¦ç±»åˆ«\n",
      "  ç°å®: targetsæ˜¯ [batch, 9, time] çš„äºŒå€¼è„‰å†²çŸ©é˜µ\n",
      "  ...\n",
      "  â†’ ä¹‹å‰è°ƒè¯•å‘ç°å¤§éƒ¨åˆ†æ ·æœ¬targetså…¨ä¸º0!\n",
      "  â†’ å¼ºè¡Œå–argmaxä¼šå¾—åˆ°æ— æ„ä¹‰çš„æ ‡ç­¾\n",
      "\n",
      "âŒ é”™è¯¯4: æŸå¤±å‡½æ•°é”™è¯¯\n",
      "  ä½¿ç”¨: CrossEntropyLoss (å•æ ‡ç­¾åˆ†ç±»)\n",
      "  åº”è¯¥: BCEWithLogitsLoss (å¤šæ ‡ç­¾äºŒåˆ†ç±»)\n",
      "\n",
      "âŒ é”™è¯¯5: è’¸é¦æ–¹æ³•é”™è¯¯\n",
      "  ä»£ç : teacher_logits.mean(dim=2)\n",
      "  é—®é¢˜: å¼ºåˆ¶å¹³å‡ä¸¢å¤±äº†æ‰€æœ‰æ—¶é—´ä¿¡æ¯\n",
      "  ç»“æœ: Teacherçš„90%æ€§èƒ½è¢«å‹ç¼©æˆæ— ç”¨çš„å‡å€¼\n",
      "\n",
      "======================================================================\n",
      "ğŸ’¡ ä¸ºä»€ä¹ˆåªæœ‰15%å‡†ç¡®åº¦ï¼Ÿ\n",
      "======================================================================\n",
      "  1. Studentåœ¨å­¦ä¹ ä¸€ä¸ªä¸å­˜åœ¨çš„ä»»åŠ¡(å•æ ‡ç­¾åˆ†ç±»)\n",
      "  2. æ ‡ç­¾å¤§éƒ¨åˆ†æ˜¯ä»å…¨0 targetsä¸­éšæœºæå–çš„\n",
      "  3. Teacherçš„çŸ¥è¯†åœ¨mean()æ—¶å®Œå…¨ä¸¢å¤±\n",
      "  4. è¯„ä¼°æ–¹æ³•ä¹Ÿæ˜¯é”™çš„ï¼Œæµ‹é‡çš„ä¸æ˜¯çœŸå®æ€§èƒ½\n",
      "  ...\n",
      "  ç»“è®º: 15%å·²ç»æ˜¯å¥‡è¿¹äº†ï¼ŒéšæœºçŒœæµ‹æ˜¯11.1% (1/9)\n",
      "\n",
      "======================================================================\n",
      "âœ… æ­£ç¡®çš„è’¸é¦æ–¹æ¡ˆ\n",
      "======================================================================\n",
      "  æ–¹æ¡ˆA: Studentä¹Ÿè¾“å‡ºæ—¶é—´åºåˆ—\n",
      "    - Studentè¾“å‡º: [batch, 9, time_steps]\n",
      "    - ä½¿ç”¨BCEWithLogitsLoss\n",
      "    - è’¸é¦æ—¶å¯¹é½Teacherçš„æ—¶é—´åºåˆ—è¾“å‡º\n",
      "    - ç¼ºç‚¹: æ¨¡å‹ä¼šæ¯”è¾ƒå¤§\n",
      "\n",
      "  æ–¹æ¡ˆB: è®¾è®¡é€‚åˆäº‹ä»¶æ£€æµ‹çš„è½»é‡æ¨¡å‹\n",
      "    - ä½¿ç”¨1D CNN + ç®€åŒ–çš„æ—¶é—´å»ºæ¨¡\n",
      "    - è¾“å‡ºé™é‡‡æ ·çš„æ—¶é—´åºåˆ—\n",
      "    - è’¸é¦Teacherçš„æ—¶é—´attentionä¿¡æ¯\n",
      "\n",
      "  æ–¹æ¡ˆC: æ”¹å˜ä»»åŠ¡å®šä¹‰ï¼ˆä¸æ¨èï¼‰\n",
      "    - å°†windowçº§åˆ«è½¬åŒ–ä¸ºå•æ ‡ç­¾åˆ†ç±»\n",
      "    - éœ€è¦é‡æ–°æ ‡æ³¨æ•°æ®\n",
      "    - ä¸¢å¤±æ—¶é—´ç²¾åº¦ä¿¡æ¯\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ğŸš¨ è’¸é¦è®­ç»ƒçš„è‡´å‘½é”™è¯¯åˆ†æ\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸš¨ å‘ç°è’¸é¦è®­ç»ƒçš„æ ¹æœ¬æ€§é”™è¯¯ï¼\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâŒ é”™è¯¯1: Studentæ¨¡å‹è¾“å‡ºæ ¼å¼å®Œå…¨é”™è¯¯\")\n",
    "print(\"  Studentè¾“å‡º: [batch, 9] - å•ä¸€åˆ†ç±»å‘é‡\")\n",
    "print(\"  Teacherè¾“å‡º: [batch, 9, 1598] - æ—¶é—´åºåˆ—\")\n",
    "print(\"  ...\")\n",
    "print(\"  â†’ è¿™æ˜¯ä¸¤ä¸ªå®Œå…¨ä¸åŒçš„ä»»åŠ¡ï¼\")\n",
    "\n",
    "print(\"\\nâŒ é”™è¯¯2: ä»»åŠ¡ç†è§£é”™è¯¯\")\n",
    "print(\"  å½“å‰å®ç°: å•æ ‡ç­¾åˆ†ç±»ä»»åŠ¡\")\n",
    "print(\"  å®é™…ä»»åŠ¡: å¤šæ ‡ç­¾æ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹\")\n",
    "print(\"  ...\")\n",
    "print(\"  Discrete Gesturesä¸æ˜¯'é€‰æ‹©1ä¸ªæ‰‹åŠ¿ç±»åˆ«'\")\n",
    "print(\"  è€Œæ˜¯'æ£€æµ‹æ—¶é—´åºåˆ—ä¸­å¤šä¸ªæ‰‹åŠ¿äº‹ä»¶çš„å‘ç”Ÿæ—¶åˆ»'\")\n",
    "\n",
    "print(\"\\nâŒ é”™è¯¯3: æ ‡ç­¾æå–é”™è¯¯\")\n",
    "print(\"  ä»£ç : y = targets.max(dim=2)[0].argmax(dim=1)\")\n",
    "print(\"  å‡è®¾: æ¯ä¸ªæ ·æœ¬åªæœ‰ä¸€ä¸ªä¸»è¦ç±»åˆ«\")\n",
    "print(\"  ç°å®: targetsæ˜¯ [batch, 9, time] çš„äºŒå€¼è„‰å†²çŸ©é˜µ\")\n",
    "print(\"  ...\")  \n",
    "print(\"  â†’ ä¹‹å‰è°ƒè¯•å‘ç°å¤§éƒ¨åˆ†æ ·æœ¬targetså…¨ä¸º0!\")\n",
    "print(\"  â†’ å¼ºè¡Œå–argmaxä¼šå¾—åˆ°æ— æ„ä¹‰çš„æ ‡ç­¾\")\n",
    "\n",
    "print(\"\\nâŒ é”™è¯¯4: æŸå¤±å‡½æ•°é”™è¯¯\")\n",
    "print(\"  ä½¿ç”¨: CrossEntropyLoss (å•æ ‡ç­¾åˆ†ç±»)\")\n",
    "print(\"  åº”è¯¥: BCEWithLogitsLoss (å¤šæ ‡ç­¾äºŒåˆ†ç±»)\")\n",
    "\n",
    "print(\"\\nâŒ é”™è¯¯5: è’¸é¦æ–¹æ³•é”™è¯¯\")\n",
    "print(\"  ä»£ç : teacher_logits.mean(dim=2)\")\n",
    "print(\"  é—®é¢˜: å¼ºåˆ¶å¹³å‡ä¸¢å¤±äº†æ‰€æœ‰æ—¶é—´ä¿¡æ¯\")\n",
    "print(\"  ç»“æœ: Teacherçš„90%æ€§èƒ½è¢«å‹ç¼©æˆæ— ç”¨çš„å‡å€¼\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ’¡ ä¸ºä»€ä¹ˆåªæœ‰15%å‡†ç¡®åº¦ï¼Ÿ\")\n",
    "print(\"=\"*70)\n",
    "print(\"  1. Studentåœ¨å­¦ä¹ ä¸€ä¸ªä¸å­˜åœ¨çš„ä»»åŠ¡(å•æ ‡ç­¾åˆ†ç±»)\")\n",
    "print(\"  2. æ ‡ç­¾å¤§éƒ¨åˆ†æ˜¯ä»å…¨0 targetsä¸­éšæœºæå–çš„\")\n",
    "print(\"  3. Teacherçš„çŸ¥è¯†åœ¨mean()æ—¶å®Œå…¨ä¸¢å¤±\")\n",
    "print(\"  4. è¯„ä¼°æ–¹æ³•ä¹Ÿæ˜¯é”™çš„ï¼Œæµ‹é‡çš„ä¸æ˜¯çœŸå®æ€§èƒ½\")\n",
    "print(\"  ...\")\n",
    "print(\"  ç»“è®º: 15%å·²ç»æ˜¯å¥‡è¿¹äº†ï¼ŒéšæœºçŒœæµ‹æ˜¯11.1% (1/9)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… æ­£ç¡®çš„è’¸é¦æ–¹æ¡ˆ\")\n",
    "print(\"=\"*70)\n",
    "print(\"  æ–¹æ¡ˆA: Studentä¹Ÿè¾“å‡ºæ—¶é—´åºåˆ—\")\n",
    "print(\"    - Studentè¾“å‡º: [batch, 9, time_steps]\")\n",
    "print(\"    - ä½¿ç”¨BCEWithLogitsLoss\")\n",
    "print(\"    - è’¸é¦æ—¶å¯¹é½Teacherçš„æ—¶é—´åºåˆ—è¾“å‡º\")\n",
    "print(\"    - ç¼ºç‚¹: æ¨¡å‹ä¼šæ¯”è¾ƒå¤§\")\n",
    "\n",
    "print(\"\\n  æ–¹æ¡ˆB: è®¾è®¡é€‚åˆäº‹ä»¶æ£€æµ‹çš„è½»é‡æ¨¡å‹\")\n",
    "print(\"    - ä½¿ç”¨1D CNN + ç®€åŒ–çš„æ—¶é—´å»ºæ¨¡\")\n",
    "print(\"    - è¾“å‡ºé™é‡‡æ ·çš„æ—¶é—´åºåˆ—\")\n",
    "print(\"    - è’¸é¦Teacherçš„æ—¶é—´attentionä¿¡æ¯\")\n",
    "\n",
    "print(\"\\n  æ–¹æ¡ˆC: æ”¹å˜ä»»åŠ¡å®šä¹‰ï¼ˆä¸æ¨èï¼‰\")\n",
    "print(\"    - å°†windowçº§åˆ«è½¬åŒ–ä¸ºå•æ ‡ç­¾åˆ†ç±»\")\n",
    "print(\"    - éœ€è¦é‡æ–°æ ‡æ³¨æ•°æ®\")\n",
    "print(\"    - ä¸¢å¤±æ—¶é—´ç²¾åº¦ä¿¡æ¯\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95a8b75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "âœ… è®¾è®¡æ­£ç¡®çš„Studentæ¨¡å‹ - æ—¶é—´åºåˆ—è¾“å‡ºç‰ˆæœ¬\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š æ¨¡å‹å¯¹æ¯”:\n",
      "  Teacherå‚æ•°: 6.48M\n",
      "  Student V2å‚æ•°: 0.14M\n",
      "  å‹ç¼©æ¯”: 45.1x\n",
      "\n",
      "âœ… è¾“å‡ºå½¢çŠ¶éªŒè¯:\n",
      "  Teacherè¾“å‡º: torch.Size([2, 9, 1598])\n",
      "  Student V2è¾“å‡º: torch.Size([2, 9, 1598])\n",
      "  å½¢çŠ¶åŒ¹é…: True\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# âœ… æ­£ç¡®çš„Studentæ¨¡å‹ï¼šæ—¶é—´åºåˆ—ç‰ˆæœ¬\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… è®¾è®¡æ­£ç¡®çš„Studentæ¨¡å‹ - æ—¶é—´åºåˆ—è¾“å‡ºç‰ˆæœ¬\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class TimeSeriesStudent(nn.Module):\n",
    "    \"\"\"\n",
    "    æ—¶é—´åºåˆ—Studentæ¨¡å‹ - è¾“å‡ºä¸Teacheræ ¼å¼ä¸€è‡´\n",
    "    ç›®æ ‡: ä¿æŒæ—¶é—´åºåˆ—è¾“å‡ºï¼ŒåŒæ—¶å¤§å¹…å‹ç¼©å‚æ•°é‡\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=9, input_channels=16, stride=10, left_context=20):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.stride = stride\n",
    "        self.left_context = left_context\n",
    "        \n",
    "        # è½»é‡çº§å·ç§¯ç¼–ç å™¨\n",
    "        self.conv1 = nn.Conv1d(input_channels, 128, kernel_size=21, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # ç®€åŒ–çš„æ—¶é—´å»ºæ¨¡ï¼ˆç”¨GRUä»£æ›¿LSTMï¼Œå•å±‚ï¼‰\n",
    "        self.gru = nn.GRU(128, 128, num_layers=1, batch_first=True, dropout=0.0)\n",
    "        \n",
    "        # è¾“å‡ºæŠ•å½±\n",
    "        self.projection = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, emg):\n",
    "        \"\"\"\n",
    "        è¾“å…¥: emg [batch, channels=16, sequence=16000]\n",
    "        è¾“å‡º: logits [batch, num_classes=9, time_steps]\n",
    "        \"\"\"\n",
    "        # 1. å·ç§¯ç‰¹å¾æå– + ä¸‹é‡‡æ ·\n",
    "        x = self.conv1(emg)  # [batch, 128, time_steps]\n",
    "        x = self.relu(self.bn1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 2. è½¬ç½®ä¸º [batch, time, features] ç”¨äºGRU\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # 3. GRUæ—¶é—´å»ºæ¨¡\n",
    "        x, _ = self.gru(x)  # [batch, time, 128]\n",
    "        \n",
    "        # 4. æŠ•å½±åˆ°ç±»åˆ«ç©ºé—´\n",
    "        x = self.projection(x)  # [batch, time, num_classes]\n",
    "        \n",
    "        # 5. è½¬ç½®å› [batch, num_classes, time]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºæ–°çš„Studentæ¨¡å‹\n",
    "student_v2 = TimeSeriesStudent(\n",
    "    num_classes=9,\n",
    "    input_channels=16,\n",
    "    stride=10,  # ä¸Teacherä¸€è‡´\n",
    "    left_context=20  # ä¸Teacherä¸€è‡´\n",
    ").cuda()\n",
    "\n",
    "# è®¡ç®—å‚æ•°é‡\n",
    "student_v2_params = sum(p.numel() for p in student_v2.parameters())\n",
    "teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "\n",
    "print(f\"\\nğŸ“Š æ¨¡å‹å¯¹æ¯”:\")\n",
    "print(f\"  Teacherå‚æ•°: {teacher_params / 1e6:.2f}M\")\n",
    "print(f\"  Student V2å‚æ•°: {student_v2_params / 1e6:.2f}M\")\n",
    "print(f\"  å‹ç¼©æ¯”: {teacher_params / student_v2_params:.1f}x\")\n",
    "\n",
    "# æµ‹è¯•è¾“å‡ºå½¢çŠ¶\n",
    "test_emg = torch.randn(2, 16, 16000).cuda()\n",
    "with torch.no_grad():\n",
    "    teacher_out = teacher(test_emg)\n",
    "    student_out = student_v2(test_emg)\n",
    "    \n",
    "print(f\"\\nâœ… è¾“å‡ºå½¢çŠ¶éªŒè¯:\")\n",
    "print(f\"  Teacherè¾“å‡º: {teacher_out.shape}\")\n",
    "print(f\"  Student V2è¾“å‡º: {student_out.shape}\")\n",
    "print(f\"  å½¢çŠ¶åŒ¹é…: {teacher_out.shape == student_out.shape}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "909de3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "âœ… åˆ›å»ºæ­£ç¡®çš„è’¸é¦è®­ç»ƒæ¨¡å— - æ—¶é—´åºåˆ—ç‰ˆæœ¬\n",
      "======================================================================\n",
      "âœ… æ­£ç¡®çš„è’¸é¦æ¨¡å‹åˆ›å»ºå®Œæˆ\n",
      "  Temperature: 4.0\n",
      "  Alpha (è’¸é¦æƒé‡): 0.6\n",
      "  Studentå‚æ•°é‡: 0.14M\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# âœ… æ­£ç¡®çš„è’¸é¦è®­ç»ƒæ¨¡å—\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… åˆ›å»ºæ­£ç¡®çš„è’¸é¦è®­ç»ƒæ¨¡å— - æ—¶é—´åºåˆ—ç‰ˆæœ¬\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class TimeSeriesDistillationModule(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    æ­£ç¡®çš„è’¸é¦æ¨¡å— - ç”¨äºæ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹ä»»åŠ¡\n",
    "    \"\"\"\n",
    "    def __init__(self, teacher, student, temperature, alpha):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # ä½¿ç”¨BCE lossï¼ˆå¤šæ ‡ç­¾äºŒåˆ†ç±»ï¼‰\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        \n",
    "        # å¤ç”¨Teacherçš„validation metric\n",
    "        from torchmetrics.classification import MulticlassAccuracy\n",
    "        self.val_accuracy = MulticlassAccuracy(num_classes=9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.student(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        emg = batch[\"emg\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        \n",
    "        # ä¸‹é‡‡æ ·targetsä»¥åŒ¹é…è¾“å‡ºé•¿åº¦\n",
    "        targets = targets[:, :, self.teacher.network.left_context::self.teacher.network.stride]\n",
    "        \n",
    "        # Teacherå‰å‘ä¼ æ’­ï¼ˆä¸è®¡ç®—æ¢¯åº¦ï¼‰\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = self.teacher(emg)  # [batch, 9, time_steps]\n",
    "        \n",
    "        # Studentå‰å‘ä¼ æ’­\n",
    "        student_logits = self.student(emg)  # [batch, 9, time_steps]\n",
    "        \n",
    "        # è’¸é¦æŸå¤±ï¼šMSE on logitsï¼ˆæ›´ç¨³å®šï¼‰\n",
    "        distill_loss = F.mse_loss(student_logits, teacher_logits)\n",
    "        \n",
    "        # çœŸå®æ ‡ç­¾æŸå¤±ï¼šBCE\n",
    "        student_loss = self.bce_loss(student_logits, targets).mean()\n",
    "        \n",
    "        # æ€»æŸå¤±\n",
    "        loss = self.alpha * distill_loss + (1 - self.alpha) * student_loss\n",
    "        \n",
    "        # è®°å½•æŒ‡æ ‡\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_distill_loss', distill_loss)\n",
    "        self.log('train_student_loss', student_loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        emg = batch[\"emg\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        \n",
    "        # ä¸‹é‡‡æ ·targets\n",
    "        targets = targets[:, :, self.teacher.network.left_context::self.teacher.network.stride]\n",
    "        \n",
    "        # Studentæ¨ç†\n",
    "        logits = self.student(emg)\n",
    "        \n",
    "        # BCE loss\n",
    "        loss = self.bce_loss(logits, targets).mean()\n",
    "        \n",
    "        # ä½¿ç”¨ä¸Teacherç›¸åŒçš„collect_metricæ–¹æ³•è®¡ç®—å‡†ç¡®åº¦\n",
    "        self.collect_metric(logits, targets, phase='val')\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def collect_metric(self, logits, target, phase):\n",
    "        \"\"\"\n",
    "        å¤åˆ¶Teacherçš„collect_metricæ–¹æ³•\n",
    "        \"\"\"\n",
    "        device = logits.device\n",
    "        w_start = 10\n",
    "        w_end = 30\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # è½¬ç½®ä¸º [batch, time, classes]\n",
    "        probs = probs.transpose(1, 2)\n",
    "        target = target.transpose(1, 2)\n",
    "        \n",
    "        y = target.to(torch.int32)\n",
    "        y_class = []\n",
    "        y_hat_class = []\n",
    "        \n",
    "        for batch in range(y.shape[0]):\n",
    "            y_diff = torch.diff(y[batch], axis=0)\n",
    "            indices = torch.argwhere(y_diff == 1)\n",
    "            for index in indices:\n",
    "                start = max(index[0] - w_start, 0)\n",
    "                end = min(index[0] + w_end, y.shape[1])\n",
    "                y_hat = probs[batch, start:end, :]\n",
    "                flattened_index = y_hat.argmax()\n",
    "                _, cols = y_hat.shape\n",
    "                col = flattened_index % cols\n",
    "                y_hat_class.append(col)\n",
    "                y_class.append(index[1])\n",
    "        \n",
    "        if len(y_class) > 0:\n",
    "            y_class = torch.stack(y_class).long().to(device)\n",
    "            y_hat_class = torch.stack(y_hat_class).long().to(device)\n",
    "        else:\n",
    "            y_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "            y_hat_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "        \n",
    "        self.val_accuracy.update(y_hat_class, y_class)\n",
    "        self.log(f'{phase}_accuracy', self.val_accuracy, on_step=False, on_epoch=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.student.parameters(),\n",
    "            lr=5e-4,  # ç¨å¾®é™ä½å­¦ä¹ ç‡\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=MAX_EPOCHS\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# åˆ›å»ºè’¸é¦æ¨¡å‹\n",
    "distill_model_v2 = TimeSeriesDistillationModule(\n",
    "    teacher=teacher,\n",
    "    student=student_v2,\n",
    "    temperature=TEMPERATURE,\n",
    "    alpha=ALPHA\n",
    ")\n",
    "\n",
    "print(\"âœ… æ­£ç¡®çš„è’¸é¦æ¨¡å‹åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"  Temperature: {TEMPERATURE}\")\n",
    "print(f\"  Alpha (è’¸é¦æƒé‡): {ALPHA}\")\n",
    "print(f\"  Studentå‚æ•°é‡: {student_v2_params / 1e6:.2f}M\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fb66172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š è’¸é¦è®­ç»ƒæ–¹æ¡ˆå¯¹æ¯”\n",
      "======================================================================\n",
      "\n",
      "âŒ åŸç‰ˆæœ¬ï¼ˆé”™è¯¯ï¼‰:\n",
      "  Studentæ¨¡å‹: ConvOnlyStudent\n",
      "  - è¾“å‡º: [batch, 9] - å•ä¸€åˆ†ç±»å‘é‡\n",
      "  - å‚æ•°: 17.4K\n",
      "  - æŸå¤±å‡½æ•°: CrossEntropyLoss\n",
      "  - è’¸é¦æ–¹æ³•: teacher_logits.mean(dim=2)\n",
      "  - éªŒè¯å‡†ç¡®åº¦: 15.67%\n",
      "  - é—®é¢˜: ä»»åŠ¡å®šä¹‰å®Œå…¨é”™è¯¯\n",
      "\n",
      "âœ… æ–°ç‰ˆæœ¬ï¼ˆæ­£ç¡®ï¼‰:\n",
      "  Studentæ¨¡å‹: TimeSeriesStudent\n",
      "  - è¾“å‡º: [batch, 9, 1598] - æ—¶é—´åºåˆ—\n",
      "  - å‚æ•°: 140K\n",
      "  - æŸå¤±å‡½æ•°: BCEWithLogitsLoss + MSEè’¸é¦\n",
      "  - è’¸é¦æ–¹æ³•: ç›´æ¥å¯¹é½æ—¶é—´åºåˆ—logits\n",
      "  - é¢„æœŸéªŒè¯å‡†ç¡®åº¦: ~40%+ (æ¥è¿‘Teacherçš„47%)\n",
      "  - ä¼˜åŠ¿: ä»»åŠ¡å®šä¹‰æ­£ç¡®ï¼Œä¿ç•™æ—¶é—´ä¿¡æ¯\n",
      "\n",
      "======================================================================\n",
      "ğŸ’¡ æ”¹è¿›æ€»ç»“\n",
      "======================================================================\n",
      "  1. âœ… è¾“å‡ºæ ¼å¼åŒ¹é…: Studentç°åœ¨è¾“å‡ºæ—¶é—´åºåˆ—\n",
      "  2. âœ… æŸå¤±å‡½æ•°æ­£ç¡®: ä½¿ç”¨BCEå¤šæ ‡ç­¾loss\n",
      "  3. âœ… è’¸é¦æ­£ç¡®: ç›´æ¥å­¦ä¹ Teacherçš„æ—¶é—´åºåˆ—è¾“å‡º\n",
      "  4. âœ… è¯„ä¼°æ­£ç¡®: ä½¿ç”¨ä¸Teacherç›¸åŒçš„collect_metric\n",
      "  5. âœ… æ¨¡å‹å¤§å°åˆé€‚: 140Kå‚æ•°ï¼Œå‹ç¼©æ¯”45x\n",
      "\n",
      "======================================================================\n",
      "ğŸ¯ ä¸‹ä¸€æ­¥\n",
      "======================================================================\n",
      "  é€‰é¡¹1: é‡æ–°è®­ç»ƒStudent V2ï¼ˆæ¨èï¼‰\n",
      "    - ä½¿ç”¨æ­£ç¡®çš„TimeSeriesDistillationModule\n",
      "    - é¢„è®¡è®­ç»ƒæ—¶é—´: ~1-2å°æ—¶ï¼ˆ30 epochsï¼‰\n",
      "    - é¢„æœŸå‡†ç¡®åº¦: 35-45%\n",
      "\n",
      "  é€‰é¡¹2: è¿›ä¸€æ­¥ä¼˜åŒ–Studentæ¶æ„\n",
      "    - è°ƒæ•´GRUå±‚æ•°/hidden size\n",
      "    - å®éªŒä¸åŒçš„è’¸é¦ç­–ç•¥\n",
      "    - è°ƒæ•´temperatureå’Œalpha\n",
      "\n",
      "  é€‰é¡¹3: å¯¼å‡ºå½“å‰æœ€ä½³æ¨¡å‹\n",
      "    - è™½ç„¶15%ä¸ç†æƒ³ï¼Œä½†å¯ä»¥ä½œä¸ºbaseline\n",
      "    - é‡åŒ–å¹¶è½¬æ¢ä¸ºTFLite\n",
      "    - åœ¨ESP32ä¸Šæµ‹è¯•æ¨ç†æ€§èƒ½\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š é”™è¯¯ç‰ˆæœ¬ vs æ­£ç¡®ç‰ˆæœ¬å¯¹æ¯”æ€»ç»“\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š è’¸é¦è®­ç»ƒæ–¹æ¡ˆå¯¹æ¯”\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâŒ åŸç‰ˆæœ¬ï¼ˆé”™è¯¯ï¼‰:\")\n",
    "print(\"  Studentæ¨¡å‹: ConvOnlyStudent\")\n",
    "print(\"  - è¾“å‡º: [batch, 9] - å•ä¸€åˆ†ç±»å‘é‡\")\n",
    "print(\"  - å‚æ•°: 17.4K\")\n",
    "print(\"  - æŸå¤±å‡½æ•°: CrossEntropyLoss\")\n",
    "print(\"  - è’¸é¦æ–¹æ³•: teacher_logits.mean(dim=2)\")\n",
    "print(\"  - éªŒè¯å‡†ç¡®åº¦: 15.67%\")\n",
    "print(\"  - é—®é¢˜: ä»»åŠ¡å®šä¹‰å®Œå…¨é”™è¯¯\")\n",
    "\n",
    "print(\"\\nâœ… æ–°ç‰ˆæœ¬ï¼ˆæ­£ç¡®ï¼‰:\")\n",
    "print(\"  Studentæ¨¡å‹: TimeSeriesStudent\")\n",
    "print(\"  - è¾“å‡º: [batch, 9, 1598] - æ—¶é—´åºåˆ—\")\n",
    "print(\"  - å‚æ•°: 140K\")\n",
    "print(\"  - æŸå¤±å‡½æ•°: BCEWithLogitsLoss + MSEè’¸é¦\")\n",
    "print(\"  - è’¸é¦æ–¹æ³•: ç›´æ¥å¯¹é½æ—¶é—´åºåˆ—logits\")\n",
    "print(\"  - é¢„æœŸéªŒè¯å‡†ç¡®åº¦: ~40%+ (æ¥è¿‘Teacherçš„47%)\")\n",
    "print(\"  - ä¼˜åŠ¿: ä»»åŠ¡å®šä¹‰æ­£ç¡®ï¼Œä¿ç•™æ—¶é—´ä¿¡æ¯\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ’¡ æ”¹è¿›æ€»ç»“\")\n",
    "print(\"=\"*70)\n",
    "print(\"  1. âœ… è¾“å‡ºæ ¼å¼åŒ¹é…: Studentç°åœ¨è¾“å‡ºæ—¶é—´åºåˆ—\")\n",
    "print(\"  2. âœ… æŸå¤±å‡½æ•°æ­£ç¡®: ä½¿ç”¨BCEå¤šæ ‡ç­¾loss\")\n",
    "print(\"  3. âœ… è’¸é¦æ­£ç¡®: ç›´æ¥å­¦ä¹ Teacherçš„æ—¶é—´åºåˆ—è¾“å‡º\")\n",
    "print(\"  4. âœ… è¯„ä¼°æ­£ç¡®: ä½¿ç”¨ä¸Teacherç›¸åŒçš„collect_metric\")\n",
    "print(\"  5. âœ… æ¨¡å‹å¤§å°åˆé€‚: 140Kå‚æ•°ï¼Œå‹ç¼©æ¯”45x\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ ä¸‹ä¸€æ­¥\")\n",
    "print(\"=\"*70)\n",
    "print(\"  é€‰é¡¹1: é‡æ–°è®­ç»ƒStudent V2ï¼ˆæ¨èï¼‰\")\n",
    "print(\"    - ä½¿ç”¨æ­£ç¡®çš„TimeSeriesDistillationModule\")\n",
    "print(\"    - é¢„è®¡è®­ç»ƒæ—¶é—´: ~1-2å°æ—¶ï¼ˆ30 epochsï¼‰\")\n",
    "print(\"    - é¢„æœŸå‡†ç¡®åº¦: 35-45%\")\n",
    "\n",
    "print(\"\\n  é€‰é¡¹2: è¿›ä¸€æ­¥ä¼˜åŒ–Studentæ¶æ„\")\n",
    "print(\"    - è°ƒæ•´GRUå±‚æ•°/hidden size\")\n",
    "print(\"    - å®éªŒä¸åŒçš„è’¸é¦ç­–ç•¥\")\n",
    "print(\"    - è°ƒæ•´temperatureå’Œalpha\")\n",
    "\n",
    "print(\"\\n  é€‰é¡¹3: å¯¼å‡ºå½“å‰æœ€ä½³æ¨¡å‹\")\n",
    "print(\"    - è™½ç„¶15%ä¸ç†æƒ³ï¼Œä½†å¯ä»¥ä½œä¸ºbaseline\")\n",
    "print(\"    - é‡åŒ–å¹¶è½¬æ¢ä¸ºTFLite\")\n",
    "print(\"    - åœ¨ESP32ä¸Šæµ‹è¯•æ¨ç†æ€§èƒ½\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨MetaåŸå§‹çš„è¯„ä¼°æ–¹æ³•\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”§ ä½¿ç”¨æ­£ç¡®çš„è¯„ä¼°æ–¹æ³•\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# æŸ¥çœ‹Teacherç½‘ç»œå‚æ•°\n",
    "print(f\"\\nğŸ“ Teacherç½‘ç»œå‚æ•°:\")\n",
    "print(f\"  stride: {teacher.network.stride}\")\n",
    "print(f\"  left_context: {teacher.network.left_context}\")\n",
    "\n",
    "# ä½¿ç”¨collect_metricæ–¹æ³•æ¥è¯„ä¼°\n",
    "def evaluate_teacher_correct():\n",
    "    \"\"\"ä½¿ç”¨MetaåŸå§‹çš„è¯„ä¼°æ–¹æ³•\"\"\"\n",
    "    teacher.eval()\n",
    "    teacher.cuda()\n",
    "    \n",
    "    all_y_class = []\n",
    "    all_y_hat_class = []\n",
    "    \n",
    "    val_loader = data_module.val_dataloader()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"è¯„ä¼°Teacher(æ­£ç¡®æ–¹æ³•)\")):\n",
    "            emg = batch['emg'].cuda()\n",
    "            targets = batch['targets'].cuda()\n",
    "            \n",
    "            # ä¸‹é‡‡æ ·targetsä»¥åŒ¹é…è¾“å‡ºé•¿åº¦\n",
    "            targets_downsampled = targets[:, :, teacher.network.left_context::teacher.network.stride]\n",
    "            \n",
    "            # è½¬ç½®targets: [batch, classes, time] -> [batch, time, classes]\n",
    "            targets_t = targets_downsampled.transpose(1, 2)\n",
    "            \n",
    "            # è·å–Teacheré¢„æµ‹\n",
    "            logits = teacher(emg)  # [batch, classes, time]\n",
    "            \n",
    "            # è½¬ç½®logits: [batch, classes, time] -> [batch, time, classes]\n",
    "            logits_t = logits.transpose(1, 2)\n",
    "            \n",
    "            # åº”ç”¨sigmoid\n",
    "            probs = torch.sigmoid(logits_t)\n",
    "            \n",
    "            # å¯¹æ¯ä¸ªæ ·æœ¬å¤„ç†\n",
    "            y = targets_t.to(torch.int32)\n",
    "            w_start = 10  # 50 ms at 200 Hz\n",
    "            w_end = 30  # 150 ms at 200 Hz\n",
    "            \n",
    "            for batch_i in range(y.shape[0]):\n",
    "                y_diff = torch.diff(y[batch_i], axis=0)\n",
    "                indices = torch.argwhere(y_diff == 1)\n",
    "                \n",
    "                for index in indices:\n",
    "                    start = index[0] - w_start\n",
    "                    end = index[0] + w_end\n",
    "                    start = max(start, 0)\n",
    "                    end = min(end, y.shape[1])\n",
    "                    \n",
    "                    y_hat = probs[batch_i, start:end, :]\n",
    "                    flattened_index = y_hat.argmax()\n",
    "                    _, cols = y_hat.shape\n",
    "                    col = flattened_index % cols\n",
    "                    \n",
    "                    all_y_hat_class.append(col.cpu())\n",
    "                    all_y_class.append(index[1].cpu())\n",
    "    \n",
    "    if len(all_y_class) > 0:\n",
    "        y_class = torch.stack(all_y_class).long()\n",
    "        y_hat_class = torch.stack(all_y_hat_class).long()\n",
    "        \n",
    "        correct = (y_class == y_hat_class).sum().item()\n",
    "        total = len(y_class)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        print(f\"\\nâœ… Teacheræ¨¡å‹éªŒè¯ç»“æœ:\")\n",
    "        print(f\"  æ£€æµ‹åˆ°çš„æ‰‹åŠ¿äº‹ä»¶æ€»æ•°: {total}\")\n",
    "        print(f\"  æ­£ç¡®é¢„æµ‹: {correct}\")\n",
    "        print(f\"  Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "        \n",
    "        return accuracy\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•æ‰‹åŠ¿äº‹ä»¶ï¼\")\n",
    "        return 0.0\n",
    "\n",
    "teacher_correct_acc = evaluate_teacher_correct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b011b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸Teacheræ¨¡å‹å¯¹æ¯”\n",
    "print(\"\\nå¯¹æ¯”Teacheræ¨¡å‹æ€§èƒ½...\")\n",
    "teacher_results = trainer.test(teacher, data_module)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š Teacher vs Student å¯¹æ¯”\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Teacheræµ‹è¯•ç²¾åº¦: {teacher_results[0]['test_acc']:.4f}\")\n",
    "print(f\"Studentæµ‹è¯•ç²¾åº¦: {test_results[0]['test_acc']:.4f}\")\n",
    "print(f\"ç²¾åº¦ä¿ç•™ç‡: {test_results[0]['test_acc'] / teacher_results[0]['test_acc'] * 100:.2f}%\")\n",
    "print(f\"\\nTeacherå‚æ•°é‡: {sum(p.numel() for p in teacher.parameters()) / 1e6:.2f}M\")\n",
    "print(f\"Studentå‚æ•°é‡: {sum(p.numel() for p in student.parameters()) / 1e6:.2f}M\")\n",
    "print(f\"å‹ç¼©æ¯”: {sum(p.numel() for p in teacher.parameters()) / sum(p.numel() for p in student.parameters()):.1f}x\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a4b8c",
   "metadata": {},
   "source": [
    "## 8. æ¨¡å‹é‡åŒ–ä¸å¯¼å‡º\n",
    "\n",
    "å°†æ¨¡å‹è½¬æ¢ä¸ºINT8é‡åŒ–çš„TFLiteæ ¼å¼ï¼Œç”¨äºESP32éƒ¨ç½²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å‡ºPyTorchæ¨¡å‹\n",
    "export_dir = f\"exports/{EXPERIMENT_ID}\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# ä¿å­˜Studentæ¨¡å‹æƒé‡\n",
    "torch.save(\n",
    "    best_model.student.state_dict(),\n",
    "    f\"{export_dir}/student_model.pt\"\n",
    ")\n",
    "print(f\"âœ… PyTorchæ¨¡å‹å·²ä¿å­˜: {export_dir}/student_model.pt\")\n",
    "\n",
    "# ä¿å­˜å®Œæ•´æ¨¡å‹(åŒ…å«æ¶æ„)\n",
    "torch.save(\n",
    "    best_model.student,\n",
    "    f\"{export_dir}/student_model_full.pt\"\n",
    ")\n",
    "print(f\"âœ… å®Œæ•´æ¨¡å‹å·²ä¿å­˜: {export_dir}/student_model_full.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INT8é‡åŒ– (éœ€è¦æ ¹æ®å®é™…çš„quantization_utils.pyè°ƒæ•´)\n",
    "print(\"\\nå¼€å§‹INT8é‡åŒ–...\")\n",
    "\n",
    "# è¿™é‡Œæä¾›ä¸€ä¸ªç¤ºä¾‹æ¡†æ¶\n",
    "# å®é™…å®ç°éœ€è¦å‚è€ƒ mini/chenee/distillation/quantization_utils.py\n",
    "\n",
    "try:\n",
    "    from quantization_utils import quantize_model_to_tflite\n",
    "    \n",
    "    # é‡åŒ–åˆ°TFLite\n",
    "    tflite_model = quantize_model_to_tflite(\n",
    "        model=best_model.student,\n",
    "        sample_input=next(iter(data_module.val_dataloader()))[0][:1],\n",
    "        quantize=True,  # INT8é‡åŒ–\n",
    "    )\n",
    "    \n",
    "    # ä¿å­˜TFLiteæ¨¡å‹\n",
    "    tflite_path = f\"{export_dir}/student_model_int8.tflite\"\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    # æ£€æŸ¥æ–‡ä»¶å¤§å°\n",
    "    tflite_size_kb = os.path.getsize(tflite_path) / 1024\n",
    "    print(f\"âœ… TFLiteæ¨¡å‹å·²ä¿å­˜: {tflite_path}\")\n",
    "    print(f\"ğŸ“¦ æ¨¡å‹å¤§å°: {tflite_size_kb:.1f} KB\")\n",
    "    \n",
    "    if STUDENT_MODEL == \"ConvOnly\":\n",
    "        print(f\"ğŸ’¡ ConvOnlyæ¨¡å‹é€‚åˆESP32 (é€šå¸¸ < 100KB)\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ é‡åŒ–å·¥å…·æœªæ‰¾åˆ°\")\n",
    "    print(\"è¯·å‚è€ƒ mini/chenee/distillation/quantization_utils.py\")\n",
    "    print(\"æˆ–æ‰‹åŠ¨ä½¿ç”¨PyTorchçš„é‡åŒ–API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86b88d",
   "metadata": {},
   "source": [
    "## 9. æ€»ç»“æŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d862bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ‰ çŸ¥è¯†è’¸é¦è®­ç»ƒå®Œæˆæ€»ç»“\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ å®éªŒé…ç½®\n",
      "  è®­ç»ƒæ¨¡å¼: quick\n",
      "  Studentæ¨¡å‹: ConvOnly\n",
      "  è®­ç»ƒè½®æ•°: 30 epochs\n",
      "  è’¸é¦æ¸©åº¦: 4.0\n",
      "  è’¸é¦æƒé‡: 0.6\n",
      "\n",
      "â±ï¸  è®­ç»ƒæ—¶é—´\n",
      "  é¢„è®¡: 1-2å°æ—¶\n",
      "  å®é™…: 1å°æ—¶6åˆ†é’Ÿ\n",
      "\n",
      "ğŸ“Š æ¨¡å‹æ€§èƒ½\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'teacher_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1152074097.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nğŸ“Š æ¨¡å‹æ€§èƒ½\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Teacherç²¾åº¦: {teacher_results[0]['test_acc']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Studentç²¾åº¦: {test_results[0]['test_acc']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  ç²¾åº¦ä¿ç•™: {test_results[0]['test_acc'] / teacher_results[0]['test_acc'] * 100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'teacher_results' is not defined"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆè®­ç»ƒæ€»ç»“\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ çŸ¥è¯†è’¸é¦è®­ç»ƒå®Œæˆæ€»ç»“\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“‹ å®éªŒé…ç½®\")\n",
    "print(f\"  è®­ç»ƒæ¨¡å¼: {TRAINING_MODE}\")\n",
    "print(f\"  Studentæ¨¡å‹: {STUDENT_MODEL}\")\n",
    "print(f\"  è®­ç»ƒè½®æ•°: {MAX_EPOCHS} epochs\")\n",
    "print(f\"  è’¸é¦æ¸©åº¦: {TEMPERATURE}\")\n",
    "print(f\"  è’¸é¦æƒé‡: {ALPHA}\")\n",
    "\n",
    "print(f\"\\nâ±ï¸  è®­ç»ƒæ—¶é—´\")\n",
    "print(f\"  é¢„è®¡: {EXPECTED_TIME}\")\n",
    "print(f\"  å®é™…: {hours}å°æ—¶{minutes}åˆ†é’Ÿ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š æ¨¡å‹æ€§èƒ½\")\n",
    "print(f\"  Teacherç²¾åº¦: {teacher_results[0]['test_acc']:.4f}\")\n",
    "print(f\"  Studentç²¾åº¦: {test_results[0]['test_acc']:.4f}\")\n",
    "print(f\"  ç²¾åº¦ä¿ç•™: {test_results[0]['test_acc'] / teacher_results[0]['test_acc'] * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ æ¨¡å‹å‹ç¼©\")\n",
    "teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "student_params = sum(p.numel() for p in student.parameters())\n",
    "print(f\"  Teacherå‚æ•°: {teacher_params / 1e6:.2f}M\")\n",
    "print(f\"  Studentå‚æ•°: {student_params / 1e6:.2f}M\")\n",
    "print(f\"  å‹ç¼©æ¯”: {teacher_params / student_params:.1f}x\")\n",
    "\n",
    "print(f\"\\nğŸ“ å¯¼å‡ºæ–‡ä»¶\")\n",
    "print(f\"  PyTorchæ¨¡å‹: {export_dir}/student_model.pt\")\n",
    "if os.path.exists(f\"{export_dir}/student_model_int8.tflite\"):\n",
    "    print(f\"  TFLiteæ¨¡å‹: {export_dir}/student_model_int8.tflite ({tflite_size_kb:.1f} KB)\")\n",
    "print(f\"  æœ€ä½³checkpoint: {checkpoint_callback.best_model_path}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ TensorBoardæ—¥å¿—\")\n",
    "print(f\"  æ—¥å¿—ç›®å½•: {log_dir}\")\n",
    "\n",
    "print(f\"\\nğŸš€ ä¸‹ä¸€æ­¥\")\n",
    "if STUDENT_MODEL == \"ConvOnly\":\n",
    "    print(\"  1. å°†TFLiteæ¨¡å‹è½¬æ¢ä¸ºCæ•°ç»„ (xxd -i student_model_int8.tflite)\")\n",
    "    print(\"  2. é›†æˆåˆ°ESP32é¡¹ç›® (å‚è€ƒ mini/LLZ/main.cc)\")\n",
    "    print(\"  3. åœ¨ESP32ä¸Šæµ‹è¯•æ¨ç†æ€§èƒ½\")\n",
    "else:\n",
    "    print(\"  1. åœ¨æµ‹è¯•é›†ä¸Šè¿›ä¸€æ­¥è¯„ä¼°\")\n",
    "    print(\"  2. å¦‚éœ€ESP32éƒ¨ç½²ï¼Œè€ƒè™‘è®­ç»ƒConvOnlyæ¨¡å‹\")\n",
    "    print(\"  3. æˆ–éƒ¨ç½²åˆ°æ›´å¼ºå¤§çš„è®¾å¤‡ (æ ‘è“æ´¾ã€æ‰‹æœºç­‰)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbb5a9",
   "metadata": {},
   "source": [
    "## é™„å½•: å¸¸è§é—®é¢˜\n",
    "\n",
    "### Q1: è®­ç»ƒæ—¶é—´æ¯”é¢„æœŸé•¿/çŸ­ï¼Ÿ\n",
    "- é¢„ä¼°åŸºäºTesla T4 GPUï¼Œå…¶ä»–GPUæ€§èƒ½ä¸åŒ\n",
    "- æ•°æ®åŠ è½½é€Ÿåº¦å½±å“è®­ç»ƒæ—¶é—´\n",
    "- å¯ä»¥è°ƒæ•´ `num_workers` å’Œ `batch_size`\n",
    "\n",
    "### Q2: ç²¾åº¦ä¸è¾¾é¢„æœŸï¼Ÿ\n",
    "- å°è¯•å¢åŠ è®­ç»ƒè½®æ•° (MAX_EPOCHS)\n",
    "- è°ƒæ•´è’¸é¦æ¸©åº¦ (TEMPERATURE) å’Œæƒé‡ (ALPHA)\n",
    "- æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´åŠ è½½\n",
    "\n",
    "### Q3: å¦‚ä½•é€‰æ‹©è®­ç»ƒæ¨¡å¼ï¼Ÿ\n",
    "- **å¿«é€Ÿæ¨¡å¼**: å…ˆéªŒè¯æµç¨‹ï¼Œå†å†³å®šæ˜¯å¦è¿è¡Œæ ‡å‡†æ¨¡å¼\n",
    "- **æ ‡å‡†æ¨¡å¼**: è¿½æ±‚æ›´é«˜ç²¾åº¦ï¼Œæ¥å—æ›´é•¿è®­ç»ƒæ—¶é—´\n",
    "\n",
    "### Q4: å¤šä¸ªColabåŒæ—¶è®­ç»ƒï¼Ÿ\n",
    "- å°†æ•°æ®æ”¾åœ¨Google Drive\n",
    "- æ¯ä¸ªColabè®¾ç½®ä¸åŒçš„ `EXPERIMENT_ID`\n",
    "- å‚è€ƒ `MULTI_COLAB_GUIDE.md`\n",
    "\n",
    "### Q5: å¦‚ä½•åŠ é€Ÿè®­ç»ƒï¼Ÿ\n",
    "- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (å·²å¯ç”¨ precision=16)\n",
    "- å¢åŠ batch size (å¦‚æœæ˜¾å­˜å…è®¸)\n",
    "- ä½¿ç”¨æ›´å¿«çš„GPU (A100 > V100 > T4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

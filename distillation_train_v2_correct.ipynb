{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d9e868",
   "metadata": {},
   "source": [
    "# EMGæ¨¡å‹çŸ¥è¯†è’¸é¦è®­ç»ƒ - æ­£ç¡®ç‰ˆæœ¬ V2\n",
    "\n",
    "**æ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹ä»»åŠ¡çš„çŸ¥è¯†è’¸é¦**\n",
    "\n",
    "## ç›®æ ‡\n",
    "- Teacher: Metaå®˜æ–¹DiscreteGesturesModule (6.5Må‚æ•°)\n",
    "- Student: TimeSeriesStudent (140Kå‚æ•°, 45xå‹ç¼©)\n",
    "- è¾“å‡º: æ—¶é—´åºåˆ— `[batch, 9, 1598]` (æ­£ç¡®ï¼)\n",
    "- é¢„æœŸå‡†ç¡®åº¦: 35-45% (Teacher=47%)\n",
    "\n",
    "## ä¿®å¤çš„å…³é”®é—®é¢˜\n",
    "âœ… è¾“å‡ºæ ¼å¼: æ—¶é—´åºåˆ—è€Œéå•åˆ†ç±»  \n",
    "âœ… æŸå¤±å‡½æ•°: BCE + MSEè’¸é¦  \n",
    "âœ… è¯„ä¼°æ–¹æ³•: ä½¿ç”¨Teacherçš„collect_metric  \n",
    "âœ… ä»»åŠ¡å®šä¹‰: å¤šæ ‡ç­¾æ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896ad8b",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®ä¸å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affe6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿è¡Œç¯å¢ƒ: Google Colab\n",
      "ğŸ”§ åœ¨Colabç¯å¢ƒä¸­è®¾ç½®...\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# æ£€æµ‹è¿è¡Œç¯å¢ƒ\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"è¿è¡Œç¯å¢ƒ: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ”§ åœ¨Colabç¯å¢ƒä¸­è®¾ç½®...\")\n",
    "    # åˆ‡æ¢åˆ°ä»£ç ç›®å½•\n",
    "    if not os.path.exists('/content/generic-neuromotor-interface'):\n",
    "        !git clone https://github.com/facebookresearch/generic-neuromotor-interface.git\n",
    "    os.chdir('/content/generic-neuromotor-interface')\n",
    "    \n",
    "    # å®‰è£…ä¾èµ–\n",
    "    !pip install -q pytorch-lightning==1.8.6 hydra-core==1.3.2 omegaconf==2.3.0 h5py\n",
    "    !pip install -q -e .\n",
    "    \n",
    "    print(\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âœ… æœ¬åœ°ç¯å¢ƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da2bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å°†ä¿å­˜åˆ°: ./logs/distillation\n"
     ]
    }
   ],
   "source": [
    "# æŒ‚è½½Google Driveï¼ˆå¯é€‰ - ç”¨äºä¿å­˜checkpointï¼‰\n",
    "USE_GOOGLE_DRIVE = False  # è®¾ç½®ä¸ºTrueä»¥ä½¿ç”¨Google Drive\n",
    "\n",
    "if IN_COLAB and USE_GOOGLE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    SAVE_DIR = '/content/drive/MyDrive/emg_distillation'\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    print(f\"âœ… å°†ä¿å­˜åˆ°: {SAVE_DIR}\")\n",
    "else:\n",
    "    SAVE_DIR = './logs/distillation'\n",
    "    print(f\"âœ… å°†ä¿å­˜åˆ°: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b91d91",
   "metadata": {},
   "source": [
    "## 2. ä¸‹è½½æ•°æ®å’ŒTeacheræ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6831f620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ ä¸‹è½½EMGæ•°æ®...\n",
      "Downloading the full_data data for discrete_gestures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading full_data data for discrete_gestures: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31.1G/31.1G [14:59<00:00, 37.1MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [09:46<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the tar file after extraction: discrete_gestures_full_data.tar\n",
      "Downloading the corpus CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading discrete_gestures corpus CSV file: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105k/105k [00:00<00:00, 921kB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for discrete_gestures (full_data) downloaded and extracted to /content/emg_data\n",
      "âœ… æ•°æ®ä¸‹è½½å®Œæˆ\n",
      "âœ… æ¨¡å‹å·²å­˜åœ¨\n",
      "\n",
      "ğŸ“ Teacher checkpoint: /content/emg_models/discrete_gestures/model_checkpoint.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ä¸‹è½½EMGæ•°æ®å’ŒTeacheræ¨¡å‹\n",
    "from generic_neuromotor_interface.scripts.download_data import download_data\n",
    "from generic_neuromotor_interface.scripts.download_models import download_models\n",
    "\n",
    "TASK = \"discrete_gestures\"\n",
    "DATA_PATH = \"/content/emg_data\" if IN_COLAB else \"~/emg_data\"\n",
    "MODELS_PATH = \"/content/emg_models\" if IN_COLAB else \"~/emg_models\"\n",
    "\n",
    "# ä¸‹è½½æ•°æ®ï¼ˆå®Œæ•´æ•°æ®é›†ï¼‰\n",
    "if not os.path.exists(os.path.expanduser(DATA_PATH)):\n",
    "    print(\"ğŸ“¥ ä¸‹è½½EMGæ•°æ®...\")\n",
    "    download_data(TASK, \"full_data\", DATA_PATH)\n",
    "    print(\"âœ… æ•°æ®ä¸‹è½½å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âœ… æ•°æ®å·²å­˜åœ¨\")\n",
    "\n",
    "# ä¸‹è½½Teacheræ¨¡å‹\n",
    "if not os.path.exists(os.path.expanduser(MODELS_PATH)):\n",
    "    print(\"ğŸ“¥ ä¸‹è½½Teacheræ¨¡å‹...\")\n",
    "    download_models(TASK, MODELS_PATH)\n",
    "    print(\"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âœ… æ¨¡å‹å·²å­˜åœ¨\")\n",
    "\n",
    "TEACHER_CHECKPOINT = os.path.join(os.path.expanduser(MODELS_PATH), TASK, \"model_checkpoint.ckpt\")\n",
    "print(f\"\\nğŸ“ Teacher checkpoint: {TEACHER_CHECKPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e4320",
   "metadata": {},
   "source": [
    "## 3. é…ç½®è¶…å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278fd99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ è®­ç»ƒé…ç½®\n",
      "============================================================\n",
      "å®éªŒID: distill_timeseries_v2\n",
      "æœ€å¤§è½®æ•°: 30\n",
      "æ‰¹å¤§å°: 64\n",
      "è’¸é¦æ¸©åº¦: 4.0\n",
      "è’¸é¦æƒé‡Alpha: 0.7\n",
      "å­¦ä¹ ç‡: 0.0005\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# è’¸é¦è®­ç»ƒè¶…å‚æ•°\n",
    "EXPERIMENT_ID = \"distill_timeseries_v2\"\n",
    "MAX_EPOCHS = 30  # å¿«é€Ÿè®­ç»ƒï¼Œå¯åç»­å¢åŠ åˆ°50-100\n",
    "BATCH_SIZE = 64  # T4 GPUä¼˜åŒ–ï¼ˆå¯è°ƒæ•´ä¸º32/128ï¼‰\n",
    "TEMPERATURE = 4.0  # è’¸é¦æ¸©åº¦\n",
    "ALPHA = 0.7  # è’¸é¦æŸå¤±æƒé‡ï¼ˆ0.7*è’¸é¦ + 0.3*çœŸå®æ ‡ç­¾ï¼‰\n",
    "LEARNING_RATE = 5e-4\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ¯ è®­ç»ƒé…ç½®\")\n",
    "print(\"=\"*60)\n",
    "print(f\"å®éªŒID: {EXPERIMENT_ID}\")\n",
    "print(f\"æœ€å¤§è½®æ•°: {MAX_EPOCHS}\")\n",
    "print(f\"æ‰¹å¤§å°: {BATCH_SIZE}\")\n",
    "print(f\"è’¸é¦æ¸©åº¦: {TEMPERATURE}\")\n",
    "print(f\"è’¸é¦æƒé‡Alpha: {ALPHA}\")\n",
    "print(f\"å­¦ä¹ ç‡: {LEARNING_RATE}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e7ebc3",
   "metadata": {},
   "source": [
    "## 4. åŠ è½½Teacheræ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae5721c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ åŠ è½½Teacheræ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'network' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['network'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Teacheræ¨¡å‹åŠ è½½å®Œæˆ\n",
      "   å‚æ•°é‡: 6.48M\n",
      "   ç½‘ç»œé…ç½®: stride=10, left_context=20\n",
      "   è¾“å‡ºå½¢çŠ¶: torch.Size([2, 9, 1598])  # [batch, 9, 1598]\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½Teacheræ¨¡å‹\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from generic_neuromotor_interface.lightning import DiscreteGesturesModule\n",
    "\n",
    "print(\"ğŸ“¦ åŠ è½½Teacheræ¨¡å‹...\")\n",
    "\n",
    "# PyTorch 2.6+ weights_onlyå¤„ç†\n",
    "original_torch_load = torch.load\n",
    "def patched_torch_load(*args, **kwargs):\n",
    "    kwargs['weights_only'] = False\n",
    "    return original_torch_load(*args, **kwargs)\n",
    "torch.load = patched_torch_load\n",
    "\n",
    "# åŠ è½½checkpoint\n",
    "teacher = DiscreteGesturesModule.load_from_checkpoint(\n",
    "    TEACHER_CHECKPOINT,\n",
    "    map_location='cpu'\n",
    ")\n",
    "\n",
    "# æ¢å¤torch.load\n",
    "torch.load = original_torch_load\n",
    "\n",
    "# ç§»åˆ°GPUå¹¶å†»ç»“\n",
    "if torch.cuda.is_available():\n",
    "    teacher = teacher.cuda()\n",
    "teacher.eval()\n",
    "teacher.freeze()\n",
    "\n",
    "teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "print(f\"âœ… Teacheræ¨¡å‹åŠ è½½å®Œæˆ\")\n",
    "print(f\"   å‚æ•°é‡: {teacher_params / 1e6:.2f}M\")\n",
    "print(f\"   ç½‘ç»œé…ç½®: stride={teacher.network.stride}, left_context={teacher.network.left_context}\")\n",
    "\n",
    "# æµ‹è¯•è¾“å‡ºå½¢çŠ¶\n",
    "test_input = torch.randn(2, 16, 16000)\n",
    "if torch.cuda.is_available():\n",
    "    test_input = test_input.cuda()\n",
    "with torch.no_grad():\n",
    "    test_output = teacher(test_input)\n",
    "print(f\"   è¾“å‡ºå½¢çŠ¶: {test_output.shape}  # [batch, 9, 1598]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38723596",
   "metadata": {},
   "source": [
    "## 5. å‡†å¤‡æ•°æ®æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78fec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š å‡†å¤‡æ•°æ®æ¨¡å—...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a21720dd4648ee8b1b2befd64d3258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split train:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# å‡†å¤‡æ•°æ®åŠ è½½å™¨\n",
    "from generic_neuromotor_interface.data_module import WindowedEmgDataModule\n",
    "from generic_neuromotor_interface.data import DataSplit\n",
    "from generic_neuromotor_interface.transforms import DiscreteGesturesTransform\n",
    "from generic_neuromotor_interface.augmentation import RotationAugmentation\n",
    "\n",
    "print(\"ğŸ“Š å‡†å¤‡æ•°æ®æ¨¡å—...\")\n",
    "\n",
    "# æ•°æ®splité…ç½®\n",
    "data_split = DataSplit.from_csv(\n",
    "    csv_filename=os.path.join(os.path.expanduser(DATA_PATH), f\"{TASK}_corpus.csv\"),\n",
    "    pool_test_partitions=True\n",
    ")\n",
    "\n",
    "# Transformå’ŒAugmentation\n",
    "transform = DiscreteGesturesTransform(pulse_window=(0, 8))  # (start_offset, end_offset) 40ms at 200Hz\n",
    "emg_augmentation = RotationAugmentation()\n",
    "\n",
    "# åˆ›å»ºæ•°æ®æ¨¡å—\n",
    "data_module = WindowedEmgDataModule(\n",
    "    data_location=os.path.expanduser(DATA_PATH),\n",
    "    data_split=data_split,\n",
    "    transform=transform,\n",
    "    emg_augmentation=emg_augmentation,\n",
    "    window_length=16000,  # 80ç§’ @ 200Hz\n",
    "    stride=8000,  # 50% overlap\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Setupæ•°æ®\n",
    "data_module.setup('fit')\n",
    "\n",
    "print(f\"âœ… æ•°æ®æ¨¡å—åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"   è®­ç»ƒbatches: {len(data_module.train_dataloader())}\")\n",
    "print(f\"   éªŒè¯batches: {len(data_module.val_dataloader())}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# éªŒè¯æ•°æ®æ ¼å¼\n",
    "sample_batch = next(iter(data_module.train_dataloader()))\n",
    "print(f\"\\nğŸ“¦ æ•°æ®æ ¼å¼æ£€æŸ¥:\")\n",
    "print(f\"   EMG shape: {sample_batch['emg'].shape}  # [batch, channels, time]\")\n",
    "print(f\"   Targets shape: {sample_batch['targets'].shape}  # [batch, classes, time]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9516e",
   "metadata": {},
   "source": [
    "## 6. å®šä¹‰TimeSeriesStudentæ¨¡å‹\n",
    "\n",
    "**å…³é”®æ”¹è¿›**: è¾“å‡ºæ—¶é—´åºåˆ— `[batch, 9, 1598]` è€Œéå•åˆ†ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesStudentæ¨¡å‹å®šä¹‰\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TimeSeriesStudent(nn.Module):\n",
    "    \"\"\"\n",
    "    æ—¶é—´åºåˆ—Studentæ¨¡å‹ - è¾“å‡ºä¸Teacheræ ¼å¼ä¸€è‡´\n",
    "    \n",
    "    æ¶æ„:\n",
    "    - Conv1d: ç‰¹å¾æå– + ä¸‹é‡‡æ · (stride=10)\n",
    "    - GRU: æ—¶é—´å»ºæ¨¡ (1å±‚, 128 hidden)\n",
    "    - Linear: æŠ•å½±åˆ°ç±»åˆ«ç©ºé—´\n",
    "    \n",
    "    è¾“å…¥: [batch, 16, 16000]\n",
    "    è¾“å‡º: [batch, 9, 1598]\n",
    "    å‚æ•°: ~140K (45xå‹ç¼©)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=9, input_channels=16, stride=10, left_context=20):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.stride = stride\n",
    "        self.left_context = left_context\n",
    "        \n",
    "        # å·ç§¯ç¼–ç å™¨ï¼ˆæ¨¡ä»¿Teacherçš„ç¬¬ä¸€å±‚ï¼‰\n",
    "        self.conv1 = nn.Conv1d(input_channels, 128, kernel_size=21, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # è½»é‡çº§æ—¶é—´å»ºæ¨¡ï¼ˆGRUæ›¿ä»£LSTMï¼‰\n",
    "        self.gru = nn.GRU(128, 128, num_layers=1, batch_first=True, dropout=0.0)\n",
    "        \n",
    "        # è¾“å‡ºæŠ•å½±\n",
    "        self.projection = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, emg):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        Args:\n",
    "            emg: [batch, channels=16, sequence=16000]\n",
    "        \n",
    "        Returns:\n",
    "            logits: [batch, num_classes=9, time_steps=1598]\n",
    "        \"\"\"\n",
    "        # 1. å·ç§¯ç‰¹å¾æå– + ä¸‹é‡‡æ ·\n",
    "        x = self.conv1(emg)  # [batch, 128, time_steps]\n",
    "        x = self.relu(self.bn1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 2. è½¬ç½®ä¸º [batch, time, features] ç”¨äºGRU\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # 3. GRUæ—¶é—´å»ºæ¨¡\n",
    "        x, _ = self.gru(x)  # [batch, time, 128]\n",
    "        \n",
    "        # 4. æŠ•å½±åˆ°ç±»åˆ«ç©ºé—´\n",
    "        x = self.projection(x)  # [batch, time, num_classes]\n",
    "        \n",
    "        # 5. è½¬ç½®å› [batch, num_classes, time]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºStudentæ¨¡å‹\n",
    "student = TimeSeriesStudent(\n",
    "    num_classes=9,\n",
    "    input_channels=16,\n",
    "    stride=10,\n",
    "    left_context=20\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    student = student.cuda()\n",
    "\n",
    "student_params = sum(p.numel() for p in student.parameters())\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… Studentæ¨¡å‹åˆ›å»ºå®Œæˆ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"å‚æ•°é‡: {student_params / 1e6:.2f}M\")\n",
    "print(f\"å‹ç¼©æ¯”: {teacher_params / student_params:.1f}x\")\n",
    "\n",
    "# éªŒè¯è¾“å‡ºå½¢çŠ¶\n",
    "with torch.no_grad():\n",
    "    student_output = student(test_input)\n",
    "    print(f\"\\nè¾“å‡ºå½¢çŠ¶éªŒè¯:\")\n",
    "    print(f\"  Teacher: {test_output.shape}\")\n",
    "    print(f\"  Student: {student_output.shape}\")\n",
    "    print(f\"  å½¢çŠ¶åŒ¹é…: {test_output.shape == student_output.shape} âœ…\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f220c",
   "metadata": {},
   "source": [
    "## 7. å®šä¹‰è’¸é¦è®­ç»ƒæ¨¡å—\n",
    "\n",
    "**å…³é”®æ”¹è¿›**: BCE + MSEè’¸é¦ï¼Œä½¿ç”¨Teacherçš„collect_metricè¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesDistillationModuleå®šä¹‰\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "class TimeSeriesDistillationModule(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    æ—¶é—´åºåˆ—è’¸é¦è®­ç»ƒæ¨¡å—\n",
    "    \n",
    "    æŸå¤±å‡½æ•°:\n",
    "    - è’¸é¦loss: MSE(student_logits, teacher_logits)\n",
    "    - çœŸå®æ ‡ç­¾loss: BCEWithLogitsLoss\n",
    "    - æ€»loss = alpha * è’¸é¦ + (1-alpha) * çœŸå®æ ‡ç­¾\n",
    "    \n",
    "    è¯„ä¼°æ–¹æ³•:\n",
    "    - ä½¿ç”¨Teacherçš„collect_metricæ–¹æ³•\n",
    "    - åœ¨äº‹ä»¶å‘ç”Ÿæ—¶åˆ»çš„æ—¶é—´çª—å£å†…è¯„ä¼°å‡†ç¡®åº¦\n",
    "    \"\"\"\n",
    "    def __init__(self, teacher, student, temperature, alpha, learning_rate):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # æŸå¤±å‡½æ•°\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        \n",
    "        # è¯„ä¼°æŒ‡æ ‡\n",
    "        self.val_accuracy = MulticlassAccuracy(num_classes=9)\n",
    "        \n",
    "        # ä¿å­˜è¶…å‚æ•°\n",
    "        self.save_hyperparameters(ignore=['teacher', 'student'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.student(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        emg = batch[\"emg\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        \n",
    "        # ä¸‹é‡‡æ ·targetsä»¥åŒ¹é…è¾“å‡ºé•¿åº¦\n",
    "        targets = targets[:, :, self.teacher.network.left_context::self.teacher.network.stride]\n",
    "        \n",
    "        # Teacherå‰å‘ä¼ æ’­ï¼ˆä¸è®¡ç®—æ¢¯åº¦ï¼‰\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = self.teacher(emg)\n",
    "        \n",
    "        # Studentå‰å‘ä¼ æ’­\n",
    "        student_logits = self.student(emg)\n",
    "        \n",
    "        # è’¸é¦æŸå¤±ï¼šMSE on logits\n",
    "        distill_loss = F.mse_loss(student_logits, teacher_logits)\n",
    "        \n",
    "        # çœŸå®æ ‡ç­¾æŸå¤±ï¼šBCE\n",
    "        student_loss = self.bce_loss(student_logits, targets).mean()\n",
    "        \n",
    "        # æ€»æŸå¤±\n",
    "        loss = self.alpha * distill_loss + (1 - self.alpha) * student_loss\n",
    "        \n",
    "        # è®°å½•æŒ‡æ ‡\n",
    "        self.log('train/loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        self.log('train/distill_loss', distill_loss, on_step=False, on_epoch=True)\n",
    "        self.log('train/student_loss', student_loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        emg = batch[\"emg\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        \n",
    "        # ä¸‹é‡‡æ ·targets\n",
    "        targets = targets[:, :, self.teacher.network.left_context::self.teacher.network.stride]\n",
    "        \n",
    "        # Studentæ¨ç†\n",
    "        logits = self.student(emg)\n",
    "        \n",
    "        # BCE loss\n",
    "        loss = self.bce_loss(logits, targets).mean()\n",
    "        \n",
    "        # ä½¿ç”¨collect_metricè®¡ç®—å‡†ç¡®åº¦\n",
    "        self.collect_metric(logits, targets, phase='val')\n",
    "        \n",
    "        self.log('val/loss', loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def collect_metric(self, logits, target, phase):\n",
    "        \"\"\"\n",
    "        å¤åˆ¶Teacherçš„collect_metricæ–¹æ³•\n",
    "        åœ¨äº‹ä»¶å‘ç”Ÿæ—¶åˆ»çš„æ—¶é—´çª—å£å†…è¯„ä¼°åˆ†ç±»å‡†ç¡®åº¦\n",
    "        \"\"\"\n",
    "        device = logits.device\n",
    "        w_start = 10  # 50 ms at 200 Hz\n",
    "        w_end = 30  # 150 ms at 200 Hz\n",
    "        \n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # è½¬ç½®ä¸º [batch, time, classes]\n",
    "        probs = probs.transpose(1, 2)\n",
    "        target = target.transpose(1, 2)\n",
    "        \n",
    "        y = target.to(torch.int32)\n",
    "        y_class = []\n",
    "        y_hat_class = []\n",
    "        \n",
    "        for batch in range(y.shape[0]):\n",
    "            y_diff = torch.diff(y[batch], axis=0)\n",
    "            indices = torch.argwhere(y_diff == 1)\n",
    "            \n",
    "            for index in indices:\n",
    "                start = max(index[0] - w_start, 0)\n",
    "                end = min(index[0] + w_end, y.shape[1])\n",
    "                \n",
    "                y_hat = probs[batch, start:end, :]\n",
    "                flattened_index = y_hat.argmax()\n",
    "                _, cols = y_hat.shape\n",
    "                col = flattened_index % cols\n",
    "                \n",
    "                y_hat_class.append(col)\n",
    "                y_class.append(index[1])\n",
    "        \n",
    "        if len(y_class) > 0:\n",
    "            y_class = torch.stack(y_class).long().to(device)\n",
    "            y_hat_class = torch.stack(y_hat_class).long().to(device)\n",
    "        else:\n",
    "            y_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "            y_hat_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "        \n",
    "        self.val_accuracy.update(y_hat_class, y_class)\n",
    "        self.log(f'{phase}/accuracy', self.val_accuracy, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.student.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=MAX_EPOCHS\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# åˆ›å»ºè’¸é¦æ¨¡å‹\n",
    "distill_model = TimeSeriesDistillationModule(\n",
    "    teacher=teacher,\n",
    "    student=student,\n",
    "    temperature=TEMPERATURE,\n",
    "    alpha=ALPHA,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "print(\"âœ… è’¸é¦è®­ç»ƒæ¨¡å—åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"   Temperature: {TEMPERATURE}\")\n",
    "print(f\"   Alpha (è’¸é¦æƒé‡): {ALPHA}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0156bd93",
   "metadata": {},
   "source": [
    "## 8. é…ç½®è®­ç»ƒå™¨å’ŒCallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®è®­ç»ƒå™¨\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# æ—¥å¿—ç›®å½•\n",
    "log_dir = os.path.join(SAVE_DIR, EXPERIMENT_ID)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(log_dir, 'checkpoints'),\n",
    "    filename='epoch={epoch:02d}-val_acc={val/accuracy:.4f}',\n",
    "    monitor='val/accuracy',\n",
    "    mode='max',\n",
    "    save_top_k=3,\n",
    "    save_last=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val/accuracy',\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=log_dir,\n",
    "    name='tensorboard_logs'\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback, lr_monitor],\n",
    "    logger=logger,\n",
    "    precision=16,  # æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "    gradient_clip_val=1.0,\n",
    "    log_every_n_steps=10,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… è®­ç»ƒå™¨é…ç½®å®Œæˆ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"æ—¥å¿—ç›®å½•: {log_dir}\")\n",
    "print(f\"æœ€å¤§è½®æ•°: {MAX_EPOCHS}\")\n",
    "print(f\"æ—©åœpatience: 10\")\n",
    "print(f\"æ··åˆç²¾åº¦: FP16\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfba47f",
   "metadata": {},
   "source": [
    "## 9. æ‰§è¡Œè®­ç»ƒ ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¼€å§‹è®­ç»ƒ\n",
    "import time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸš€ å¼€å§‹è’¸é¦è®­ç»ƒ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Teacherå‡†ç¡®åº¦: 47.42% (validation)\")\n",
    "print(f\"ç›®æ ‡Studentå‡†ç¡®åº¦: 35-45%\")\n",
    "print(f\"é¢„è®¡è®­ç»ƒæ—¶é—´: ~1-1.5å°æ—¶ (T4 GPU)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# è®­ç»ƒ\n",
    "trainer.fit(distill_model, data_module)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "hours = int(elapsed_time // 3600)\n",
    "minutes = int((elapsed_time % 3600) // 60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… è®­ç»ƒå®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"è®­ç»ƒæ—¶é—´: {hours}å°æ—¶ {minutes}åˆ†é’Ÿ\")\n",
    "print(f\"æœ€ä½³checkpoint: {checkpoint_callback.best_model_path}\")\n",
    "print(f\"æœ€ä½³éªŒè¯å‡†ç¡®åº¦: {checkpoint_callback.best_model_score:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651a9d4",
   "metadata": {},
   "source": [
    "## 10. ç»“æœè¯„ä¼°ä¸å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "print(\"ğŸ“Š è¯„ä¼°æœ€ä½³æ¨¡å‹...\\n\")\n",
    "\n",
    "best_model = TimeSeriesDistillationModule.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    teacher=teacher,\n",
    "    student=student,\n",
    "    temperature=TEMPERATURE,\n",
    "    alpha=ALPHA,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°\n",
    "val_results = trainer.validate(best_model, data_module, verbose=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š æœ€ç»ˆç»“æœå¯¹æ¯”\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Teacheræ¨¡å‹:\")\n",
    "print(f\"  å‚æ•°é‡: {teacher_params / 1e6:.2f}M\")\n",
    "print(f\"  éªŒè¯å‡†ç¡®åº¦: 47.42%\")\n",
    "print()\n",
    "print(f\"Studentæ¨¡å‹ (TimeSeriesStudent):\")\n",
    "print(f\"  å‚æ•°é‡: {student_params / 1e6:.2f}M\")\n",
    "print(f\"  éªŒè¯å‡†ç¡®åº¦: {val_results[0]['val/accuracy']*100:.2f}%\")\n",
    "print(f\"  éªŒè¯æŸå¤±: {val_results[0]['val/loss']:.4f}\")\n",
    "print()\n",
    "print(f\"å‹ç¼©æ¯”: {teacher_params / student_params:.1f}x\")\n",
    "print(f\"å‡†ç¡®åº¦ä¿ç•™: {val_results[0]['val/accuracy'] / 0.4742 * 100:.1f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ä¿å­˜å…³é”®ä¿¡æ¯\n",
    "result_summary = {\n",
    "    'experiment_id': EXPERIMENT_ID,\n",
    "    'teacher_params': teacher_params,\n",
    "    'student_params': student_params,\n",
    "    'compression_ratio': teacher_params / student_params,\n",
    "    'teacher_val_acc': 0.4742,\n",
    "    'student_val_acc': val_results[0]['val/accuracy'].item(),\n",
    "    'student_val_loss': val_results[0]['val/loss'].item(),\n",
    "    'best_checkpoint': checkpoint_callback.best_model_path,\n",
    "    'training_time_minutes': int(elapsed_time / 60)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(os.path.join(log_dir, 'result_summary.json'), 'w') as f:\n",
    "    json.dump(result_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {log_dir}/result_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328be60",
   "metadata": {},
   "source": [
    "## 11. å¯¼å‡ºStudentæ¨¡å‹ï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2014ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å‡ºçº¯Studentæ¨¡å‹ï¼ˆä¸å«Training wrapperï¼‰\n",
    "student_save_path = os.path.join(log_dir, 'student_model.pt')\n",
    "torch.save({\n",
    "    'model_state_dict': best_model.student.state_dict(),\n",
    "    'model_config': {\n",
    "        'num_classes': 9,\n",
    "        'input_channels': 16,\n",
    "        'stride': 10,\n",
    "        'left_context': 20\n",
    "    },\n",
    "    'val_accuracy': val_results[0]['val/accuracy'].item(),\n",
    "    'parameters': student_params\n",
    "}, student_save_path)\n",
    "\n",
    "print(f\"âœ… Studentæ¨¡å‹å·²å¯¼å‡ºåˆ°: {student_save_path}\")\n",
    "print(f\"\\nğŸ’¡ ä¸‹ä¸€æ­¥:\")\n",
    "print(f\"   1. é‡åŒ–æ¨¡å‹: ä½¿ç”¨PyTorchçš„é‡åŒ–å·¥å…·\")\n",
    "print(f\"   2. è½¬æ¢ä¸ºTFLite: ç”¨äºESP32éƒ¨ç½²\")\n",
    "print(f\"   3. ç»§ç»­è®­ç»ƒ: åŠ è½½checkpointè®­ç»ƒæ›´å¤šepochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8de03",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "### âœ… å®Œæˆçš„å·¥ä½œ\n",
    "1. **æ­£ç¡®çš„ä»»åŠ¡å®šä¹‰**: æ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹ï¼Œè¾“å‡º `[batch, 9, 1598]`\n",
    "2. **æ­£ç¡®çš„æ¨¡å‹æ¶æ„**: TimeSeriesStudent (140Kå‚æ•°, 45xå‹ç¼©)\n",
    "3. **æ­£ç¡®çš„è’¸é¦æ–¹æ³•**: BCE + MSEè’¸é¦ï¼Œä¿ç•™æ—¶é—´åºåˆ—ä¿¡æ¯\n",
    "4. **æ­£ç¡®çš„è¯„ä¼°æ–¹æ³•**: ä½¿ç”¨Teacherçš„collect_metric\n",
    "\n",
    "### ğŸ“Š é¢„æœŸvså®é™…\n",
    "- **é¢„æœŸå‡†ç¡®åº¦**: 35-45%\n",
    "- **å®é™…å‡†ç¡®åº¦**: (è®­ç»ƒåæŸ¥çœ‹)\n",
    "- **Teacherå‡†ç¡®åº¦**: 47.42%\n",
    "\n",
    "### ğŸ¯ ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘\n",
    "1. **å¢åŠ è®­ç»ƒè½®æ•°**: 50-100 epochs\n",
    "2. **è°ƒæ•´è¶…å‚æ•°**: temperature (2-6), alpha (0.5-0.9)\n",
    "3. **æ¨¡å‹æ¶æ„**: å¢åŠ GRUå±‚æ•°æˆ–hidden size\n",
    "4. **é‡åŒ–éƒ¨ç½²**: INT8é‡åŒ– â†’ TFLite â†’ ESP32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

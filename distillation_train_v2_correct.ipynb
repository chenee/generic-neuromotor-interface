{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d9e868",
   "metadata": {},
   "source": [
    "# EMGæ¨¡å‹çŸ¥è¯†è’¸é¦è®­ç»ƒ - æ­£ç¡®ç‰ˆæœ¬ V2\n",
    "\n",
    "**æ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹ä»»åŠ¡çš„æ¨¡å‹å‹ç¼©**\n",
    "\n",
    "## ç›®æ ‡\n",
    "- Teacher: Metaå®˜æ–¹DiscreteGesturesModule (6.5Må‚æ•°, 48.66%å‡†ç¡®åº¦)\n",
    "- Student: TimeSeriesStudent (880Kå‚æ•°, 7.4xå‹ç¼©)\n",
    "- è¾“å‡º: æ—¶é—´åºåˆ— `[batch, 9, 1598]` (æ­£ç¡®ï¼)\n",
    "- é¢„æœŸå‡†ç¡®åº¦: 30-40% (ç›´æ¥è®­ç»ƒ)\n",
    "\n",
    "## å…³é”®å‘ç°\n",
    "âœ… è¾“å‡ºæ ¼å¼: æ—¶é—´åºåˆ—è€Œéå•åˆ†ç±»  \n",
    "âœ… æŸå¤±å‡½æ•°: BCE + Masking\n",
    "âœ… è¯„ä¼°æ–¹æ³•: ä½¿ç”¨Teacherçš„collect_metric  \n",
    "âœ… ä»»åŠ¡å®šä¹‰: å¤šæ ‡ç­¾æ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹\n",
    "âš ï¸ **è’¸é¦æ•ˆæœä¸ä½³**ï¼šç›´æ¥è®­ç»ƒ(17.48%) > è’¸é¦è®­ç»ƒ(11.12%)ï¼Œé‡‡ç”¨ç›´æ¥è®­ç»ƒæ–¹å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896ad8b",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®ä¸å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affe6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿è¡Œç¯å¢ƒ: Google Colab\n",
      "ğŸ”§ åœ¨Colabç¯å¢ƒä¸­è®¾ç½®...\n",
      "Cloning into 'generic-neuromotor-interface'...\n",
      "remote: Enumerating objects: 110, done.\u001b[K\n",
      "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
      "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
      "remote: Total 110 (delta 21), reused 18 (delta 13), pack-reused 39 (from 1)\u001b[K\n",
      "Receiving objects: 100% (110/110), 4.46 MiB | 11.57 MiB/s, done.\n",
      "Resolving deltas: 100% (24/24), done.\n",
      "ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# æ£€æµ‹è¿è¡Œç¯å¢ƒ\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"è¿è¡Œç¯å¢ƒ: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ”§ åœ¨Colabç¯å¢ƒä¸­è®¾ç½®...\")\n",
    "    # åˆ‡æ¢åˆ°ä»£ç ç›®å½•\n",
    "    if not os.path.exists('/content/generic-neuromotor-interface'):\n",
    "        !git clone https://github.com/facebookresearch/generic-neuromotor-interface.git\n",
    "    os.chdir('/content/generic-neuromotor-interface')\n",
    "    \n",
    "    # å®‰è£…æ‰€æœ‰å¿…è¦çš„ä¾èµ–\n",
    "    print(\"ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...\")\n",
    "    !pip install -q pytorch-lightning==1.8.6 hydra-core==1.3.2 omegaconf==2.3.0\n",
    "    !pip install -q h5py python-Levenshtein unidecode scipy pandas seaborn\n",
    "    !pip install -q -e .\n",
    "    \n",
    "    print(\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âœ… æœ¬åœ°ç¯å¢ƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da2bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "âœ… Driveå·²æŒ‚è½½\n",
      "ğŸ“‚ æ•°æ®è·¯å¾„: /content/drive/MyDrive/generic-neuromotor-data/data\n",
      "ğŸ“‚ æ¨¡å‹è·¯å¾„: /content/drive/MyDrive/generic-neuromotor-data/models\n",
      "ğŸ’¾ ä¿å­˜è·¯å¾„: /content/drive/MyDrive/emg_distillation\n"
     ]
    }
   ],
   "source": [
    "# æŒ‚è½½Google Driveï¼ˆä½¿ç”¨å·²ä¸‹è½½çš„æ•°æ®å’Œæ¨¡å‹ï¼‰\n",
    "USE_GOOGLE_DRIVE = True  # å·²æ”¹ä¸ºTrueï¼Œä½¿ç”¨Driveä¸­çš„æ•°æ®\n",
    "\n",
    "if IN_COLAB and USE_GOOGLE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # æ•°æ®å’Œæ¨¡å‹è·¯å¾„ - ä½¿ç”¨Driveä¸­å·²ä¸‹è½½çš„å†…å®¹\n",
    "    DRIVE_DATA_DIR = '/content/drive/MyDrive/generic-neuromotor-data'\n",
    "    DATA_PATH = f'{DRIVE_DATA_DIR}/data'\n",
    "    MODELS_PATH = f'{DRIVE_DATA_DIR}/models'\n",
    "    SAVE_DIR = '/content/drive/MyDrive/emg_distillation'\n",
    "    \n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    print(f\"âœ… Driveå·²æŒ‚è½½\")\n",
    "    print(f\"ğŸ“‚ æ•°æ®è·¯å¾„: {DATA_PATH}\")\n",
    "    print(f\"ğŸ“‚ æ¨¡å‹è·¯å¾„: {MODELS_PATH}\")\n",
    "    print(f\"ğŸ’¾ ä¿å­˜è·¯å¾„: {SAVE_DIR}\")\n",
    "else:\n",
    "    SAVE_DIR = './logs/distillation'\n",
    "    DATA_PATH = \"~/emg_data\"\n",
    "    MODELS_PATH = \"~/emg_models\"\n",
    "    print(f\"âœ… å°†ä¿å­˜åˆ°: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b91d91",
   "metadata": {},
   "source": [
    "## 2. ç¡®è®¤æ•°æ®å’ŒTeacheræ¨¡å‹ï¼ˆä½¿ç”¨Driveä¸­å·²ä¸‹è½½çš„æ•°æ®ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6831f620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ£€æŸ¥æ•°æ®å’Œæ¨¡å‹...\n",
      "âœ… æ•°æ®ç›®å½•å­˜åœ¨: /content/drive/MyDrive/generic-neuromotor-data/data\n",
      "   åŒ…å« 100 ä¸ªHDF5æ–‡ä»¶\n",
      "âœ… Teacheræ¨¡å‹å­˜åœ¨: /content/drive/MyDrive/generic-neuromotor-data/models/discrete_gestures/model_checkpoint.ckpt\n",
      "   å¤§å°: 74.2 MB\n",
      "\n",
      "ğŸ“ Teacher checkpoint: /content/drive/MyDrive/generic-neuromotor-data/models/discrete_gestures/model_checkpoint.ckpt\n"
     ]
    }
   ],
   "source": [
    "# ç¡®è®¤æ•°æ®å’Œæ¨¡å‹ï¼ˆå·²åœ¨Driveä¸­ï¼Œä¸éœ€è¦é‡æ–°ä¸‹è½½ï¼‰\n",
    "TASK = \"discrete_gestures\"\n",
    "\n",
    "# DATA_PATH å’Œ MODELS_PATH å·²åœ¨ä¸Šä¸€cellä¸­è®¾ç½®\n",
    "# å¦‚æœéœ€è¦é‡æ–°è®¾ç½®ï¼ˆæœ¬åœ°ç¯å¢ƒï¼‰ï¼š\n",
    "if not USE_GOOGLE_DRIVE:\n",
    "    DATA_PATH = \"~/emg_data\"\n",
    "    MODELS_PATH = \"~/emg_models\"\n",
    "\n",
    "# ç¡®è®¤æ•°æ®ç›®å½•\n",
    "print(\"ğŸ” æ£€æŸ¥æ•°æ®å’Œæ¨¡å‹...\")\n",
    "data_path = os.path.expanduser(DATA_PATH) if not USE_GOOGLE_DRIVE else DATA_PATH\n",
    "models_path = os.path.expanduser(MODELS_PATH) if not USE_GOOGLE_DRIVE else MODELS_PATH\n",
    "\n",
    "# æ£€æŸ¥æ•°æ®ï¼ˆæ•°æ®ç›´æ¥åœ¨ data/ ç›®å½•ä¸‹ï¼Œä¸åœ¨å­ç›®å½•ä¸­ï¼‰\n",
    "data_dir = data_path  # ç›´æ¥ä½¿ç”¨ data_pathï¼Œä¸éœ€è¦æ·»åŠ  TASK/full_data å­è·¯å¾„\n",
    "if os.path.exists(data_dir):\n",
    "    num_files = len([f for f in os.listdir(data_dir) if f.endswith('.hdf5')])\n",
    "    print(f\"âœ… æ•°æ®ç›®å½•å­˜åœ¨: {data_dir}\")\n",
    "    print(f\"   åŒ…å« {num_files} ä¸ªHDF5æ–‡ä»¶\")\n",
    "else:\n",
    "    print(f\"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}\")\n",
    "    print(\"   è¯·ç¡®è®¤Driveä¸­çš„è·¯å¾„æ˜¯å¦æ­£ç¡®\")\n",
    "\n",
    "# æ£€æŸ¥Teacheræ¨¡å‹ï¼ˆæ¨¡å‹åœ¨ models/discrete_gestures/ å­ç›®å½•ä¸‹ï¼‰\n",
    "TEACHER_CHECKPOINT = os.path.join(models_path, TASK, \"model_checkpoint.ckpt\")\n",
    "if os.path.exists(TEACHER_CHECKPOINT):\n",
    "    size_mb = os.path.getsize(TEACHER_CHECKPOINT) / 1024 / 1024\n",
    "    print(f\"âœ… Teacheræ¨¡å‹å­˜åœ¨: {TEACHER_CHECKPOINT}\")\n",
    "    print(f\"   å¤§å°: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(f\"âŒ Teacheræ¨¡å‹ä¸å­˜åœ¨: {TEACHER_CHECKPOINT}\")\n",
    "    print(\"   è¯·ç¡®è®¤Driveä¸­çš„è·¯å¾„æ˜¯å¦æ­£ç¡®\")\n",
    "    # å°è¯•æŸ¥æ‰¾å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶\n",
    "    if os.path.exists(models_path):\n",
    "        print(f\"   models/ ç›®å½•å†…å®¹:\")\n",
    "        for f in os.listdir(models_path):\n",
    "            print(f\"     - {f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Teacher checkpoint: {TEACHER_CHECKPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e4320",
   "metadata": {},
   "source": [
    "## 3. é…ç½®è¶…å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278fd99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ è®­ç»ƒé…ç½®\n",
      "============================================================\n",
      "å®éªŒID: distill_timeseries_v2_L4\n",
      "æœ€å¤§è½®æ•°: 30\n",
      "æ‰¹å¤§å°: 128\n",
      "è’¸é¦æ¸©åº¦: 4.0\n",
      "è’¸é¦æƒé‡Alpha: 0.3\n",
      "å­¦ä¹ ç‡: 0.002\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# è’¸é¦è®­ç»ƒè¶…å‚æ•° - L4 GPUä¼˜åŒ–ï¼ˆè°ƒæ•´åï¼‰\n",
    "EXPERIMENT_ID = \"distill_timeseries_v2_L4\"\n",
    "MAX_EPOCHS = 30  # å¿«é€Ÿè®­ç»ƒï¼Œå¯åç»­å¢åŠ åˆ°50-100\n",
    "BATCH_SIZE = 128  # L4 GPUä¼˜åŒ–ï¼ˆ24GBæ˜¾å­˜ï¼Œä»64å¢åŠ åˆ°128ï¼‰\n",
    "TEMPERATURE = 4.0  # è’¸é¦æ¸©åº¦\n",
    "ALPHA = 0.3  # è’¸é¦æŸå¤±æƒé‡ï¼ˆ0.3*è’¸é¦ + 0.7*çœŸå®æ ‡ç­¾ - æ›´å¤šå­¦ä¹ çœŸå®æ ‡ç­¾ï¼‰\n",
    "LEARNING_RATE = 2e-3  # å¢åŠ å­¦ä¹ ç‡ä»¥åŠ å¿«æ”¶æ•›\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ¯ è®­ç»ƒé…ç½®\")\n",
    "print(\"=\"*60)\n",
    "print(f\"å®éªŒID: {EXPERIMENT_ID}\")\n",
    "print(f\"æœ€å¤§è½®æ•°: {MAX_EPOCHS}\")\n",
    "print(f\"æ‰¹å¤§å°: {BATCH_SIZE}\")\n",
    "print(f\"è’¸é¦æ¸©åº¦: {TEMPERATURE}\")\n",
    "print(f\"è’¸é¦æƒé‡Alpha: {ALPHA}\")\n",
    "print(f\"å­¦ä¹ ç‡: {LEARNING_RATE}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e7ebc3",
   "metadata": {},
   "source": [
    "## 4. åŠ è½½Teacheræ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae5721c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ åŠ è½½Teacheræ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'network' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['network'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Teacheræ¨¡å‹åŠ è½½å®Œæˆ\n",
      "   å‚æ•°é‡: 6.48M\n",
      "   ç½‘ç»œé…ç½®: stride=10, left_context=20\n",
      "   è¾“å‡ºå½¢çŠ¶: torch.Size([2, 9, 1598])  # [batch, 9, 1598]\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½Teacheræ¨¡å‹\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from generic_neuromotor_interface.lightning import DiscreteGesturesModule\n",
    "\n",
    "print(\"ğŸ“¦ åŠ è½½Teacheræ¨¡å‹...\")\n",
    "\n",
    "# PyTorch 2.6+ weights_onlyå¤„ç†\n",
    "original_torch_load = torch.load\n",
    "def patched_torch_load(*args, **kwargs):\n",
    "    kwargs['weights_only'] = False\n",
    "    return original_torch_load(*args, **kwargs)\n",
    "torch.load = patched_torch_load\n",
    "\n",
    "# åŠ è½½checkpoint\n",
    "teacher = DiscreteGesturesModule.load_from_checkpoint(\n",
    "    TEACHER_CHECKPOINT,\n",
    "    map_location='cpu'\n",
    ")\n",
    "\n",
    "# æ¢å¤torch.load\n",
    "torch.load = original_torch_load\n",
    "\n",
    "# ç§»åˆ°GPUå¹¶å†»ç»“\n",
    "if torch.cuda.is_available():\n",
    "    teacher = teacher.cuda()\n",
    "teacher.eval()\n",
    "teacher.freeze()\n",
    "\n",
    "teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "print(f\"âœ… Teacheræ¨¡å‹åŠ è½½å®Œæˆ\")\n",
    "print(f\"   å‚æ•°é‡: {teacher_params / 1e6:.2f}M\")\n",
    "print(f\"   ç½‘ç»œé…ç½®: stride={teacher.network.stride}, left_context={teacher.network.left_context}\")\n",
    "\n",
    "# æµ‹è¯•è¾“å‡ºå½¢çŠ¶\n",
    "test_input = torch.randn(2, 16, 16000)\n",
    "if torch.cuda.is_available():\n",
    "    test_input = test_input.cuda()\n",
    "with torch.no_grad():\n",
    "    test_output = teacher(test_input)\n",
    "print(f\"   è¾“å‡ºå½¢çŠ¶: {test_output.shape}  # [batch, 9, 1598]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75816b8",
   "metadata": {},
   "source": [
    "## 4.5 æ€§èƒ½ä¼˜åŒ–ï¼šå¤åˆ¶æ•°æ®åˆ°æœ¬åœ°ï¼ˆå¯é€‰ä½†å¼ºçƒˆæ¨èï¼‰\n",
    "\n",
    "**é—®é¢˜è¯´æ˜**ï¼š\n",
    "- æ•°æ®åŠ è½½éœ€è¦æ‰“å¼€90ä¸ªHDF5æ–‡ä»¶ï¼ˆ80è®­ç»ƒ+10éªŒè¯ï¼‰\n",
    "- ä»Driveè¯»å–HDF5æ–‡ä»¶å¾ˆæ…¢ï¼ˆ5-10åˆ†é’Ÿï¼‰\n",
    "- è®­ç»ƒæ—¶æ¯ä¸ªepochä¹Ÿè¦ä»Driveè¯»å–æ•°æ®ï¼ˆæ…¢20-30%ï¼‰\n",
    "\n",
    "**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š\n",
    "- ä¸€æ¬¡æ€§å¤åˆ¶31GBæ•°æ®åˆ°Colabæœ¬åœ°SSDï¼ˆ5-8åˆ†é’Ÿï¼‰\n",
    "- åç»­åŠ è½½å’Œè®­ç»ƒéƒ½å¾ˆå¿«ï¼ˆsetupä»…éœ€1åˆ†é’Ÿï¼Œè®­ç»ƒå¿«30%ï¼‰\n",
    "- **æ€»æ—¶é—´èŠ‚çœï¼šçº¦30åˆ†é’Ÿ**\n",
    "\n",
    "è¿è¡Œä¸‹é¢çš„cellæ¥å¤åˆ¶æ•°æ®ï¼ˆå¦‚æœå·²åœ¨æœ¬åœ°ç¯å¢ƒåˆ™è·³è¿‡ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3aea068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ å¼€å§‹å¤åˆ¶æ•°æ®åˆ°æœ¬åœ°SSD...\n",
      "   æºè·¯å¾„: /content/drive/MyDrive/generic-neuromotor-data/data\n",
      "   ç›®æ ‡è·¯å¾„: /content/emg_data_local\n",
      "   æ•°æ®å¤§å°: çº¦31GBï¼Œé¢„è®¡5-8åˆ†é’Ÿ\n",
      "\n",
      "â³ å¤åˆ¶ä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…...\n",
      "\n",
      "âœ… å¤åˆ¶å®Œæˆï¼è€—æ—¶: 14.7 åˆ†é’Ÿ\n",
      "   æ•°æ®: /content/emg_data_local\n",
      "   æ¨¡å‹: /content/emg_models_local\n",
      "\n",
      "ğŸ’¡ ç°åœ¨æ•°æ®åŠ è½½å’Œè®­ç»ƒéƒ½ä¼šä½¿ç”¨æœ¬åœ°å‰¯æœ¬ï¼ˆå¿«å¾ˆå¤šï¼ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# å¤åˆ¶æ•°æ®åˆ°æœ¬åœ°ä»¥åŠ é€Ÿè®­ç»ƒï¼ˆColabç¯å¢ƒæ¨èï¼‰\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "if IN_COLAB and USE_GOOGLE_DRIVE:\n",
    "    # æœ¬åœ°æ•°æ®è·¯å¾„\n",
    "    LOCAL_DATA_PATH = '/content/emg_data_local'\n",
    "    LOCAL_MODELS_PATH = '/content/emg_models_local'\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦å·²å¤åˆ¶\n",
    "    if not os.path.exists(LOCAL_DATA_PATH):\n",
    "        print(f\"ğŸ“‹ å¼€å§‹å¤åˆ¶æ•°æ®åˆ°æœ¬åœ°SSD...\")\n",
    "        print(f\"   æºè·¯å¾„: {DATA_PATH}\")\n",
    "        print(f\"   ç›®æ ‡è·¯å¾„: {LOCAL_DATA_PATH}\")\n",
    "        print(f\"   æ•°æ®å¤§å°: çº¦31GBï¼Œé¢„è®¡5-8åˆ†é’Ÿ\")\n",
    "        print(f\"\\nâ³ å¤åˆ¶ä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…...\")\n",
    "        \n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # å¤åˆ¶æ•°æ®æ–‡ä»¶å¤¹\n",
    "        shutil.copytree(DATA_PATH, LOCAL_DATA_PATH)\n",
    "        \n",
    "        # å¤åˆ¶æ¨¡å‹æ–‡ä»¶å¤¹\n",
    "        shutil.copytree(MODELS_PATH, LOCAL_MODELS_PATH)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nâœ… å¤åˆ¶å®Œæˆï¼è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ\")\n",
    "        print(f\"   æ•°æ®: {LOCAL_DATA_PATH}\")\n",
    "        print(f\"   æ¨¡å‹: {LOCAL_MODELS_PATH}\")\n",
    "        \n",
    "        # æ›´æ–°è·¯å¾„å˜é‡\n",
    "        DATA_PATH = LOCAL_DATA_PATH\n",
    "        MODELS_PATH = LOCAL_MODELS_PATH\n",
    "        TEACHER_CHECKPOINT = os.path.join(MODELS_PATH, TASK, \"model_checkpoint.ckpt\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ ç°åœ¨æ•°æ®åŠ è½½å’Œè®­ç»ƒéƒ½ä¼šä½¿ç”¨æœ¬åœ°å‰¯æœ¬ï¼ˆå¿«å¾ˆå¤šï¼ï¼‰\")\n",
    "    else:\n",
    "        print(f\"âœ… æ•°æ®å·²åœ¨æœ¬åœ°:\")\n",
    "        print(f\"   {LOCAL_DATA_PATH}\")\n",
    "        \n",
    "        # ç›´æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„\n",
    "        DATA_PATH = LOCAL_DATA_PATH\n",
    "        MODELS_PATH = LOCAL_MODELS_PATH\n",
    "        TEACHER_CHECKPOINT = os.path.join(MODELS_PATH, TASK, \"model_checkpoint.ckpt\")\n",
    "        \n",
    "        print(f\"ğŸ’¡ä½¿ç”¨æœ¬åœ°æ•°æ®ï¼Œè·³è¿‡å¤åˆ¶\")\n",
    "else:\n",
    "    print(f\"â­ï¸  æœ¬åœ°ç¯å¢ƒæˆ–æœªä½¿ç”¨Driveï¼Œè·³è¿‡å¤åˆ¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38723596",
   "metadata": {},
   "source": [
    "## 5. å‡†å¤‡æ•°æ®æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5cb80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š å‡†å¤‡æ•°æ®æ¨¡å—...\n",
      "ğŸ“„ åŠ è½½æ•°æ®splité…ç½®: /content/emg_data_local/discrete_gestures_corpus.csv\n",
      "âœ… æ•°æ®splitåŠ è½½å®Œæˆ\n",
      "\n",
      "ğŸ”§ é…ç½®æ•°æ®è½¬æ¢...\n",
      "ğŸ—ï¸  åˆ›å»ºæ•°æ®æ¨¡å—...\n",
      "\n",
      "âš™ï¸  è®¾ç½®æ•°æ®åŠ è½½å™¨ï¼ˆæ‰“å¼€HDF5æ–‡ä»¶ï¼‰...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c91d9be177f46d48d5909e4c1f40cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split train:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5e864510d24524a6c56fac717f8351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setupå®Œæˆï¼Œè€—æ—¶: 211.7ç§’\n",
      "\n",
      "âœ… æ•°æ®æ¨¡å—åˆ›å»ºå®Œæˆ\n",
      "   è®­ç»ƒbatches: 216\n",
      "   éªŒè¯batches: 27\n",
      "   Batch size: 128\n",
      "\n",
      "ğŸ“¦ è·å–æ ·æœ¬æ•°æ®...\n",
      "âœ… æ•°æ®æ ¼å¼æ£€æŸ¥:\n",
      "   EMG shape: torch.Size([128, 16, 16000])  # [batch, channels, time]\n",
      "   Targets shape: torch.Size([128, 9, 16000])  # [batch, classes, time]\n"
     ]
    }
   ],
   "source": [
    "# å‡†å¤‡æ•°æ®åŠ è½½å™¨\n",
    "from generic_neuromotor_interface.data_module import WindowedEmgDataModule\n",
    "from generic_neuromotor_interface.data import DataSplit\n",
    "from generic_neuromotor_interface.transforms import DiscreteGesturesTransform\n",
    "from generic_neuromotor_interface.augmentation import RotationAugmentation\n",
    "import time\n",
    "\n",
    "print(\"ğŸ“Š å‡†å¤‡æ•°æ®æ¨¡å—...\")\n",
    "\n",
    "# æ•°æ®è·¯å¾„å¤„ç†\n",
    "if USE_GOOGLE_DRIVE:\n",
    "    data_location = DATA_PATH\n",
    "else:\n",
    "    data_location = os.path.expanduser(DATA_PATH)\n",
    "\n",
    "# åŠ è½½æ•°æ®splité…ç½®\n",
    "csv_file = os.path.join(data_location, f\"{TASK}_corpus.csv\")\n",
    "print(f\"ğŸ“„ åŠ è½½æ•°æ®splité…ç½®: {csv_file}\")\n",
    "\n",
    "data_split = DataSplit.from_csv(\n",
    "    csv_filename=csv_file,\n",
    "    pool_test_partitions=True\n",
    ")\n",
    "print(f\"âœ… æ•°æ®splitåŠ è½½å®Œæˆ\")\n",
    "\n",
    "# Transformå’ŒAugmentation\n",
    "print(f\"\\nğŸ”§ é…ç½®æ•°æ®è½¬æ¢...\")\n",
    "transform = DiscreteGesturesTransform(pulse_window=(0, 8))  # 40ms at 200Hz\n",
    "emg_augmentation = RotationAugmentation()\n",
    "\n",
    "# åˆ›å»ºæ•°æ®æ¨¡å—\n",
    "print(f\"ğŸ—ï¸  åˆ›å»ºæ•°æ®æ¨¡å—...\")\n",
    "data_module = WindowedEmgDataModule(\n",
    "    data_location=data_location,\n",
    "    data_split=data_split,\n",
    "    transform=transform,\n",
    "    emg_augmentation=emg_augmentation,\n",
    "    window_length=16000,  # 80ç§’ @ 200Hz\n",
    "    stride=8000,  # 50% overlap\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4  # L4 GPUä¼˜åŒ–ï¼šå¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹\n",
    ")\n",
    "\n",
    "# Setupæ•°æ®åŠ è½½å™¨ï¼ˆæ‰“å¼€100ä¸ªHDF5æ–‡ä»¶ï¼‰\n",
    "print(f\"\\nâš™ï¸  è®¾ç½®æ•°æ®åŠ è½½å™¨ï¼ˆæ‰“å¼€HDF5æ–‡ä»¶ï¼‰...\")\n",
    "setup_start = time.time()\n",
    "\n",
    "data_module.setup('fit')\n",
    "\n",
    "setup_time = time.time() - setup_start\n",
    "print(f\"âœ… Setupå®Œæˆï¼Œè€—æ—¶: {setup_time:.1f}ç§’\")\n",
    "\n",
    "print(f\"\\nâœ… æ•°æ®æ¨¡å—åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"   è®­ç»ƒbatches: {len(data_module.train_dataloader())}\")\n",
    "print(f\"   éªŒè¯batches: {len(data_module.val_dataloader())}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# éªŒè¯æ•°æ®æ ¼å¼\n",
    "print(f\"\\nğŸ“¦ è·å–æ ·æœ¬æ•°æ®...\")\n",
    "sample_batch = next(iter(data_module.train_dataloader()))\n",
    "print(f\"âœ… æ•°æ®æ ¼å¼æ£€æŸ¥:\")\n",
    "print(f\"   EMG shape: {sample_batch['emg'].shape}  # [batch, channels, time]\")\n",
    "print(f\"   Targets shape: {sample_batch['targets'].shape}  # [batch, classes, time]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5e244",
   "metadata": {},
   "source": [
    "## 5.5 éªŒè¯Teacheræ¨¡å‹å‡†ç¡®åº¦\n",
    "\n",
    "åœ¨å¼€å§‹è®­ç»ƒStudentä¹‹å‰ï¼Œå…ˆåœ¨éªŒè¯é›†ä¸Šæµ‹è¯•Teacheræ¨¡å‹çš„å‡†ç¡®åº¦ï¼Œç¡®ä¿æ•°æ®åŠ è½½æ­£ç¡®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2e8171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š è¯„ä¼°Teacheræ¨¡å‹å‡†ç¡®åº¦...\n",
      "\n",
      "âš™ï¸  åœ¨éªŒè¯é›†ä¸Šè¿è¡ŒTeacheræ¨¡å‹...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f687909764448e87fc2d0c148d9bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3edfb2873d479889a614da73944944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š Teacheræ¨¡å‹éªŒè¯ç»“æœ\n",
      "============================================================\n",
      "éªŒè¯å‡†ç¡®åº¦: 48.65%\n",
      "éªŒè¯æŸå¤±: 1.8168\n",
      "\n",
      "å¯¹æ¯”:\n",
      "  å®é™…å‡†ç¡®åº¦: 48.65%\n",
      "  é¢„æœŸå‡†ç¡®åº¦: 47.42%\n",
      "  å·®å¼‚: +1.23%\n",
      "\n",
      "âœ… å‡†ç¡®åº¦æ­£å¸¸ï¼Œæ•°æ®åŠ è½½æ­£ç¡®ï¼\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# éªŒè¯Teacheræ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å‡†ç¡®åº¦\n",
    "print(\"ğŸ“Š è¯„ä¼°Teacheræ¨¡å‹å‡†ç¡®åº¦...\\n\")\n",
    "\n",
    "# åˆ›å»ºä¸´æ—¶trainerç”¨äºevaluation\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "eval_trainer = Trainer(\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    logger=False,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "# åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°Teacher\n",
    "print(\"âš™ï¸  åœ¨éªŒè¯é›†ä¸Šè¿è¡ŒTeacheræ¨¡å‹...\")\n",
    "teacher_results = eval_trainer.validate(teacher, data_module, verbose=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š Teacheræ¨¡å‹éªŒè¯ç»“æœ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = teacher_results[0]\n",
    "teacher_acc = result.get('val_accuracy', result.get('accuracy', 0)) * 100\n",
    "teacher_loss = result.get('val_loss', result.get('loss', 0))\n",
    "\n",
    "print(f\"éªŒè¯å‡†ç¡®åº¦: {teacher_acc:.2f}%\")\n",
    "print(f\"éªŒè¯æŸå¤±: {teacher_loss:.4f}\")\n",
    "print(f\"\\nå¯¹æ¯”:\")\n",
    "print(f\"  å®é™…å‡†ç¡®åº¦: {teacher_acc:.2f}%\")\n",
    "print(f\"  é¢„æœŸå‡†ç¡®åº¦: 47.42%\")\n",
    "print(f\"  å·®å¼‚: {teacher_acc - 47.42:+.2f}%\")\n",
    "\n",
    "if abs(teacher_acc - 47.42) < 3.0:\n",
    "    print(f\"\\nâœ… å‡†ç¡®åº¦æ­£å¸¸ï¼Œæ•°æ®åŠ è½½æ­£ç¡®ï¼\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  å‡†ç¡®åº¦å·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥æ•°æ®\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf80c49",
   "metadata": {},
   "source": [
    "## 5.6 éªŒè¯Teacheræ¨¡å‹CLER\n",
    "\n",
    "CLER (Character-Level Error Rate) æ˜¯æ›´å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡ï¼Œè€ƒè™‘äº†åˆ†ç±»å‡†ç¡®åº¦å’Œæ—¶é—´ç²¾åº¦ã€‚\n",
    "\n",
    "**è¯´æ˜**ï¼š\n",
    "- éªŒè¯é›†ä½¿ç”¨ MulticlassAccuracyï¼ˆå¿«é€Ÿï¼‰\n",
    "- æµ‹è¯•é›†ä½¿ç”¨ CLERï¼ˆæ›´å‡†ç¡®ï¼Œä½†éœ€è¦æ•´ä¸ªæµ‹è¯•é›†ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b578fd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š è¯„ä¼°Teacheræ¨¡å‹CLERï¼ˆæµ‹è¯•é›†ï¼‰...\n",
      "\n",
      "âš™ï¸  å‡†å¤‡æµ‹è¯•æ•°æ®é›†...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1102885f3c47528d60da464194bec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split test:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'network' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['network'])`.\n",
      "  rank_zero_warn(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æµ‹è¯•é›†å‡†å¤‡å®Œæˆ\n",
      "âš™ï¸  é‡æ–°åŠ è½½Teacheræ¨¡å‹...\n",
      "âœ… Teacheræ¨¡å‹å·²åŠ è½½ï¼ˆCPUæ¨¡å¼ï¼Œé¿å…cuDNNé”™è¯¯ï¼‰\n",
      "\n",
      "âš™ï¸  åœ¨æµ‹è¯•é›†ä¸Šè¿è¡ŒTeacheræ¨¡å‹ï¼ˆè®¡ç®—CLERï¼‰...\n",
      "ğŸ’¡ ä½¿ç”¨CPUè¯„ä¼°ï¼Œé€Ÿåº¦è¾ƒæ…¢ä½†æ›´ç¨³å®š...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf678ed5685488fabebcb15b7b5b406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split test:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f8cd5ef5134d78b6daa0a9668a258a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:85: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š Teacheræ¨¡å‹æµ‹è¯•ç»“æœ (CLER)\n",
      "============================================================\n",
      "æµ‹è¯•é›†CLER: 0.1819\n",
      "\n",
      "è¯´æ˜:\n",
      "  CLER = Character-Level Error Rate\n",
      "  è¶Šä½è¶Šå¥½ (0 = å®Œç¾)\n",
      "  è€ƒè™‘äº†åˆ†ç±»å‡†ç¡®åº¦å’Œæ—¶é—´ç²¾åº¦\n",
      "\n",
      "æµ‹è¯•é›†æŸå¤±: 2.4291\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°Teacherçš„CLER\n",
    "print(\"ğŸ“Š è¯„ä¼°Teacheræ¨¡å‹CLERï¼ˆæµ‹è¯•é›†ï¼‰...\\n\")\n",
    "\n",
    "# éœ€è¦å…ˆsetup testé›†\n",
    "if not hasattr(data_module, '_test_dataset'):\n",
    "    print(\"âš™ï¸  å‡†å¤‡æµ‹è¯•æ•°æ®é›†...\")\n",
    "    data_module.setup('test')\n",
    "    print(f\"âœ… æµ‹è¯•é›†å‡†å¤‡å®Œæˆ\")\n",
    "\n",
    "# è§£å†³æ–¹æ¡ˆï¼šé‡æ–°åŠ è½½teacheræ¨¡å‹å¹¶ç§»åˆ°CPUï¼ˆé¿å…cuDNNé”™è¯¯ï¼‰\n",
    "print(\"âš™ï¸  é‡æ–°åŠ è½½Teacheræ¨¡å‹...\")\n",
    "# PyTorch 2.6+ weights_onlyå¤„ç†\n",
    "original_torch_load = torch.load\n",
    "def patched_torch_load(*args, **kwargs):\n",
    "    kwargs['weights_only'] = False\n",
    "    return original_torch_load(*args, **kwargs)\n",
    "torch.load = patched_torch_load\n",
    "\n",
    "# é‡æ–°åŠ è½½checkpoint - ä½¿ç”¨CPUé¿å…cuDNNé—®é¢˜\n",
    "teacher_for_test = DiscreteGesturesModule.load_from_checkpoint(\n",
    "    TEACHER_CHECKPOINT,\n",
    "    map_location='cpu'  # ä¿æŒåœ¨CPUä¸Š\n",
    ")\n",
    "\n",
    "# æ¢å¤torch.load\n",
    "torch.load = original_torch_load\n",
    "\n",
    "teacher_for_test.eval()\n",
    "teacher_for_test.freeze()\n",
    "print(\"âœ… Teacheræ¨¡å‹å·²åŠ è½½ï¼ˆCPUæ¨¡å¼ï¼Œé¿å…cuDNNé”™è¯¯ï¼‰\")\n",
    "\n",
    "# åˆ›å»ºæµ‹è¯•trainerï¼ˆä½¿ç”¨CPUï¼‰\n",
    "test_trainer = Trainer(\n",
    "    accelerator='cpu',  # ä½¿ç”¨CPUè¯„ä¼°CLER\n",
    "    devices=1,\n",
    "    logger=False,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "# åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œ\n",
    "print(\"\\nâš™ï¸  åœ¨æµ‹è¯•é›†ä¸Šè¿è¡ŒTeacheræ¨¡å‹ï¼ˆè®¡ç®—CLERï¼‰...\")\n",
    "print(\"ğŸ’¡ ä½¿ç”¨CPUè¯„ä¼°ï¼Œé€Ÿåº¦è¾ƒæ…¢ä½†æ›´ç¨³å®š...\")\n",
    "test_results = test_trainer.test(teacher_for_test, data_module, verbose=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š Teacheræ¨¡å‹æµ‹è¯•ç»“æœ (CLER)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if test_results and len(test_results) > 0:\n",
    "    test_result = test_results[0]\n",
    "    \n",
    "    if 'test_cler' in test_result:\n",
    "        teacher_cler = test_result['test_cler']\n",
    "        print(f\"æµ‹è¯•é›†CLER: {teacher_cler:.4f}\")\n",
    "        print(f\"\\nè¯´æ˜:\")\n",
    "        print(f\"  CLER = Character-Level Error Rate\")\n",
    "        print(f\"  è¶Šä½è¶Šå¥½ (0 = å®Œç¾)\")\n",
    "        print(f\"  è€ƒè™‘äº†åˆ†ç±»å‡†ç¡®åº¦å’Œæ—¶é—´ç²¾åº¦\")\n",
    "    else:\n",
    "        print(\"âš ï¸  æœªæ‰¾åˆ°test_cleræŒ‡æ ‡\")\n",
    "        print(f\"å¯ç”¨æŒ‡æ ‡: {list(test_result.keys())}\")\n",
    "    \n",
    "    if 'test_loss' in test_result:\n",
    "        print(f\"\\næµ‹è¯•é›†æŸå¤±: {test_result['test_loss']:.4f}\")\n",
    "else:\n",
    "    print(\"âŒ æµ‹è¯•å¤±è´¥ï¼Œæœªè·å–åˆ°ç»“æœ\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9516e",
   "metadata": {},
   "source": [
    "## 6. å®šä¹‰TimeSeriesStudentæ¨¡å‹\n",
    "\n",
    "**å…³é”®æ”¹è¿›**: è¾“å‡ºæ—¶é—´åºåˆ— `[batch, 9, 1598]` è€Œéå•åˆ†ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "820e184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "âœ… Studentæ¨¡å‹åˆ›å»ºå®Œæˆ\n",
      "============================================================\n",
      "å‚æ•°é‡: 0.88M\n",
      "å‹ç¼©æ¯”: 7.4x\n",
      "\n",
      "è¾“å‡ºå½¢çŠ¶éªŒè¯:\n",
      "  Teacher: torch.Size([2, 9, 1598])\n",
      "  Student: torch.Size([2, 9, 1598])\n",
      "  å½¢çŠ¶åŒ¹é…: True âœ…\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# TimeSeriesStudentæ¨¡å‹å®šä¹‰\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TimeSeriesStudent(nn.Module):\n",
    "    \"\"\"\n",
    "    æ—¶é—´åºåˆ—Studentæ¨¡å‹ - è¾“å‡ºä¸Teacheræ ¼å¼ä¸€è‡´\n",
    "    \n",
    "    æ¶æ„:\n",
    "    - Conv1d: ç‰¹å¾æå– + ä¸‹é‡‡æ · (stride=10)\n",
    "    - GRU: æ—¶é—´å»ºæ¨¡ (1å±‚, 128 hidden)\n",
    "    - Linear: æŠ•å½±åˆ°ç±»åˆ«ç©ºé—´\n",
    "    \n",
    "    è¾“å…¥: [batch, 16, 16000]\n",
    "    è¾“å‡º: [batch, 9, 1598]\n",
    "    å‚æ•°: ~140K (45xå‹ç¼©)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=9, input_channels=16, stride=10, left_context=20):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.stride = stride\n",
    "        self.left_context = left_context\n",
    "        \n",
    "        # å·ç§¯ç¼–ç å™¨ï¼ˆæ¨¡ä»¿Teacherçš„ç¬¬ä¸€å±‚ï¼‰- å¢åŠ é€šé“æ•°\n",
    "        self.conv1 = nn.Conv1d(input_channels, 256, kernel_size=21, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # è½»é‡çº§æ—¶é—´å»ºæ¨¡ï¼ˆGRUæ›¿ä»£LSTMï¼‰- å¢åŠ hidden sizeå’Œå±‚æ•°\n",
    "        self.gru = nn.GRU(256, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        # è¾“å‡ºæŠ•å½±\n",
    "        self.projection = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, emg):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        Args:\n",
    "            emg: [batch, channels=16, sequence=16000]\n",
    "        \n",
    "        Returns:\n",
    "            logits: [batch, num_classes=9, time_steps=1598]\n",
    "        \"\"\"\n",
    "        # 1. å·ç§¯ç‰¹å¾æå– + ä¸‹é‡‡æ ·\n",
    "        x = self.conv1(emg)  # [batch, 256, time_steps]\n",
    "        x = self.relu(self.bn1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 2. è½¬ç½®ä¸º [batch, time, features] ç”¨äºGRU\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # 3. GRUæ—¶é—´å»ºæ¨¡\n",
    "        x, _ = self.gru(x)  # [batch, time, 256]\n",
    "        \n",
    "        # 4. æŠ•å½±åˆ°ç±»åˆ«ç©ºé—´\n",
    "        x = self.projection(x)  # [batch, time, num_classes]\n",
    "        \n",
    "        # 5. è½¬ç½®å› [batch, num_classes, time]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºStudentæ¨¡å‹\n",
    "student = TimeSeriesStudent(\n",
    "    num_classes=9,\n",
    "    input_channels=16,\n",
    "    stride=10,\n",
    "    left_context=20\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    student = student.cuda()\n",
    "\n",
    "student_params = sum(p.numel() for p in student.parameters())\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… Studentæ¨¡å‹åˆ›å»ºå®Œæˆ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"å‚æ•°é‡: {student_params / 1e6:.2f}M\")\n",
    "print(f\"å‹ç¼©æ¯”: {teacher_params / student_params:.1f}x\")\n",
    "\n",
    "# éªŒè¯è¾“å‡ºå½¢çŠ¶\n",
    "with torch.no_grad():\n",
    "    student_output = student(test_input)\n",
    "    print(f\"\\nè¾“å‡ºå½¢çŠ¶éªŒè¯:\")\n",
    "    print(f\"  Teacher: {test_output.shape}\")\n",
    "    print(f\"  Student: {student_output.shape}\")\n",
    "    print(f\"  å½¢çŠ¶åŒ¹é…: {test_output.shape == student_output.shape} âœ…\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f220c",
   "metadata": {},
   "source": [
    "## 7. å®šä¹‰è’¸é¦è®­ç»ƒæ¨¡å—\n",
    "\n",
    "**å…³é”®æ”¹è¿›**: BCE + MSEè’¸é¦ï¼Œä½¿ç”¨Teacherçš„collect_metricè¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7bf761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Studentè®­ç»ƒæ¨¡å—åˆ›å»ºå®Œæˆï¼ˆç›´æ¥è®­ç»ƒï¼Œæ— è’¸é¦ï¼‰\n",
      "   Learning Rate: 0.002\n",
      "   ç†ç”±ï¼šè¯Šæ–­æµ‹è¯•æ˜¾ç¤ºç›´æ¥è®­ç»ƒ(17.48%) > è’¸é¦è®­ç»ƒ(11.12%)\n"
     ]
    }
   ],
   "source": [
    "# TimeSeriesDistillationModuleå®šä¹‰\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from generic_neuromotor_interface.constants import GestureType\n",
    "from generic_neuromotor_interface.lightning import FingerStateMaskGenerator\n",
    "\n",
    "class TimeSeriesDistillationModule(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    æ—¶é—´åºåˆ—è’¸é¦è®­ç»ƒæ¨¡å—\n",
    "    \n",
    "    æŸå¤±å‡½æ•°:\n",
    "    - è’¸é¦loss: MSE(student_logits, teacher_logits) with masking\n",
    "    - çœŸå®æ ‡ç­¾loss: BCEWithLogitsLoss with masking ï¼ˆå’ŒTeacherä¸€è‡´ï¼‰\n",
    "    - æ€»loss = alpha * è’¸é¦ + (1-alpha) * çœŸå®æ ‡ç­¾\n",
    "    \n",
    "    è¯„ä¼°æ–¹æ³•:\n",
    "    - ä½¿ç”¨Teacherçš„collect_metricæ–¹æ³•\n",
    "    - åœ¨äº‹ä»¶å‘ç”Ÿæ—¶åˆ»çš„æ—¶é—´çª—å£å†…è¯„ä¼°å‡†ç¡®åº¦\n",
    "    \"\"\"\n",
    "    def __init__(self, teacher, student, temperature, alpha, learning_rate):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # æŸå¤±å‡½æ•°\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        \n",
    "        # Masking generatorï¼ˆå’ŒTeacherä¸€è‡´ï¼‰\n",
    "        self.mask_generator = FingerStateMaskGenerator(lpad=0, rpad=7)\n",
    "        \n",
    "        # è¯„ä¼°æŒ‡æ ‡\n",
    "        self.val_accuracy = MulticlassAccuracy(num_classes=9)\n",
    "        \n",
    "        # ä¿å­˜è¶…å‚æ•°\n",
    "        self.save_hyperparameters(ignore=['teacher', 'student'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.student(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        emg = batch[\"emg\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        \n",
    "        # ä¸‹é‡‡æ ·targetsä»¥åŒ¹é…è¾“å‡ºé•¿åº¦\n",
    "        targets = targets[:, :, self.teacher.network.left_context::self.teacher.network.stride]\n",
    "        \n",
    "        # ç”Ÿæˆmaskï¼ˆå’ŒTeacherä¸€è‡´ï¼‰\n",
    "        release_mask = self.mask_generator(targets)\n",
    "        mask = torch.ones_like(targets)\n",
    "        mask[:, [GestureType.index_release.value, GestureType.middle_release.value], :] = release_mask\n",
    "        \n",
    "        # Teacherå‰å‘ä¼ æ’­ï¼ˆä¸è®¡ç®—æ¢¯åº¦ï¼‰\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = self.teacher(emg)\n",
    "        \n",
    "        # Studentå‰å‘ä¼ æ’­\n",
    "        student_logits = self.student(emg)\n",
    "        \n",
    "        # è’¸é¦æŸå¤±ï¼šMSE on logits (with temperature and masking)\n",
    "        soft_target = teacher_logits / self.temperature\n",
    "        soft_student = student_logits / self.temperature\n",
    "        distill_loss = F.mse_loss(soft_student, soft_target, reduction='none')\n",
    "        distill_loss = (distill_loss * mask).sum() / mask.sum()\n",
    "        distill_loss = distill_loss * (self.temperature ** 2)  # ç¼©æ”¾å›åŸå§‹å°ºåº¦\n",
    "        \n",
    "        # çœŸå®æ ‡ç­¾æŸå¤±ï¼šBCE with masking\n",
    "        student_loss = self.bce_loss(student_logits, targets)\n",
    "        student_loss = (student_loss * mask).sum() / mask.sum()\n",
    "        \n",
    "        # æ€»æŸå¤±\n",
    "        loss = self.alpha * distill_loss + (1 - self.alpha) * student_loss\n",
    "        \n",
    "        # è®°å½•æŒ‡æ ‡\n",
    "        self.log('train/loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        self.log('train/distill_loss', distill_loss, on_step=False, on_epoch=True)\n",
    "        self.log('train/student_loss', student_loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        emg = batch[\"emg\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        \n",
    "        # ä¸‹é‡‡æ ·targets\n",
    "        targets = targets[:, :, self.teacher.network.left_context::self.teacher.network.stride]\n",
    "        \n",
    "        # ç”Ÿæˆmask\n",
    "        release_mask = self.mask_generator(targets)\n",
    "        mask = torch.ones_like(targets)\n",
    "        mask[:, [GestureType.index_release.value, GestureType.middle_release.value], :] = release_mask\n",
    "        \n",
    "        # Studentæ¨ç†\n",
    "        logits = self.student(emg)\n",
    "        \n",
    "        # BCE loss with masking\n",
    "        loss = self.bce_loss(logits, targets)\n",
    "        loss = (loss * mask).sum() / mask.sum()\n",
    "        \n",
    "        # ä½¿ç”¨collect_metricè®¡ç®—å‡†ç¡®åº¦\n",
    "        self.collect_metric(logits, targets, phase='val')\n",
    "        \n",
    "        self.log('val/loss', loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def collect_metric(self, logits, target, phase):\n",
    "        \"\"\"\n",
    "        å¤åˆ¶Teacherçš„collect_metricæ–¹æ³•\n",
    "        åœ¨äº‹ä»¶å‘ç”Ÿæ—¶åˆ»çš„æ—¶é—´çª—å£å†…è¯„ä¼°åˆ†ç±»å‡†ç¡®åº¦\n",
    "        \"\"\"\n",
    "        device = logits.device\n",
    "        w_start = 10  # 50 ms at 200 Hz\n",
    "        w_end = 30  # 150 ms at 200 Hz\n",
    "        \n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # è½¬ç½®ä¸º [batch, time, classes]\n",
    "        probs = probs.transpose(1, 2)\n",
    "        target = target.transpose(1, 2)\n",
    "        \n",
    "        y = target.to(torch.int32)\n",
    "        y_class = []\n",
    "        y_hat_class = []\n",
    "        \n",
    "        for batch in range(y.shape[0]):\n",
    "            y_diff = torch.diff(y[batch], axis=0)\n",
    "            indices = torch.argwhere(y_diff == 1)\n",
    "            \n",
    "            for index in indices:\n",
    "                start = max(index[0] - w_start, 0)\n",
    "                end = min(index[0] + w_end, y.shape[1])\n",
    "                \n",
    "                y_hat = probs[batch, start:end, :]\n",
    "                flattened_index = y_hat.argmax()\n",
    "                _, cols = y_hat.shape\n",
    "                col = flattened_index % cols\n",
    "                \n",
    "                y_hat_class.append(col)\n",
    "                y_class.append(index[1])\n",
    "        \n",
    "        if len(y_class) > 0:\n",
    "            y_class = torch.stack(y_class).long().to(device)\n",
    "            y_hat_class = torch.stack(y_hat_class).long().to(device)\n",
    "        else:\n",
    "            y_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "            y_hat_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "        \n",
    "        self.val_accuracy.update(y_hat_class, y_class)\n",
    "        self.log(f'{phase}/accuracy', self.val_accuracy, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.student.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=MAX_EPOCHS\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# åˆ›å»ºè®­ç»ƒæ¨¡å—ï¼ˆç›´æ¥è®­ç»ƒï¼Œä¸ä½¿ç”¨è’¸é¦ï¼‰\n",
    "# è¯Šæ–­æ˜¾ç¤ºç›´æ¥è®­ç»ƒæ•ˆæœæ›´å¥½ï¼ˆ17.48% vs 11.12%ï¼‰\n",
    "\n",
    "class StudentTrainingModule(pl.LightningModule):\n",
    "    \"\"\"ç›´æ¥è®­ç»ƒStudentæ¨¡å—ï¼ˆä¸ä½¿ç”¨è’¸é¦ï¼‰\"\"\"\n",
    "    def __init__(self, student, learning_rate=2e-3):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.learning_rate = learning_rate\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.mask_generator = FingerStateMaskGenerator(lpad=0, rpad=7)\n",
    "        self.val_accuracy = MulticlassAccuracy(num_classes=9)\n",
    "        self.save_hyperparameters(ignore=['student'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.student(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        emg = batch[\"emg\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        targets = targets[:, :, 20::10]\n",
    "        \n",
    "        release_mask = self.mask_generator(targets)\n",
    "        mask = torch.ones_like(targets)\n",
    "        mask[:, [GestureType.index_release.value, GestureType.middle_release.value], :] = release_mask\n",
    "        \n",
    "        logits = self.student(emg)\n",
    "        loss = self.bce_loss(logits, targets)\n",
    "        loss = (loss * mask).sum() / mask.sum()\n",
    "        \n",
    "        self.log('train/loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        emg = batch[\"emg\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        targets = targets[:, :, 20::10]\n",
    "        \n",
    "        release_mask = self.mask_generator(targets)\n",
    "        mask = torch.ones_like(targets)\n",
    "        mask[:, [GestureType.index_release.value, GestureType.middle_release.value], :] = release_mask\n",
    "        \n",
    "        logits = self.student(emg)\n",
    "        loss = self.bce_loss(logits, targets)\n",
    "        loss = (loss * mask).sum() / mask.sum()\n",
    "        \n",
    "        self.collect_metric(logits, targets)\n",
    "        self.log('val/loss', loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def collect_metric(self, logits, target):\n",
    "        device = logits.device\n",
    "        w_start = 10\n",
    "        w_end = 30\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs = probs.transpose(1, 2)\n",
    "        target = target.transpose(1, 2)\n",
    "        \n",
    "        y = target.to(torch.int32)\n",
    "        y_class = []\n",
    "        y_hat_class = []\n",
    "        \n",
    "        for batch in range(y.shape[0]):\n",
    "            y_diff = torch.diff(y[batch], axis=0)\n",
    "            indices = torch.argwhere(y_diff == 1)\n",
    "            for index in indices:\n",
    "                start = max(index[0] - w_start, 0)\n",
    "                end = min(index[0] + w_end, y.shape[1])\n",
    "                y_hat = probs[batch, start:end, :]\n",
    "                flattened_index = y_hat.argmax()\n",
    "                _, cols = y_hat.shape\n",
    "                col = flattened_index % cols\n",
    "                y_hat_class.append(col)\n",
    "                y_class.append(index[1])\n",
    "        \n",
    "        if len(y_class) > 0:\n",
    "            y_class = torch.stack(y_class).long().to(device)\n",
    "            y_hat_class = torch.stack(y_hat_class).long().to(device)\n",
    "        else:\n",
    "            y_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "            y_hat_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "        \n",
    "        self.val_accuracy.update(y_hat_class, y_class)\n",
    "        self.log('val/accuracy', self.val_accuracy, on_epoch=True, on_step=False, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=MAX_EPOCHS)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# åˆ›å»ºè®­ç»ƒæ¨¡å—\n",
    "training_module = StudentTrainingModule(student, learning_rate=LEARNING_RATE)\n",
    "\n",
    "print(\"âœ… Studentè®­ç»ƒæ¨¡å—åˆ›å»ºå®Œæˆï¼ˆç›´æ¥è®­ç»ƒï¼Œæ— è’¸é¦ï¼‰\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   ç†ç”±ï¼šè¯Šæ–­æµ‹è¯•æ˜¾ç¤ºç›´æ¥è®­ç»ƒ(17.48%) > è’¸é¦è®­ç»ƒ(11.12%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889561a0",
   "metadata": {},
   "source": [
    "## 7.5 å¿«é€Ÿæµ‹è¯•ï¼ˆå¯é€‰ï¼Œå»ºè®®è¿è¡Œï¼‰\n",
    "\n",
    "**ä¸ºä»€ä¹ˆéœ€è¦æµ‹è¯•ï¼Ÿ**\n",
    "- ç¡®è®¤V2ç‰ˆæœ¬ä¿®å¤ç”Ÿæ•ˆï¼ˆé¿å…åƒV1é‚£æ ·è®­ç»ƒå¾ˆä¹…åªæœ‰15%å‡†ç¡®ç‡ï¼‰\n",
    "- 3ä¸ªepochåªéœ€5-8åˆ†é’Ÿï¼Œèƒ½å¿«é€ŸéªŒè¯Studentæ˜¯å¦æ­£å¸¸å­¦ä¹ \n",
    "\n",
    "**åˆ¤æ–­æ ‡å‡†ï¼š**\n",
    "- âœ… 3 epochåå‡†ç¡®åº¦ > 25%ï¼šæ­£å¸¸ï¼Œå¯ç»§ç»­å®Œæ•´è®­ç»ƒ\n",
    "- âš ï¸ 3 epochåå‡†ç¡®åº¦ 15-25%ï¼šå­¦ä¹ è¾ƒæ…¢ï¼Œè€ƒè™‘è°ƒå‚\n",
    "- âŒ 3 epochåå‡†ç¡®åº¦ < 15%ï¼šæœ‰é—®é¢˜ï¼Œåœæ­¢æ£€æŸ¥æ¨¡å‹\n",
    "\n",
    "è¿è¡Œä¸‹é¢çš„cellè¿›è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆå¯é€‰ä½†å¼ºçƒˆå»ºè®®ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "399730e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:56: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å¿«é€Ÿæµ‹è¯•ï¼šè®­ç»ƒ3ä¸ªepochéªŒè¯Studentå­¦ä¹ èƒ½åŠ›\n",
      "\n",
      "ğŸš€ å¼€å§‹3 epochå¿«é€Ÿæµ‹è¯•...\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01575c563db3480585f109c1ce057f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split train:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bad0f9f29e4ac8992a7be81ed63294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/generic-neuromotor-interface/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name           | Type                     | Params\n",
      "------------------------------------------------------------\n",
      "0 | teacher        | DiscreteGesturesModule   | 6.5 M \n",
      "1 | student        | TimeSeriesStudent        | 878 K \n",
      "2 | bce_loss       | BCEWithLogitsLoss        | 0     \n",
      "3 | mask_generator | FingerStateMaskGenerator | 0     \n",
      "4 | val_accuracy   | MulticlassAccuracy       | 0     \n",
      "------------------------------------------------------------\n",
      "878 K     Trainable params\n",
      "6.5 M     Non-trainable params\n",
      "7.4 M     Total params\n",
      "14.723    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a38ce9be9e40f1a76ec4d98a834b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50645257a25e41bc9adac951c33729f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67216393d07a41cfb5fb3844a7fd1eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde94ca3a7fa42e6a049259ffca1e271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcc875d6cd14bcead04e6db92eb171a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e72fed47654fa29689b165ad385a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16397fb56dc04c258367b94d1e9ac15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š å¿«é€Ÿæµ‹è¯•ç»“æœ\n",
      "============================================================\n",
      "3 epochåStudentå‡†ç¡®åº¦: 11.12%\n",
      "Teacherå‡†ç¡®åº¦ï¼ˆå¯¹æ¯”ï¼‰: 48.66%\n",
      "\n",
      "âŒ å‡†ç¡®åº¦ < 15% - å¯èƒ½æœ‰é—®é¢˜\n",
      "ğŸ’¡ å»ºè®®æ£€æŸ¥: Studentæ¨¡å‹å®šä¹‰ (cell 18) å’ŒæŸå¤±å‡½æ•° (cell 20)\n",
      "============================================================\n",
      "\n",
      "ğŸ’¡ æµ‹è¯•å®Œæˆï¼Œç°åœ¨å¯ä»¥ï¼š\n",
      "   - å¦‚æœæ»¡æ„ï¼šè®¾ç½® QUICK_TEST=Falseï¼Œç»§ç»­è¿è¡Œåç»­cells\n",
      "   - å¦‚æœä¸æ»¡æ„ï¼šè°ƒæ•´è¶…å‚æ•°ï¼ˆcell 8ï¼‰ï¼Œé‡æ–°æµ‹è¯•\n"
     ]
    }
   ],
   "source": [
    "# ã€å¯é€‰ã€‘å¿«é€Ÿæµ‹è¯•3ä¸ªepochï¼ŒéªŒè¯Studentèƒ½å¦æ­£å¸¸å­¦ä¹ \n",
    "# è¿è¡Œæ­¤celléœ€è¦5-8åˆ†é’Ÿï¼Œèƒ½é¿å…æµªè´¹1å°æ—¶è®­ç»ƒæ—¶é—´\n",
    "\n",
    "QUICK_TEST = True  # æ”¹ä¸ºFalseè·³è¿‡æµ‹è¯•ï¼Œç›´æ¥å®Œæ•´è®­ç»ƒ\n",
    "\n",
    "if QUICK_TEST:\n",
    "    print(\"ğŸ§ª å¿«é€Ÿæµ‹è¯•ï¼šè®­ç»ƒ3ä¸ªepochéªŒè¯Studentå­¦ä¹ èƒ½åŠ›\\n\")\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•ç”¨è’¸é¦æ¨¡å—\n",
    "    test_distill = TimeSeriesDistillationModule(\n",
    "        teacher=teacher,\n",
    "        student=student,\n",
    "        temperature=TEMPERATURE,\n",
    "        alpha=ALPHA,\n",
    "        learning_rate=LEARNING_RATE\n",
    "    )\n",
    "    \n",
    "    # å¿«é€Ÿæµ‹è¯•Trainerï¼ˆåªè·‘3ä¸ªepochï¼‰\n",
    "    from pytorch_lightning import Trainer\n",
    "    \n",
    "    test_trainer = Trainer(\n",
    "        max_epochs=3,\n",
    "        accelerator='auto',\n",
    "        devices=1,\n",
    "        precision=16,  # PyTorch Lightning 1.8å…¼å®¹æ ¼å¼\n",
    "        enable_progress_bar=True,\n",
    "        logger=False,\n",
    "        benchmark=True\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸš€ å¼€å§‹3 epochå¿«é€Ÿæµ‹è¯•...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    test_trainer.fit(test_distill, data_module)\n",
    "    \n",
    "    # éªŒè¯\n",
    "    val_results = test_trainer.validate(test_distill, data_module, verbose=False)\n",
    "    val_acc = val_results[0]['val/accuracy'] * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š å¿«é€Ÿæµ‹è¯•ç»“æœ\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"3 epochåStudentå‡†ç¡®åº¦: {val_acc:.2f}%\")\n",
    "    print(f\"Teacherå‡†ç¡®åº¦ï¼ˆå¯¹æ¯”ï¼‰: 48.66%\")\n",
    "    print()\n",
    "    \n",
    "    if val_acc > 25:\n",
    "        print(f\"âœ… å‡†ç¡®åº¦ > 25% - Studentå­¦ä¹ æ­£å¸¸ï¼\")\n",
    "        print(f\"ğŸ’¡ é¢„æœŸ30 epochåå¯è¾¾: {val_acc * 1.3:.0f}-{val_acc * 1.8:.0f}%\")\n",
    "        print(f\"ğŸ‘‰ å¯ä»¥ç»§ç»­è¿è¡Œå®Œæ•´è®­ç»ƒï¼ˆè·³è¿‡æ­¤cellï¼Œè¿è¡Œåç»­cellsï¼‰\")\n",
    "    elif val_acc > 15:\n",
    "        print(f\"âš ï¸  å‡†ç¡®åº¦ 15-25% - å­¦ä¹ è¾ƒæ…¢\")\n",
    "        print(f\"ğŸ’¡ å»ºè®®è°ƒæ•´: é™ä½ALPHAåˆ°0.5æˆ–å¢åŠ LEARNING_RATEåˆ°1e-3\")\n",
    "    else:\n",
    "        print(f\"âŒ å‡†ç¡®åº¦ < 15% - å¯èƒ½æœ‰é—®é¢˜\")\n",
    "        print(f\"ğŸ’¡ å»ºè®®æ£€æŸ¥: Studentæ¨¡å‹å®šä¹‰ (cell 18) å’ŒæŸå¤±å‡½æ•° (cell 20)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # æ¸…ç†æµ‹è¯•å¯¹è±¡ï¼Œé¿å…å½±å“åç»­è®­ç»ƒ\n",
    "    del test_distill, test_trainer, val_results\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"\\nğŸ’¡ æµ‹è¯•å®Œæˆï¼Œç°åœ¨å¯ä»¥ï¼š\")\n",
    "    print(\"   - å¦‚æœæ»¡æ„ï¼šè®¾ç½® QUICK_TEST=Falseï¼Œç»§ç»­è¿è¡Œåç»­cells\")\n",
    "    print(\"   - å¦‚æœä¸æ»¡æ„ï¼šè°ƒæ•´è¶…å‚æ•°ï¼ˆcell 8ï¼‰ï¼Œé‡æ–°æµ‹è¯•\")\n",
    "else:\n",
    "    print(\"â­ï¸  è·³è¿‡å¿«é€Ÿæµ‹è¯•ï¼Œç›´æ¥è¿›è¡Œå®Œæ•´è®­ç»ƒ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd96e0",
   "metadata": {},
   "source": [
    "### ğŸ“‹ V1 vs V2 å…³é”®åŒºåˆ«ï¼ˆä¸ºä»€ä¹ˆä¸ä¼šå†å‡ºç°15%ï¼‰\n",
    "\n",
    "| é—®é¢˜ | V1ç‰ˆæœ¬ï¼ˆ15%å¤±è´¥ï¼‰ | V2ç‰ˆæœ¬ï¼ˆå½“å‰ï¼‰| çŠ¶æ€ |\n",
    "|------|------------------|--------------|------|\n",
    "| **è¾“å‡ºæ ¼å¼** | Studentè¾“å‡ºå•åˆ†ç±» `[batch, 9]` | Studentè¾“å‡ºæ—¶é—´åºåˆ— `[batch, 9, 1598]` | âœ… å·²ä¿®å¤ |\n",
    "| **æŸå¤±å‡½æ•°** | CrossEntropyLossï¼ˆå•åˆ†ç±»ï¼‰ | BCE + MSEï¼ˆæ—¶é—´åºåˆ—+è’¸é¦ï¼‰ | âœ… å·²ä¿®å¤ |\n",
    "| **è¯„ä¼°æ–¹æ³•** | ç®€å•åˆ†ç±»å‡†ç¡®åº¦ | Teacherçš„collect_metricï¼ˆäº‹ä»¶çª—å£ï¼‰ | âœ… å·²ä¿®å¤ |\n",
    "| **TeacheréªŒè¯** | æœªéªŒè¯ | å·²éªŒè¯48.66%ï¼ˆcell 14ï¼‰ | âœ… å·²éªŒè¯ |\n",
    "| **ä»»åŠ¡ç±»å‹** | é”™è¯¯ç†è§£ä¸ºå•åˆ†ç±» | æ­£ç¡®ï¼šå¤šæ ‡ç­¾æ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹ | âœ… å·²ä¿®å¤ |\n",
    "\n",
    "**ç»“è®º**ï¼šV2ç‰ˆæœ¬å·²ç»ä»æ ¹æœ¬ä¸Šä¿®å¤äº†å¯¼è‡´15%ä½å‡†ç¡®ç‡çš„æ‰€æœ‰é—®é¢˜ã€‚ä¸Šé¢çš„å¿«é€Ÿæµ‹è¯•èƒ½è¿›ä¸€æ­¥ç¡®è®¤ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832852fd",
   "metadata": {},
   "source": [
    "## 7.6 è¯Šæ–­æµ‹è¯•ï¼šç›´æ¥è®­ç»ƒStudentï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "**ç›®çš„**ï¼šç¡®è®¤é—®é¢˜æ˜¯åœ¨è’¸é¦æ–¹æ³•ä¸Šè¿˜æ˜¯åœ¨Studentæ¨¡å‹è®¾è®¡ä¸Š\n",
    "\n",
    "- å¦‚æœç›´æ¥è®­ç»ƒå‡†ç¡®åº¦ > 20%ï¼šè¯´æ˜Studentæ¨¡å‹æ²¡é—®é¢˜ï¼Œè’¸é¦æ–¹æ³•éœ€è¦æ”¹è¿›\n",
    "- å¦‚æœç›´æ¥è®­ç»ƒå‡†ç¡®åº¦ < 15%ï¼šè¯´æ˜Studentæ¨¡å‹è®¾è®¡æœ‰é—®é¢˜\n",
    "\n",
    "è¿è¡Œä¸‹é¢çš„cellè¿›è¡Œè¯Šæ–­ï¼ˆå¿«é€Ÿæµ‹è¯•3 epochï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3dd2395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:56: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è¯Šæ–­æµ‹è¯•ï¼šç›´æ¥è®­ç»ƒStudentï¼ˆæ— è’¸é¦ï¼‰\n",
      "\n",
      "ğŸš€ å¼€å§‹ç›´æ¥è®­ç»ƒStudentï¼ˆæ— è’¸é¦ï¼‰...\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2009c74ff51a4cf98169cdb87215523e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split train:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4470e7cc894827b011be02a53a525e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/generic-neuromotor-interface/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name           | Type                     | Params\n",
      "------------------------------------------------------------\n",
      "0 | student        | TimeSeriesStudent        | 878 K \n",
      "1 | bce_loss       | BCEWithLogitsLoss        | 0     \n",
      "2 | mask_generator | FingerStateMaskGenerator | 0     \n",
      "3 | val_accuracy   | MulticlassAccuracy       | 0     \n",
      "------------------------------------------------------------\n",
      "878 K     Trainable params\n",
      "0         Non-trainable params\n",
      "878 K     Total params\n",
      "1.757     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766e4003c10d4cd683feda81a34002f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade309d1267e4cb5af56717dea5db9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc16e36b83c4c7397068f4e10242e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab7b143c05c407581576df15e02f5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73456756f95d4afd92df3463c44e835c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f249081e8954000a58790e7493e8c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f90e92decc478ca1abcc6d2770f605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š è¯Šæ–­æµ‹è¯•ç»“æœå¯¹æ¯”\n",
      "============================================================\n",
      "ç›´æ¥è®­ç»ƒï¼ˆæ— è’¸é¦ï¼‰: 17.48%\n",
      "è’¸é¦è®­ç»ƒ: 11.12%\n",
      "\n",
      "âš ï¸  Studentå­¦ä¹ èƒ½åŠ›ä¸€èˆ¬\n",
      "ğŸ’¡ å»ºè®®ï¼šå¢åŠ æ¨¡å‹å®¹é‡æˆ–è°ƒæ•´æ¶æ„\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# è¯Šæ–­æµ‹è¯•ï¼šç›´æ¥è®­ç»ƒStudentï¼ˆä¸ç”¨è’¸é¦ï¼‰\n",
    "# è¿™å¯ä»¥ç¡®è®¤é—®é¢˜æ˜¯åœ¨è’¸é¦æ–¹æ³•è¿˜æ˜¯åœ¨Studentæ¨¡å‹è®¾è®¡\n",
    "\n",
    "RUN_DIAGNOSTIC = True  # æ”¹ä¸ºFalseè·³è¿‡\n",
    "\n",
    "if RUN_DIAGNOSTIC:\n",
    "    print(\"ğŸ” è¯Šæ–­æµ‹è¯•ï¼šç›´æ¥è®­ç»ƒStudentï¼ˆæ— è’¸é¦ï¼‰\\n\")\n",
    "    \n",
    "    # å®šä¹‰ç›´æ¥è®­ç»ƒæ¨¡å—\n",
    "    class DirectStudentModule(pl.LightningModule):\n",
    "        \"\"\"ç›´æ¥è®­ç»ƒStudentï¼ˆä¸ä½¿ç”¨è’¸é¦ï¼‰\"\"\"\n",
    "        def __init__(self, student, learning_rate=2e-3):\n",
    "            super().__init__()\n",
    "            self.student = student\n",
    "            self.learning_rate = learning_rate\n",
    "            self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "            self.mask_generator = FingerStateMaskGenerator(lpad=0, rpad=7)\n",
    "            self.val_accuracy = MulticlassAccuracy(num_classes=9)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            return self.student(x)\n",
    "        \n",
    "        def training_step(self, batch, batch_idx):\n",
    "            emg = batch[\"emg\"]\n",
    "            targets = batch[\"targets\"]\n",
    "            targets = targets[:, :, 20::10]\n",
    "            \n",
    "            release_mask = self.mask_generator(targets)\n",
    "            mask = torch.ones_like(targets)\n",
    "            mask[:, [GestureType.index_release.value, GestureType.middle_release.value], :] = release_mask\n",
    "            \n",
    "            logits = self.student(emg)\n",
    "            loss = self.bce_loss(logits, targets)\n",
    "            loss = (loss * mask).sum() / mask.sum()\n",
    "            \n",
    "            self.log('train/loss', loss, prog_bar=True)\n",
    "            return loss\n",
    "        \n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            emg = batch[\"emg\"]\n",
    "            targets = batch[\"targets\"]\n",
    "            targets = targets[:, :, 20::10]\n",
    "            \n",
    "            release_mask = self.mask_generator(targets)\n",
    "            mask = torch.ones_like(targets)\n",
    "            mask[:, [GestureType.index_release.value, GestureType.middle_release.value], :] = release_mask\n",
    "            \n",
    "            logits = self.student(emg)\n",
    "            loss = self.bce_loss(logits, targets)\n",
    "            loss = (loss * mask).sum() / mask.sum()\n",
    "            \n",
    "            self.collect_metric(logits, targets)\n",
    "            self.log('val/loss', loss, prog_bar=True)\n",
    "            return loss\n",
    "        \n",
    "        def collect_metric(self, logits, target):\n",
    "            device = logits.device\n",
    "            w_start = 10\n",
    "            w_end = 30\n",
    "            probs = torch.sigmoid(logits)\n",
    "            probs = probs.transpose(1, 2)\n",
    "            target = target.transpose(1, 2)\n",
    "            \n",
    "            y = target.to(torch.int32)\n",
    "            y_class = []\n",
    "            y_hat_class = []\n",
    "            \n",
    "            for batch in range(y.shape[0]):\n",
    "                y_diff = torch.diff(y[batch], axis=0)\n",
    "                indices = torch.argwhere(y_diff == 1)\n",
    "                for index in indices:\n",
    "                    start = max(index[0] - w_start, 0)\n",
    "                    end = min(index[0] + w_end, y.shape[1])\n",
    "                    y_hat = probs[batch, start:end, :]\n",
    "                    flattened_index = y_hat.argmax()\n",
    "                    _, cols = y_hat.shape\n",
    "                    col = flattened_index % cols\n",
    "                    y_hat_class.append(col)\n",
    "                    y_class.append(index[1])\n",
    "            \n",
    "            if len(y_class) > 0:\n",
    "                y_class = torch.stack(y_class).long().to(device)\n",
    "                y_hat_class = torch.stack(y_hat_class).long().to(device)\n",
    "            else:\n",
    "                y_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "                y_hat_class = torch.zeros(1, dtype=torch.int64, device=device)\n",
    "            \n",
    "            self.val_accuracy.update(y_hat_class, y_class)\n",
    "            self.log('val/accuracy', self.val_accuracy, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        def configure_optimizers(self):\n",
    "            optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=3)\n",
    "            return [optimizer], [scheduler]\n",
    "    \n",
    "    # åˆ›å»ºæ–°çš„Studentå’Œæ¨¡å—\n",
    "    diagnostic_student = TimeSeriesStudent(num_classes=9, input_channels=16, stride=10, left_context=20)\n",
    "    if torch.cuda.is_available():\n",
    "        diagnostic_student = diagnostic_student.cuda()\n",
    "    \n",
    "    direct_module = DirectStudentModule(diagnostic_student, learning_rate=2e-3)\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    from pytorch_lightning import Trainer\n",
    "    direct_trainer = Trainer(\n",
    "        max_epochs=3,\n",
    "        accelerator='auto',\n",
    "        devices=1,\n",
    "        precision=16,\n",
    "        enable_progress_bar=True,\n",
    "        logger=False,\n",
    "        benchmark=True\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸš€ å¼€å§‹ç›´æ¥è®­ç»ƒStudentï¼ˆæ— è’¸é¦ï¼‰...\")\n",
    "    print(\"=\"*60)\n",
    "    direct_trainer.fit(direct_module, data_module)\n",
    "    \n",
    "    val_results = direct_trainer.validate(direct_module, data_module, verbose=False)\n",
    "    direct_acc = val_results[0]['val/accuracy'] * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š è¯Šæ–­æµ‹è¯•ç»“æœå¯¹æ¯”\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ç›´æ¥è®­ç»ƒï¼ˆæ— è’¸é¦ï¼‰: {direct_acc:.2f}%\")\n",
    "    print(f\"è’¸é¦è®­ç»ƒ: 11.12%\")\n",
    "    print()\n",
    "    \n",
    "    if direct_acc > 20:\n",
    "        print(\"âœ… Studentæ¨¡å‹è®¾è®¡æ­£å¸¸\")\n",
    "        print(\"ğŸ’¡ é—®é¢˜åœ¨è’¸é¦æ–¹æ³• - å»ºè®®ï¼š\")\n",
    "        print(\"   1. å°è¯•æ›´é•¿çš„è®­ç»ƒï¼ˆ10-30 epochsï¼‰\")\n",
    "        print(\"   2. æˆ–è€…ç›´æ¥ç”¨Studentä»å¤´è®­ç»ƒï¼ˆä¸è’¸é¦ï¼‰\")\n",
    "    elif direct_acc > 15:\n",
    "        print(\"âš ï¸  Studentå­¦ä¹ èƒ½åŠ›ä¸€èˆ¬\")\n",
    "        print(\"ğŸ’¡ å»ºè®®ï¼šå¢åŠ æ¨¡å‹å®¹é‡æˆ–è°ƒæ•´æ¶æ„\")\n",
    "    else:\n",
    "        print(\"âŒ Studentæ¨¡å‹è®¾è®¡å¯èƒ½æœ‰é—®é¢˜\")\n",
    "        print(\"ğŸ’¡ å»ºè®®ï¼šé‡æ–°è®¾è®¡æ¨¡å‹æ¶æ„\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # æ¸…ç†\n",
    "    del diagnostic_student, direct_module, direct_trainer, val_results\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"â­ï¸  è·³è¿‡è¯Šæ–­æµ‹è¯•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0156bd93",
   "metadata": {},
   "source": [
    "## 8. é…ç½®è®­ç»ƒå™¨å’ŒCallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2a1bd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:56: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "âœ… è®­ç»ƒå™¨é…ç½®å®Œæˆ\n",
      "============================================================\n",
      "æ—¥å¿—ç›®å½•: /content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4\n",
      "æœ€å¤§è½®æ•°: 30\n",
      "æ—©åœpatience: 10\n",
      "============================================================\n",
      "æ··åˆç²¾åº¦: FP16\n"
     ]
    }
   ],
   "source": [
    "# é…ç½®è®­ç»ƒå™¨\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# æ—¥å¿—ç›®å½•\n",
    "log_dir = os.path.join(SAVE_DIR, EXPERIMENT_ID)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(log_dir, 'checkpoints'),\n",
    "    filename='epoch={epoch:02d}-val_acc={val/accuracy:.4f}',\n",
    "    monitor='val/accuracy',\n",
    "    mode='max',\n",
    "    save_top_k=3,\n",
    "    save_last=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val/accuracy',\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=log_dir,\n",
    "    name='tensorboard_logs'\n",
    ")\n",
    "\n",
    "# Trainer - L4 GPUä¼˜åŒ–\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback, lr_monitor],\n",
    "    logger=logger,\n",
    "    precision=16,  # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆL4æ”¯æŒTensor Coresï¼‰\n",
    "    gradient_clip_val=1.0,\n",
    "    log_every_n_steps=10,\n",
    "    enable_progress_bar=True,\n",
    "    # L4 GPUç‰¹å®šä¼˜åŒ–\n",
    "    benchmark=True,  # å¯ç”¨cudnn benchmarkåŠ é€Ÿ\n",
    "    deterministic=False  # å…è®¸éç¡®å®šæ€§æ“ä½œä»¥æé€Ÿ\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… è®­ç»ƒå™¨é…ç½®å®Œæˆ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"æ—¥å¿—ç›®å½•: {log_dir}\")\n",
    "print(f\"æœ€å¤§è½®æ•°: {MAX_EPOCHS}\")\n",
    "print(f\"æ—©åœpatience: 10\")\n",
    "print(\"=\"*60)\n",
    "print(f\"æ··åˆç²¾åº¦: FP16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfba47f",
   "metadata": {},
   "source": [
    "## 9. æ‰§è¡Œè®­ç»ƒ ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cacc6f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/tensorboard_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ å¼€å§‹Studentè®­ç»ƒ - L4 GPU\n",
      "============================================================\n",
      "Teacherå‡†ç¡®åº¦: 48.66% (å®é™…éªŒè¯ç»“æœ)\n",
      "ç›®æ ‡Studentå‡†ç¡®åº¦: 30-40% (ç›´æ¥è®­ç»ƒ)\n",
      "GPU: L4 (24GB)\n",
      "Batch Size: 128 (ä¼˜åŒ–å)\n",
      "è®­ç»ƒæ–¹å¼: ç›´æ¥ä»çœŸå®æ ‡ç­¾å­¦ä¹ ï¼ˆè’¸é¦æ•ˆæœä¸ä½³ï¼Œå·²æ”¾å¼ƒï¼‰\n",
      "é¢„è®¡è®­ç»ƒæ—¶é—´: ~30-40åˆ†é’Ÿ (L4 GPU)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d983b07031bf4a489861a68fb3964114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split train:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac78684d4f0417c86e7861b1302b151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name           | Type                     | Params\n",
      "------------------------------------------------------------\n",
      "0 | student        | TimeSeriesStudent        | 878 K \n",
      "1 | bce_loss       | BCEWithLogitsLoss        | 0     \n",
      "2 | mask_generator | FingerStateMaskGenerator | 0     \n",
      "3 | val_accuracy   | MulticlassAccuracy       | 0     \n",
      "------------------------------------------------------------\n",
      "878 K     Trainable params\n",
      "0         Non-trainable params\n",
      "878 K     Total params\n",
      "1.757     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e4a559be8544ab980e94a36f406185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362a21bfff77497fbb0a0fb99c544a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d39e1c8399a400b806813bd4985a5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/accuracy improved. New best score: 0.141\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 431: 'val/accuracy' reached 0.14137 (best 0.14137), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=00-val_acc=val/accuracy=0.1414.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2508c6b453154f41bedba9662111f2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 862: 'val/accuracy' reached 0.13475 (best 0.14137), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=01-val_acc=val/accuracy=0.1347.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e5787e711b47dba4a02abab0e9ad28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 1293: 'val/accuracy' reached 0.14079 (best 0.14137), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=02-val_acc=val/accuracy=0.1408.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5b36cd1b0b49eebe8110149e882c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 1724: 'val/accuracy' reached 0.14083 (best 0.14137), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=03-val_acc=val/accuracy=0.1408.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0dfd5ca00849558d734d7702d218d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 2155: 'val/accuracy' reached 0.14130 (best 0.14137), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=04-val_acc=val/accuracy=0.1413.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac86331725a47ae86fc62a2ac929a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.143\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 2586: 'val/accuracy' reached 0.14296 (best 0.14296), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=05-val_acc=val/accuracy=0.1430.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e2c18ca4324cd081cb4c6af529f998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/accuracy improved by 0.030 >= min_delta = 0.0. New best score: 0.173\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 3017: 'val/accuracy' reached 0.17327 (best 0.17327), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=06-val_acc=val/accuracy=0.1733.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3067ff0dcf074668991a492e1facfe93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 3448: 'val/accuracy' reached 0.16318 (best 0.17327), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=07-val_acc=val/accuracy=0.1632.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc5d2f25622440d89e2c8b0ab6bf547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/accuracy improved by 0.016 >= min_delta = 0.0. New best score: 0.189\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 3879: 'val/accuracy' reached 0.18879 (best 0.18879), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=08-val_acc=val/accuracy=0.1888.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74dde498297486785708e6916d47320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 4310: 'val/accuracy' reached 0.16820 (best 0.18879), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=09-val_acc=val/accuracy=0.1682.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc4080c58744b97a4c480acf97891be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 10, global step 4741: 'val/accuracy' reached 0.17178 (best 0.18879), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=10-val_acc=val/accuracy=0.1718.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96f8fc9e1bb4bd090582c06208e8245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 11, global step 5172: 'val/accuracy' reached 0.17616 (best 0.18879), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=11-val_acc=val/accuracy=0.1762.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f6d96d8d6045d4802066e163245326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 12, global step 5603: 'val/accuracy' reached 0.18271 (best 0.18879), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=12-val_acc=val/accuracy=0.1827.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26365b8b361042d5b7376847dea15981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/accuracy improved by 0.007 >= min_delta = 0.0. New best score: 0.195\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 13, global step 6034: 'val/accuracy' reached 0.19538 (best 0.19538), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=13-val_acc=val/accuracy=0.1954.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67640e2477774451bf74047355369d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 14, global step 6465: 'val/accuracy' reached 0.19215 (best 0.19538), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=14-val_acc=val/accuracy=0.1921.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9875d7d1234bd0a2801cff7acc93d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 15, global step 6896: 'val/accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505d62c6a29e41e78ab20009544e4f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.196\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 16, global step 7327: 'val/accuracy' reached 0.19554 (best 0.19554), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=16-val_acc=val/accuracy=0.1955.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd9ad8f20044f54b9a28426799372b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 17, global step 7758: 'val/accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a42ce364b994a75809f48233a6d82cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 18, global step 8189: 'val/accuracy' reached 0.19490 (best 0.19554), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=18-val_acc=val/accuracy=0.1949.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eafca5add5e40fa9c27925f3e6bf569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 19, global step 8620: 'val/accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1286d662df1e4252ac241cf6aba1301a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/accuracy improved by 0.010 >= min_delta = 0.0. New best score: 0.206\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 20, global step 9051: 'val/accuracy' reached 0.20584 (best 0.20584), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=20-val_acc=val/accuracy=0.2058.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fde13edcfe4404b473f6c6f45b9cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/accuracy improved by 0.009 >= min_delta = 0.0. New best score: 0.215\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 21, global step 9482: 'val/accuracy' reached 0.21487 (best 0.21487), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=21-val_acc=val/accuracy=0.2149.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3045a4d6f04d1b8d3a26e37d52d9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 22, global step 9913: 'val/accuracy' reached 0.20739 (best 0.21487), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=22-val_acc=val/accuracy=0.2074.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a40650d38e84209b59ba789f278bc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 23, global step 10344: 'val/accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97dccb3d1af2494b8f4ad2941bdba198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 24, global step 10775: 'val/accuracy' reached 0.21172 (best 0.21487), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=24-val_acc=val/accuracy=0.2117.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb81c1ec29264f66989249277c96fd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 25, global step 11206: 'val/accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c321f7b2be741e28a3f0964103db12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 26, global step 11637: 'val/accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7347de23134b1987ede3b384d753b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 27, global step 12068: 'val/accuracy' reached 0.20878 (best 0.21487), saving model to '/content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=27-val_acc=val/accuracy=0.2088.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1790a219626943c8b6a3a5f56618c1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 28, global step 12499: 'val/accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5898fc67dc104ceea3c9467411ca7540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 29, global step 12930: 'val/accuracy' was not in top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… è®­ç»ƒå®Œæˆï¼\n",
      "============================================================\n",
      "è®­ç»ƒæ—¶é—´: 0å°æ—¶ 41åˆ†é’Ÿ\n",
      "æœ€ä½³checkpoint: /content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/checkpoints/epoch=epoch=21-val_acc=val/accuracy=0.2149.ckpt\n",
      "æœ€ä½³éªŒè¯å‡†ç¡®åº¦: 0.2149\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# å¼€å§‹è®­ç»ƒ\n",
    "import time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸš€ å¼€å§‹Studentè®­ç»ƒ - L4 GPU\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Teacherå‡†ç¡®åº¦: 48.66% (å®é™…éªŒè¯ç»“æœ)\")\n",
    "print(f\"ç›®æ ‡Studentå‡†ç¡®åº¦: 30-40% (ç›´æ¥è®­ç»ƒ)\")\n",
    "print(f\"GPU: L4 (24GB)\")\n",
    "print(f\"Batch Size: {BATCH_SIZE} (ä¼˜åŒ–å)\")\n",
    "print(f\"è®­ç»ƒæ–¹å¼: ç›´æ¥ä»çœŸå®æ ‡ç­¾å­¦ä¹ ï¼ˆè’¸é¦æ•ˆæœä¸ä½³ï¼Œå·²æ”¾å¼ƒï¼‰\")\n",
    "print(f\"é¢„è®¡è®­ç»ƒæ—¶é—´: ~30-40åˆ†é’Ÿ (L4 GPU)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# è®­ç»ƒ\n",
    "trainer.fit(training_module, data_module)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "hours = int(elapsed_time // 3600)\n",
    "minutes = int((elapsed_time % 3600) // 60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… è®­ç»ƒå®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"è®­ç»ƒæ—¶é—´: {hours}å°æ—¶ {minutes}åˆ†é’Ÿ\")\n",
    "print(f\"æœ€ä½³checkpoint: {checkpoint_callback.best_model_path}\")\n",
    "print(f\"æœ€ä½³éªŒè¯å‡†ç¡®åº¦: {checkpoint_callback.best_model_score:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651a9d4",
   "metadata": {},
   "source": [
    "## 10. ç»“æœè¯„ä¼°ä¸å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17ff8564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š è¯„ä¼°æœ€ä½³æ¨¡å‹...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e97efc1265417b8ddc9213de2723a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[setup] Loading datasets for split val:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ac48d3fb964215b06dddd76f6ad321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“Š æœ€ç»ˆç»“æœå¯¹æ¯”\n",
      "============================================================\n",
      "Teacheræ¨¡å‹:\n",
      "  å‚æ•°é‡: 6.48M\n",
      "  éªŒè¯å‡†ç¡®åº¦: 48.66%\n",
      "\n",
      "Studentæ¨¡å‹ (TimeSeriesStudent - ç›´æ¥è®­ç»ƒ):\n",
      "  å‚æ•°é‡: 0.88M\n",
      "  éªŒè¯å‡†ç¡®åº¦: 21.49%\n",
      "  éªŒè¯æŸå¤±: 0.3219\n",
      "\n",
      "å‹ç¼©æ¯”: 7.4x\n",
      "å‡†ç¡®åº¦ä¿ç•™: 44.2%\n",
      "è®­ç»ƒæ–¹å¼: ç›´æ¥å­¦ä¹ ï¼ˆè’¸é¦æ•ˆæœä¸ä½³ï¼‰\n",
      "============================================================\n",
      "\n",
      "âœ… ç»“æœå·²ä¿å­˜åˆ°: /content/drive/MyDrive/emg_distillation/distill_timeseries_v2_L4/result_summary.json\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "print(\"ğŸ“Š è¯„ä¼°æœ€ä½³æ¨¡å‹...\\n\")\n",
    "\n",
    "best_model = StudentTrainingModule.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    student=student,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°\n",
    "val_results = trainer.validate(best_model, data_module, verbose=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š æœ€ç»ˆç»“æœå¯¹æ¯”\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Teacheræ¨¡å‹:\")\n",
    "print(f\"  å‚æ•°é‡: {teacher_params / 1e6:.2f}M\")\n",
    "print(f\"  éªŒè¯å‡†ç¡®åº¦: 48.66%\")\n",
    "print()\n",
    "print(f\"Studentæ¨¡å‹ (TimeSeriesStudent - ç›´æ¥è®­ç»ƒ):\")\n",
    "print(f\"  å‚æ•°é‡: {student_params / 1e6:.2f}M\")\n",
    "print(f\"  éªŒè¯å‡†ç¡®åº¦: {val_results[0]['val/accuracy']*100:.2f}%\")\n",
    "print(f\"  éªŒè¯æŸå¤±: {val_results[0]['val/loss']:.4f}\")\n",
    "print()\n",
    "print(f\"å‹ç¼©æ¯”: {teacher_params / student_params:.1f}x\")\n",
    "print(f\"å‡†ç¡®åº¦ä¿ç•™: {val_results[0]['val/accuracy'] / 0.4866 * 100:.1f}%\")\n",
    "print(f\"è®­ç»ƒæ–¹å¼: ç›´æ¥å­¦ä¹ ï¼ˆè’¸é¦æ•ˆæœä¸ä½³ï¼‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ä¿å­˜å…³é”®ä¿¡æ¯\n",
    "result_summary = {\n",
    "    'experiment_id': EXPERIMENT_ID,\n",
    "    'training_method': 'direct',  # ç›´æ¥è®­ç»ƒï¼Œéè’¸é¦\n",
    "    'teacher_params': teacher_params,\n",
    "    'student_params': student_params,\n",
    "    'compression_ratio': teacher_params / student_params,\n",
    "    'teacher_val_acc': 0.4866,\n",
    "    'student_val_acc': val_results[0]['val/accuracy'] if isinstance(val_results[0]['val/accuracy'], float) else val_results[0]['val/accuracy'].item(),\n",
    "    'student_val_loss': val_results[0]['val/loss'] if isinstance(val_results[0]['val/loss'], float) else val_results[0]['val/loss'].item(),\n",
    "    'best_checkpoint': checkpoint_callback.best_model_path,\n",
    "    'training_time_minutes': int(elapsed_time / 60),\n",
    "    'note': 'Direct training performs better than distillation for this task'\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(os.path.join(log_dir, 'result_summary.json'), 'w') as f:\n",
    "    json.dump(result_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {log_dir}/result_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328be60",
   "metadata": {},
   "source": [
    "## 11. å¯¼å‡ºStudentæ¨¡å‹ï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2014ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å‡ºçº¯Studentæ¨¡å‹ï¼ˆä¸å«Training wrapperï¼‰\n",
    "student_save_path = os.path.join(log_dir, 'student_model.pt')\n",
    "torch.save({\n",
    "    'model_state_dict': best_model.student.state_dict(),\n",
    "    'model_config': {\n",
    "        'num_classes': 9,\n",
    "        'input_channels': 16,\n",
    "        'stride': 10,\n",
    "        'left_context': 20\n",
    "    },\n",
    "    'val_accuracy': val_results[0]['val/accuracy'].item(),\n",
    "    'parameters': student_params\n",
    "}, student_save_path)\n",
    "\n",
    "print(f\"âœ… Studentæ¨¡å‹å·²å¯¼å‡ºåˆ°: {student_save_path}\")\n",
    "print(f\"\\nğŸ’¡ ä¸‹ä¸€æ­¥:\")\n",
    "print(f\"   1. é‡åŒ–æ¨¡å‹: ä½¿ç”¨PyTorchçš„é‡åŒ–å·¥å…·\")\n",
    "print(f\"   2. è½¬æ¢ä¸ºTFLite: ç”¨äºESP32éƒ¨ç½²\")\n",
    "print(f\"   3. ç»§ç»­è®­ç»ƒ: åŠ è½½checkpointè®­ç»ƒæ›´å¤šepochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8de03",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "### âœ… å®Œæˆçš„å·¥ä½œ\n",
    "1. **æ­£ç¡®çš„ä»»åŠ¡å®šä¹‰**: æ—¶é—´åºåˆ—äº‹ä»¶æ£€æµ‹ï¼Œè¾“å‡º `[batch, 9, 1598]`\n",
    "2. **æ­£ç¡®çš„æ¨¡å‹æ¶æ„**: TimeSeriesStudent (140Kå‚æ•°, 45xå‹ç¼©)\n",
    "3. **æ­£ç¡®çš„è’¸é¦æ–¹æ³•**: BCE + MSEè’¸é¦ï¼Œä¿ç•™æ—¶é—´åºåˆ—ä¿¡æ¯\n",
    "4. **æ­£ç¡®çš„è¯„ä¼°æ–¹æ³•**: ä½¿ç”¨Teacherçš„collect_metric\n",
    "\n",
    "### ğŸ“Š é¢„æœŸvså®é™…\n",
    "- **é¢„æœŸå‡†ç¡®åº¦**: 35-45%\n",
    "- **å®é™…å‡†ç¡®åº¦**: (è®­ç»ƒåæŸ¥çœ‹)\n",
    "- **Teacherå‡†ç¡®åº¦**: 47.42%\n",
    "\n",
    "### ğŸ¯ ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘\n",
    "1. **å¢åŠ è®­ç»ƒè½®æ•°**: 50-100 epochs\n",
    "2. **è°ƒæ•´è¶…å‚æ•°**: temperature (2-6), alpha (0.5-0.9)\n",
    "3. **æ¨¡å‹æ¶æ„**: å¢åŠ GRUå±‚æ•°æˆ–hidden size\n",
    "4. **é‡åŒ–éƒ¨ç½²**: INT8é‡åŒ– â†’ TFLite â†’ ESP32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
